<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Google Brain Research Overview | Jeremy Nixon</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Google Brain Research Overview" />
<meta name="author" content="Jeremy Nixon" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="By Jeremy Nixon [jnixon2@gmail.com]. Nov 2017." />
<meta property="og:description" content="By Jeremy Nixon [jnixon2@gmail.com]. Nov 2017." />
<link rel="canonical" href="http://localhost:4000/machinelearning/2018/06/07/google-brain-research-overview.html" />
<meta property="og:url" content="http://localhost:4000/machinelearning/2018/06/07/google-brain-research-overview.html" />
<meta property="og:site_name" content="Jeremy Nixon" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-06-07T05:02:46-07:00" />
<script type="application/ld+json">
{"headline":"Google Brain Research Overview","dateModified":"2018-06-07T05:02:46-07:00","datePublished":"2018-06-07T05:02:46-07:00","url":"http://localhost:4000/machinelearning/2018/06/07/google-brain-research-overview.html","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/machinelearning/2018/06/07/google-brain-research-overview.html"},"author":{"@type":"Person","name":"Jeremy Nixon"},"description":"By Jeremy Nixon [jnixon2@gmail.com]. Nov 2017.","@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Jeremy Nixon" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Jeremy Nixon</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">Identity.</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Google Brain Research Overview</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2018-06-07T05:02:46-07:00" itemprop="datePublished">Jun 7, 2018
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>By Jeremy Nixon [<a href="mailto:jnixon2@gmail.com">jnixon2@gmail.com</a>]. Nov 2017.</p>

<p>Overview</p>

<ol>
  <li>
    <p>Categorization of Breakthroughs / Contents</p>
  </li>
  <li>
    <p>Major / Minor Researchers List (All appearing on papers)</p>
  </li>
  <li>
    <p>Genealogy</p>
  </li>
  <li>
    <p>Sorted Researchers by Paper Count</p>
  </li>
  <li>
    <p>Deep Learning</p>

    <ol>
      <li>
        <p>Scalability and Speed</p>
      </li>
      <li>
        <p>Convolutional Neural Networks</p>
      </li>
      <li>
        <p>Recurrent Neural Networks</p>
      </li>
      <li>
        <p>Privacy</p>
      </li>
      <li>
        <p>Understanding / Theory</p>
      </li>
      <li>
        <p>Regularization</p>
      </li>
    </ol>
  </li>
  <li>
    <p>Applications</p>

    <ol>
      <li>
        <p>Speech Recognition</p>
      </li>
      <li>
        <p>Image Categorization</p>
      </li>
      <li>
        <p>Image Captioning</p>
      </li>
      <li>
        <p>Machine Translation</p>
      </li>
      <li>
        <p>Natural Language Understanding</p>
      </li>
      <li>
        <p>Multi-Modal</p>
      </li>
      <li>
        <p>Pedestrian Detection</p>
      </li>
      <li>
        <p>Grasp Detection</p>
      </li>
      <li>
        <p>Go</p>
      </li>
      <li>
        <p>Video</p>
      </li>
      <li>
        <p>Dialogue</p>
      </li>
      <li>
        <p>3D Object Reconstruction</p>
      </li>
      <li>
        <p>Speaker Verification</p>
      </li>
      <li>
        <p>Health Care</p>
      </li>
      <li>
        <p>Theorem Proving</p>
      </li>
      <li>
        <p>Music</p>
      </li>
      <li>
        <p>Pose Estimation</p>
      </li>
      <li>
        <p>Speech Generation</p>
      </li>
      <li>
        <p>Super Resolution</p>
      </li>
      <li>
        <p>Chemistry</p>
      </li>
      <li>
        <p>Robotics</p>

        <ol>
          <li>Autonomous Vehicles</li>
        </ol>
      </li>
      <li>
        <p>Physics</p>
      </li>
      <li>
        <p>Device Placement</p>
      </li>
      <li>
        <p>Games</p>
      </li>
      <li>
        <p>Art</p>
      </li>
    </ol>
  </li>
  <li>
    <p>Unsupervised Learning</p>
  </li>
  <li>
    <p>Attention</p>
  </li>
  <li>
    <p>Memory</p>
  </li>
  <li>
    <p>Transfer Learning</p>
  </li>
  <li>
    <p>Representation Learning</p>
  </li>
  <li>
    <p>Reinforcement Learning</p>

    <ol>
      <li>
        <p>Model-Based Reinforcement Learning</p>
      </li>
      <li>
        <p>Multi-Task Learning</p>
      </li>
    </ol>
  </li>
  <li>
    <p>Metalearning</p>

    <ol>
      <li>
        <p>Neural Programming</p>
      </li>
      <li>
        <p>Hyperparameter Optimization</p>
      </li>
    </ol>
  </li>
  <li>
    <p>Generative</p>

    <ol>
      <li>GANs</li>
    </ol>
  </li>
  <li>
    <p>Interpretability</p>
  </li>
  <li>
    <p>Tools, Environments &amp; Datasets</p>
  </li>
  <li>
    <p>Adversarial Examples</p>
  </li>
  <li>
    <p>Multi-Agent Systems</p>
  </li>
  <li>
    <p>Variational Inference</p>
  </li>
  <li>
    <p>Kernel Machines</p>
  </li>
  <li>
    <p>Collaborative Filtering</p>
  </li>
  <li>
    <p>Graphical / Relational Learning</p>
  </li>
  <li>
    <p>Miscellaneous</p>
  </li>
  <li>
    <p>Deep Learning</p>

    <ol>
      <li>
        <p>Scalability and Speed</p>

        <ol>
          <li>Large Scale Distributed Deep Networks
            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40565.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40565.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Multiframe Deep Neural Networks for Acoustic Modeling</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40810.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40810.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Asynchronous Stochastic Optimization for Sequence Training of Deep Neural Networks</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42248.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42248.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Tensorflow: Large-Scale Machine Learning on Heterogeneous Distributed Systems</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45166.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45166.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Distilling the Knowledge in a Neural Network</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44873.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44873.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Deep Networks with Large Output Spaces</p>

            <ol>
              <li><a href="https://arxiv.org/pdf/1412.7479.pdf">https://arxiv.org/pdf/1412.7479.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>TensorFlow: A System for Large-Scale Machine Learning</p>

            <ol>
              <li><a href="https://www.usenix.org/system/files/conference/osdi16/osdi16-abadi.pdf">https://www.usenix.org/system/files/conference/osdi16/osdi16-abadi.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Revisiting Distributed Synchronous SGD</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45187.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45187.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Depthwise Separable Convolutions for Neural Machine Translation</p>

            <ol>
              <li><a href="https://arxiv.org/abs/1706.03059">https://arxiv.org/abs/1706.03059</a></li>
            </ol>
          </li>
          <li>
            <p>Large Scale Distributed Neural Network Training Through Online Distillation</p>

            <ol>
              <li><a href="https://openreview.net/pdf?id=rkr1UDeC-">https://openreview.net/pdf?id=rkr1UDeC-</a></li>
            </ol>
          </li>
          <li>
            <p>Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training</p>

            <ol>
              <li>https://openreview.net/pdf?id=SkhQHMW0W</li>
            </ol>
          </li>
        </ol>
      </li>
      <li>
        <p>Convolutional Neural Networks</p>

        <ol>
          <li>
            <p>Going Deeper with Convolutions [Inception]</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43022.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43022.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Rethinking the Inception Architecture for Computer Vision</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44903.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44903.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45169.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45169.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Towards Understanding the Invertibility of Convolutional Neural Networks</p>

            <ol>
              <li>https://arxiv.org/pdf/1705.08664.pdf</li>
            </ol>
          </li>
        </ol>
      </li>
      <li>
        <p>Recurrent Neural Networks</p>

        <ol>
          <li>
            <p>Sequence to Sequence Learning with Neural Networks</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43155.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43155.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Sequence Discriminative Distributed Training of Long Short-Term Memory Recurrent Neural Networks</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42547.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42547.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Recurrent Neural Network Regularization [Also, Language Modeling]</p>

            <ol>
              <li><a href="https://arxiv.org/abs/1409.2329">https://arxiv.org/abs/1409.2329</a></li>
            </ol>
          </li>
          <li>
            <p>Semi-supervised Sequence Learning</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44267.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44267.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Learning to Execute</p>

            <ol>
              <li><a href="https://research.google.com/pubs/pub45474.html">https://research.google.com/pubs/pub45474.html</a></li>
            </ol>
          </li>
          <li>
            <p>An Empirical Exploration of Recurrent Network Architectures</p>

            <ol>
              <li><a href="https://research.google.com/pubs/pub45473.html">https://research.google.com/pubs/pub45473.html</a></li>
            </ol>
          </li>
          <li>
            <p>A Simple Way to Initialize Recurrent Networks of Rectified Linear Units</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44961.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44961.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Using Fast Weights to Attend to the Recent Past</p>

            <ol>
              <li><a href="https://arxiv.org/pdf/1610.06258.pdf">https://arxiv.org/pdf/1610.06258.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Unsupervised Pre-training for Sequence to Sequence Learning</p>

            <ol>
              <li><a href="https://arxiv.org/pdf/1611.02683.pdf">https://arxiv.org/pdf/1611.02683.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Order Matters: Sequence to Sequence for Sets</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44871.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44871.pdf</a>`</li>
            </ol>
          </li>
          <li>
            <p>Multi-Task Sequence to Sequence Learning</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44928.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44928.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Generating Sentences from a Continuous Space</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45404.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45404.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Exponential expressivity in deep neural networks through transient chaos</p>

            <ol>
              <li><a href="https://arxiv.org/pdf/1606.05340.pdf">https://arxiv.org/pdf/1606.05340.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>An Online Sequence-to-Sequence Model Using Partial Conditioning</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45167.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45167.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>A Neural Transducer</p>

            <ol>
              <li><a href="https://arxiv.org/pdf/1511.04868.pdf">https://arxiv.org/pdf/1511.04868.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Tuning Recurrent Neural Networks with Reinforcement Learning</p>

            <ol>
              <li><a href="https://openreview.net/pdf?id=Syyv2e-Kx">https://openreview.net/pdf?id=Syyv2e-Kx</a></li>
            </ol>
          </li>
          <li>
            <p>Sequence Tutor: Conservative Fine-Tuning of Sequence Generation Models with KL-control</p>

            <ol>
              <li><a href="https://arxiv.org/pdf/1611.02796.pdf">https://arxiv.org/pdf/1611.02796.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>SGD Learns the Conjugate Kernel Class of the Network</p>

            <ol>
              <li><a href="https://arxiv.org/pdf/1702.08503.pdf">https://arxiv.org/pdf/1702.08503.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Learning Hierarchical Information Flow with Recurrent Neural Modules</p>

            <ol>
              <li><a href="https://arxiv.org/pdf/1706.05744.pdf">https://arxiv.org/pdf/1706.05744.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Latent Sequence Decompositions</p>

            <ol>
              <li><a href="https://arxiv.org/pdf/1610.03035.pdf">https://arxiv.org/pdf/1610.03035.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Capacity and Trainability in Recurrent Neural Networks</p>

            <ol>
              <li><a href="https://openreview.net/pdf?id=BydARw9ex">https://openreview.net/pdf?id=BydARw9ex</a></li>
            </ol>
          </li>
          <li>
            <p>Initialization Matters: Orthogonal Predictive State Recurrent Neural Networks</p>

            <ol>
              <li>https://openreview.net/pdf?id=HJJ23bW0b</li>
            </ol>
          </li>
        </ol>
      </li>
      <li>
        <p>Privacy</p>

        <ol>
          <li>
            <p>Deep Learning with Differential Privacy</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45428.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45428.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Semi-Supervised Knowledge Transfer for Deep Learning from Private Training Data</p>

            <ol>
              <li><a href="https://arxiv.org/pdf/1610.05755.pdf">https://arxiv.org/pdf/1610.05755.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Glimmers: Resolving the Privacy / Trust Quagmire</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46128.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46128.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Scalable Private Learning with PATE</p>

            <ol>
              <li><a href="https://arxiv.org/pdf/1802.08908.pdf">https://arxiv.org/pdf/1802.08908.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Learning Differentially Private Recurrent Language Models [Also, Language Modeling]</p>

            <ol>
              <li>https://openreview.net/pdf?id=BJ0hF1Z0b</li>
            </ol>
          </li>
        </ol>
      </li>
      <li>
        <p>Understanding / Theory</p>

        <ol>
          <li>
            <p>Qualitatively Characterizing Neural Network Optimization Problems</p>

            <ol>
              <li><a href="https://arxiv.org/pdf/1412.6544.pdf">https://arxiv.org/pdf/1412.6544.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Toward Deeper Understanding of Neural Networks: The Power of Initialization and a Dual View on Expressivity</p>

            <ol>
              <li><a href="https://arxiv.org/pdf/1602.05897.pdf">https://arxiv.org/pdf/1602.05897.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Understanding Deep Learning Requires Re-Thinking Generalization</p>

            <ol>
              <li><a href="https://arxiv.org/pdf/1611.03530.pdf">https://arxiv.org/pdf/1611.03530.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Sharp Minima Can Generalize for Deep Nets</p>

            <ol>
              <li><a href="https://arxiv.org/pdf/1703.04933.pdf">https://arxiv.org/pdf/1703.04933.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>On the Expressive Power of Deep Neural Networks</p>

            <ol>
              <li><a href="https://arxiv.org/pdf/1606.05336.pdf">https://arxiv.org/pdf/1606.05336.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Nonlinear Random Matrix Theory for Deep Learning</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46342.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46342.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Mean Field Residual Networks: On the Edge of Chaos</p>

            <ol>
              <li><a href="http://papers.nips.cc/paper/6879-mean-field-residual-networks-on-the-edge-of-chaos.pdf">http://papers.nips.cc/paper/6879-mean-field-residual-networks-on-the-edge-of-chaos.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Identity Matters in Deep Learning</p>

            <ol>
              <li><a href="https://arxiv.org/pdf/1611.04231.pdf">https://arxiv.org/pdf/1611.04231.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Geometry of Neural Network Loss Surfaces via Random Matrix Theory</p>

            <ol>
              <li><a href="http://proceedings.mlr.press/v70/pennington17a/pennington17a.pdf">http://proceedings.mlr.press/v70/pennington17a/pennington17a.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Explaining the Learning Dynamics of Direct Feedback Alignment</p>

            <ol>
              <li><a href="https://openreview.net/pdf?id=HkXKUTVFl">https://openreview.net/pdf?id=HkXKUTVFl</a></li>
            </ol>
          </li>
          <li>
            <p>Deep Information Propagation</p>

            <ol>
              <li><a href="https://openreview.net/pdf?id=H1W1UN9gg">https://openreview.net/pdf?id=H1W1UN9gg</a></li>
            </ol>
          </li>
          <li>
            <p>The Emergence of Spectral Universality in Deep Networks</p>

            <ol>
              <li><a href="https://arxiv.org/pdf/1802.09979.pdf">https://arxiv.org/pdf/1802.09979.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Sensitivity and Generalization in Neural Networks: An Empirical Study</p>

            <ol>
              <li><a href="https://arxiv.org/pdf/1802.08760.pdf">https://arxiv.org/pdf/1802.08760.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Gradient Descent with identity initialization efficiently learns positive definite linear transformations by deep residual networks</p>

            <ol>
              <li><a href="https://arxiv.org/pdf/1802.06093.pdf">https://arxiv.org/pdf/1802.06093.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Deep Neural Networks as Gaussian Processes</p>

            <ol>
              <li><a href="https://openreview.net/pdf?id=B1EA-M-0Z">https://openreview.net/pdf?id=B1EA-M-0Z</a></li>
            </ol>
          </li>
          <li>
            <p>A Bayesian Perspective on Generalization and Stochastic Gradient Descent</p>

            <ol>
              <li><a href="https://openreview.net/pdf?id=BJij4yg0Z">https://openreview.net/pdf?id=BJij4yg0Z</a></li>
            </ol>
          </li>
        </ol>
      </li>
      <li>
        <p>Regularization</p>

        <ol>
          <li>
            <p>Adding Gradient Noise Improves Learning for Very Deep Networks</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45137.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45137.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Surprising Properties of Dropout in Deep Networks</p>

            <ol>
              <li><a href="http://www.phillong.info/publications/HL17_deep_dropout.pdf">http://www.phillong.info/publications/HL17_deep_dropout.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Regularizing Neural Networks by Penalizing Confident Output Distributions</p>

            <ol>
              <li><a href="https://arxiv.org/pdf/1701.06548.pdf">https://arxiv.org/pdf/1701.06548.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>A Unified Approach to Adaptive Regularization in Online and Stochastic Optimization</p>

            <ol>
              <li>https://arxiv.org/pdf/1706.06569.pdf</li>
            </ol>
          </li>
        </ol>
      </li>
      <li>
        <p>Training Highly Multiclass Classifiers</p>

        <ol>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41872.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41872.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Random Walk Initialization for Training Very Deep Feedforward Networks</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1412.6558.pdf">https://arxiv.org/pdf/1412.6558.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Learning Factored Representations in a Deep Mixture of Experts</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1312.4314.pdf">https://arxiv.org/pdf/1312.4314.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Training Deep Neural Networks on Noisy Labels with Bootstrapping</p>

        <ol>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43273.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43273.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Convolutional, Long Short-Term Memory, Fully Connected Deep Neural Networks</p>

        <ol>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43455.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43455.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Reward Augmented Maximum Likelihood for Neural Structured Prediction</p>

        <ol>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45580.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45580.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>MuProp: Unbiased Backpropagation for Stochastic Neural Networks</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1511.05176v3.pdf">https://arxiv.org/pdf/1511.05176v3.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Chained predictions using convolutional neural networks</p>

        <ol>
          <li><a href="https://research.google.com/pubs/pub45945.html">https://research.google.com/pubs/pub45945.html</a></li>
        </ol>
      </li>
      <li>
        <p>Training a Subsampling Mechanism in Expectation</p>

        <ol>
          <li><a href="https://openreview.net/pdf?id=BJBkkaNYe">https://openreview.net/pdf?id=BJBkkaNYe</a></li>
        </ol>
      </li>
      <li>
        <p>Resurrecting the Sigmoid in deep learning through dynamical isometry: theory and practice</p>

        <ol>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46341.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46341.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer</p>

        <ol>
          <li><a href="https://openreview.net/pdf?id=B1ckMDqlg">https://openreview.net/pdf?id=B1ckMDqlg</a></li>
        </ol>
      </li>
      <li>
        <p>On Blackbox Backpropagation and Jacobian Sensing</p>

        <ol>
          <li><a href="https://research.google.com/pubs/pub46347.html">https://research.google.com/pubs/pub46347.html</a></li>
        </ol>
      </li>
      <li>
        <p>Deep Value Networks Learn to Evaluate and Iteratively Refine Structured Outputs</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1703.04363.pdf">https://arxiv.org/pdf/1703.04363.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Critical Hyper-Parameters: No Random, No Cry</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1706.03200.pdf">https://arxiv.org/pdf/1706.03200.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Distilling a Neural Network into a Soft Decision Tree</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1711.09784.pdf">https://arxiv.org/pdf/1711.09784.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Categorical Reparameterization with Gumbel-Softmax</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1611.01144.pdf">https://arxiv.org/pdf/1611.01144.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Training Confidence-Calibrated Classifiers For Detecting Out-of-Distribution Samples</p>

        <ol>
          <li><a href="https://openreview.net/pdf?id=ryiAv2xAZ">https://openreview.net/pdf?id=ryiAv2xAZ</a></li>
        </ol>
      </li>
      <li>
        <p>Fidelity-Weighted Learning</p>

        <ol>
          <li><a href="https://openreview.net/pdf?id=B1X0mzZCW">https://openreview.net/pdf?id=B1X0mzZCW</a></li>
        </ol>
      </li>
      <li>
        <p>Don’t Decay the Learning Rate, Increase the Batch Size</p>

        <ol>
          <li>https://openreview.net/pdf?id=B1Yy1BxCZ</li>
        </ol>
      </li>
    </ol>
  </li>
  <li>
    <p>Applications</p>

    <ol>
      <li>
        <p>Speech Recognition</p>

        <ol>
          <li>
            <p>Deep Neural Networks for Acoustic Modeling in Speech Recognition</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/38131.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/38131.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Application of Pre-trained Deep Neural Networks to Large Vocabulary Speech Recognition</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/38130.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/38130.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>On Rectified Linear Units for Speech Processing</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40811.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40811.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Multilingual Acoustic Models Using Distributed Deep Neural Networks</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40807.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40807.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>An Empirical Study of Learning Rates in DNNs for Speech Recognition</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40808.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40808.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Word Embeddings for Speech Recognition</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42543.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42543.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Autoregressive product of multi-frame predictions can improve the accuracy of hybrid models</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42947.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42947.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Learning the Speech Front-end with Raw Waveform CLDNNs</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43960.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43960.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Acoustic Modeling for Google Home</p>

            <ol>
              <li><a href="http://www.cs.cmu.edu/~chanwook/MyPapers/b_li_interspeech_2017.pdf">http://www.cs.cmu.edu/~chanwook/MyPapers/b_li_interspeech_2017.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Multilingual Speech Recognition With a Single End-to-End Model</p>

            <ol>
              <li><a href="https://arxiv.org/pdf/1711.01694.pdf">https://arxiv.org/pdf/1711.01694.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>An Analysis of Incorporating an External Language Model into a Sequence-to-Sequence Model</p>

            <ol>
              <li>https://arxiv.org/pdf/1712.01996.pdf</li>
            </ol>
          </li>
        </ol>
      </li>
      <li>
        <p>Image Classification</p>

        <ol>
          <li>
            <p>Using Web Co-occurrence Statistics for Improving Image Categorization</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42244.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42244.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>The Unreasonable Effectiveness of Noisy Data for Fine-Grained Recognition</p>

            <ol>
              <li><a href="https://arxiv.org/pdf/1511.06789.pdf">https://arxiv.org/pdf/1511.06789.pdf</a></li>
            </ol>
          </li>
        </ol>
      </li>
      <li>
        <p>Image Captioning</p>

        <ol>
          <li>
            <p>Grounded Compositional Semantics for Finding and Describing Images with Sentences</p>

            <ol>
              <li><a href="https://nlp.stanford.edu/~socherr/SocherKarpathyLeManningNg_TACL2013.pdf">https://nlp.stanford.edu/~socherr/SocherKarpathyLeManningNg_TACL2013.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Show and Tell: A Neural Image Caption Generator</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43274.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43274.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Learning Semantic Relationships for Better Action Retrieval in Images</p>

            <ol>
              <li>https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43443.pdf</li>
            </ol>
          </li>
        </ol>
      </li>
      <li>
        <p>Machine Translation</p>

        <ol>
          <li>
            <p>Exploiting Similarities among Languages for Machine Translation</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44931.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44931.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Addressing the Rare Word Problem in Neural Machine Translation</p>

            <ol>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44929.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44929.pdf</a></li>
            </ol>
          </li>
          <li>
            <p>Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation</p>
          </li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>81. [https://arxiv.org/abs/1609.08144](https://arxiv.org/abs/1609.08144)
</code></pre></div>        </div>

        <ol>
          <li>Sequence-to-Sequence Models Can Directly Translate Foreign Speech</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>82. [https://arxiv.org/pdf/1703.08581.pdf](https://arxiv.org/pdf/1703.08581.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Massive Exploration of Neural Machine Translation Architectures</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>83. https://arxiv.org/pdf/1703.03906.pdf
</code></pre></div>        </div>
      </li>
      <li>
        <p>Natural Language Understanding</p>

        <ol>
          <li>Efficient Estimation of Word Representations in Vector Space</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>84. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41224.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41224.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Distributed Representations of Words and Their Compositionality</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>85. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44876.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44876.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Zero-Shot Learning by Convex Combination of Semantic Embeddings</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>86. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42371.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42371.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Distributed Representations of Sentences and Documents</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>87. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44930.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44930.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Sentence Compression by Deletion with LSTMs</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>88. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43852.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43852.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Grammar as a Foreign Language</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>89. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43799.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43799.pdf)
</code></pre></div>        </div>

        <ol>
          <li>BilBOWA: Fast Bilingual Distributed Representations without Word Alignments</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>90. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45190.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45190.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Multilingual Language Processing From Bytes</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>91. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45170.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45170.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Exploring the Limits of Language Modeling</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>92. [https://arxiv.org/pdf/1602.02410.pdf](https://arxiv.org/pdf/1602.02410.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Towards better decoding and language model integration in sequence to sequence models</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>93. [https://arxiv.org/pdf/1612.02695.pdf](https://arxiv.org/pdf/1612.02695.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Learning to Skim Text</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>94. [https://arxiv.org/pdf/1704.06877.pdf](https://arxiv.org/pdf/1704.06877.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Get To The Point: Summarization with Pointer-Generator Networks</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>95. [https://arxiv.org/pdf/1704.04368.pdf](https://arxiv.org/pdf/1704.04368.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Generating Wikipedia by Summarizing Long Sequences</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>96. [https://openreview.net/pdf?id=Hyg0vbWC-](https://openreview.net/pdf?id=Hyg0vbWC-)
</code></pre></div>        </div>

        <ol>
          <li>An Efficient Framework for Learning Sentence Representations</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>97. https://openreview.net/pdf?id=rJvJXZb0W
</code></pre></div>        </div>
      </li>
      <li>
        <p>Multi-Modal</p>

        <ol>
          <li>DeViSE: A Deep Visual-Semantic Embedding Model</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>98. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41869.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41869.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Modulating Early Visual Processing by Language</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>99. [https://arxiv.org/pdf/1707.00683.pdf](https://arxiv.org/pdf/1707.00683.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Context-aware Captions from Context-agnostic Supervision</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100. [http://openaccess.thecvf.com/content_cvpr_2017/papers/Vedantam_Context-Aware_Captions_From_CVPR_2017_paper.pdf](http://openaccess.thecvf.com/content_cvpr_2017/papers/Vedantam_Context-Aware_Captions_From_CVPR_2017_paper.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Better Text Understanding Through Image-To-Text Transfer</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>101. https://arxiv.org/pdf/1705.08386.pdf
</code></pre></div>        </div>
      </li>
      <li>
        <p>Pedestrian Detection</p>

        <ol>
          <li>Real Time Pedestrian Detection with Deep Network Cascades</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>102. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43850.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43850.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Pedestrian Detection with a Large Field-Of-View Deep Network</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>103. https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43849.pdf
</code></pre></div>        </div>
      </li>
      <li>
        <p>Grasp Detection</p>

        <ol>
          <li>Real-Time Grasp Detection Using Convolutional Neural Networks</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>104. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43875.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43875.pdf)
</code></pre></div>        </div>
      </li>
      <li>
        <p>Go</p>

        <ol>
          <li>Move Evaluation in Go Using Deep Convolutional Neural Networks</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>105. [https://arxiv.org/pdf/1412.6564.pdf](https://arxiv.org/pdf/1412.6564.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Mastering the game of Go with deep neural networks and tree search</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>106. https://www.nature.com/articles/nature16961
</code></pre></div>        </div>
      </li>
      <li>
        <p>Video</p>

        <ol>
          <li>Beyond Short Snippets: Deep Networks for Video Classification</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>107. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43793.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43793.pdf)
</code></pre></div>        </div>
      </li>
      <li>
        <p>Dialogue</p>

        <ol>
          <li>A Neural Conversational Model</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>108. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44925.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44925.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Smart Reply: Automated Response Suggestion for Email</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>109. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45189.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45189.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Adversarial Evaluation of Dialogue Models</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>110. [https://arxiv.org/pdf/1701.08198.pdf](https://arxiv.org/pdf/1701.08198.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Generating High-Quality and Informative Conversation Responses with Sequence-to-Sequence Models</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>111. https://arxiv.org/pdf/1701.03185.pdf
</code></pre></div>        </div>
      </li>
      <li>
        <p>3D Object Reconstruction</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1612.00814.pdf">https://arxiv.org/pdf/1612.00814.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Speaker Verification</p>

        <ol>
          <li>End-to-End Text-Dependent Speaker Verification</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>112. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44681.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44681.pdf)
</code></pre></div>        </div>
      </li>
      <li>
        <p>Health Care</p>

        <ol>
          <li>Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>113. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45732.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45732.pdf)
</code></pre></div>        </div>
      </li>
      <li>
        <p>Theorem Proving</p>

        <ol>
          <li>DeepMath - Deep Sequence Models for Premise Selection</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>114. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45402.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45402.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Deep Network Guided Proof Search</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>115. https://arxiv.org/pdf/1701.06972.pdf
</code></pre></div>        </div>
      </li>
      <li>
        <p>Music</p>

        <ol>
          <li>Audio Deepdream: Optimizing Raw Audio with Convolutional Networks</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>116. https://18798-presscdn-pagely.netdna-ssl.com/ismir2016/wp-content/uploads/sites/2294/2016/08/ardila-audio.pdf
</code></pre></div>        </div>

        <ol>
          <li>Generating Music by Fine-Tuning Recurrent Neural Networks with Reinforcement Learning</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>117. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45871.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45871.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>118. https://arxiv.org/pdf/1704.01279.pdf
</code></pre></div>        </div>
      </li>
      <li>
        <p>Pose Estimation</p>

        <ol>
          <li>Towards Accurate Multi-person Pose Estimation in the Wild</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>119. [https://arxiv.org/pdf/1701.01779.pdf](https://arxiv.org/pdf/1701.01779.pdf)
</code></pre></div>        </div>
      </li>
      <li>
        <p>Speech Generation</p>

        <ol>
          <li>Tacotron: Towards End-to-End Speech Synthesis</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>120. [https://arxiv.org/pdf/1703.10135.pdf](https://arxiv.org/pdf/1703.10135.pdf)
</code></pre></div>        </div>

        <ol>
          <li>RNN Approaches to Text Normalization: A Challenge</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>121. [https://arxiv.org/pdf/1611.00068.pdf](https://arxiv.org/pdf/1611.00068.pdf)
</code></pre></div>        </div>

        <ol>
          <li>On Using Backpropagation for Speech texture Generation and Voice Cnversion</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>122. [https://arxiv.org/pdf/1712.08363.pdf](https://arxiv.org/pdf/1712.08363.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Natural TTS Synthesis by Conditioning Wavenet on Mel Spectrogram Prediction [Tacotron 2]</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>123. https://arxiv.org/pdf/1712.05884.pdf
</code></pre></div>        </div>
      </li>
      <li>
        <p>Super Resolution</p>

        <ol>
          <li>Pixel Recursive Super Resolution</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>124. [https://arxiv.org/pdf/1702.00783.pdf](https://arxiv.org/pdf/1702.00783.pdf)
</code></pre></div>        </div>
      </li>
      <li>
        <p>Chemistry</p>

        <ol>
          <li>Neural Message Passing for Quantum Chemistry</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>125. [https://arxiv.org/pdf/1704.01212.pdf](https://arxiv.org/pdf/1704.01212.pdf)
</code></pre></div>        </div>
      </li>
      <li>
        <p>Robotics</p>

        <ol>
          <li>Autonomous Vehicles</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>126. Learning with Proxy Supervision for End-To-End Visual Learning

    1. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45985.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45985.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Learning Robotic Manipulation of Granular Media</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>127. [https://arxiv.org/pdf/1709.02833.pdf](https://arxiv.org/pdf/1709.02833.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>128. [https://drive.google.com/file/d/0B0mFoBMu8f8BaHYzOXZMdzVOalU/view](https://drive.google.com/file/d/0B0mFoBMu8f8BaHYzOXZMdzVOalU/view)
</code></pre></div>        </div>

        <ol>
          <li>End-to-End Learning of Semantic Grasping</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>129. [https://arxiv.org/pdf/1707.01932.pdf](https://arxiv.org/pdf/1707.01932.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Cognitive Mapping and Planning for Visual Navigation</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>130. [https://arxiv.org/pdf/1702.03920.pdf](https://arxiv.org/pdf/1702.03920.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>131. https://arxiv.org/pdf/1709.07857.pdf
</code></pre></div>        </div>
      </li>
      <li>
        <p>Physics</p>

        <ol>
          <li>Accelerating Eulerian Fluid Simulation with Convolutional Networks</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>132. [https://arxiv.org/pdf/1607.03597.pdf](https://arxiv.org/pdf/1607.03597.pdf)
</code></pre></div>        </div>
      </li>
      <li>
        <p>Device Placement</p>

        <ol>
          <li>Device Placement Optimization with Reinforcement Learning</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>133. [https://arxiv.org/pdf/1706.04972.pdf](https://arxiv.org/pdf/1706.04972.pdf)
</code></pre></div>        </div>

        <ol>
          <li>A Hierarchical Model for Device Placement</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>134. [https://openreview.net/pdf?id=Hkc-TeZ0W](https://openreview.net/pdf?id=Hkc-TeZ0W)
</code></pre></div>        </div>
      </li>
      <li>
        <p>Games</p>

        <ol>
          <li>Can Deep Reinforcement Learning Solve Erdos-Selfridge-Spencer Games?</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>135. [https://arxiv.org/pdf/1711.02301.pdf](https://arxiv.org/pdf/1711.02301.pdf)
</code></pre></div>        </div>
      </li>
      <li>
        <p>Art</p>

        <ol>
          <li>A Neural Representation of Sketch Drawings</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>136. https://arxiv.org/pdf/1704.03477.pdf
</code></pre></div>        </div>
      </li>
    </ol>
  </li>
  <li>
    <p>Unsupervised Learning</p>

    <ol>
      <li>
        <p>Building High-level Features Using Large Scale Unsupervised Learning</p>

        <ol>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/38115.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/38115.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Towards Principled Unsupervised Learning</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1511.06440.pdf">https://arxiv.org/pdf/1511.06440.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Time-Contrastive Networks: Self-Supervised Learning from Video</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1704.06888.pdf">https://arxiv.org/pdf/1704.06888.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Stochastic Variational Video prediction [Also, Model-Based RL]</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1710.11252.pdf">https://arxiv.org/pdf/1710.11252.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Short and Deep: Sketching Neural Networks</p>

        <ol>
          <li><a href="https://openreview.net/pdf?id=r1br_2Kge">https://openreview.net/pdf?id=r1br_2Kge</a></li>
        </ol>
      </li>
      <li>
        <p>Geometry-Based Next Frame Prediction from Monocular Video</p>

        <ol>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45984.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45984.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Decomposing Motion and Content for Natural Video Sequence Prediction</p>

        <ol>
          <li><a href="https://sites.google.com/a/umich.edu/rubenevillegas/iclr2017">https://sites.google.com/a/umich.edu/rubenevillegas/iclr2017</a></li>
        </ol>
      </li>
      <li>
        <p>Cross-View Training for Semi-Supervised Learning</p>

        <ol>
          <li>https://openreview.net/forum?id=BJubPWZRW</li>
        </ol>
      </li>
    </ol>
  </li>
  <li>
    <p>Attention</p>

    <ol>
      <li>
        <p>On Learning Where to Look</p>

        <ol>
          <li><a href="https://research.google.com/pubs/pub45477.html">https://research.google.com/pubs/pub45477.html</a></li>
        </ol>
      </li>
      <li>
        <p>Pointer Networks</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1506.03134.pdf">https://arxiv.org/pdf/1506.03134.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Attention for Fine-Grained Categorization</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1412.7054.pdf">https://arxiv.org/pdf/1412.7054.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Listen, Attend and Spell</p>

        <ol>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44926.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44926.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Collective Entity Resolution with Multi-Focal Attention</p>

        <ol>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45395.pdf">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45395.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Attend, Infer, Repeat: Fast Scene Understanding with Generative Models</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1603.08575.pdf">https://arxiv.org/pdf/1603.08575.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Online and Linear-Time Attention by Enforcing Monotonic Alignments</p>

        <ol>
          <li><a href="https://research.google.com/pubs/pub46110.html">https://research.google.com/pubs/pub46110.html</a></li>
        </ol>
      </li>
      <li>
        <p>Learning Hard Alignments with Variational Inference [Hard Attention]</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1705.05524.pdf">https://arxiv.org/pdf/1705.05524.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Efficient Attention using a Fixed-Size Memory Representation</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1707.00110.pdf">https://arxiv.org/pdf/1707.00110.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Attention is All You Need</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1706.03762.pdf">https://arxiv.org/pdf/1706.03762.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>An Analysis of “Attention” in Sequence-to-Sequence Models</p>

        <ol>
          <li><a href="http://www.isca-speech.org/archive/Interspeech_2017/pdfs/0232.PDF">http://www.isca-speech.org/archive/Interspeech_2017/pdfs/0232.PDF</a></li>
        </ol>
      </li>
      <li>
        <p>Monotonic Chunkwise Attention</p>

        <ol>
          <li>https://openreview.net/pdf?id=Hko85plCW</li>
        </ol>
      </li>
    </ol>
  </li>
  <li>
    <p>Memory</p>

    <ol>
      <li>
        <p>Learning to Remember Rare Events</p>

        <ol>
          <li>https://openreview.net/pdf?id=SJTQLdqlg</li>
        </ol>
      </li>
    </ol>
  </li>
  <li>
    <p>Transfer Learning</p>

    <ol>
      <li>
        <p>Net2Net: Accelerating Learning via Knowledge Transfer</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1511.05641.pdf">https://arxiv.org/pdf/1511.05641.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Domain Separation Networks</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1608.06019.pdf">https://arxiv.org/pdf/1608.06019.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Unsupervised Pixel-Level Domain Adaptation with Generative Adversarial Networks</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1612.05424.pdf">https://arxiv.org/pdf/1612.05424.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>PathNet: Evolution Channels Gradient Descent in Super Neural networks</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1701.08734.pdf">https://arxiv.org/pdf/1701.08734.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>One Model to Learn Them All</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1706.05137.pdf">https://arxiv.org/pdf/1706.05137.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Exploring the structure of a real-time, arbitrary neural artistic stylization network</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1705.06830.pdf">https://arxiv.org/pdf/1705.06830.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>A Brief Study of In-Domain Transfer and Learning from Fewer Samples using a Few Simple Priors</p>

        <ol>
          <li>https://arxiv.org/pdf/1707.03979.pdf</li>
        </ol>
      </li>
    </ol>
  </li>
  <li>
    <p>Representation Learning</p>

    <ol>
      <li>
        <p>SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1706.05806.pdf">https://arxiv.org/pdf/1706.05806.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>A Learned Representation for Artistic Style</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1610.07629.pdf">https://arxiv.org/pdf/1610.07629.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Learning Latent Permutations with Gumbel-Sinkhorn Networks</p>

        <ol>
          <li>https://openreview.net/pdf?id=Byt3oJ-0W</li>
        </ol>
      </li>
    </ol>
  </li>
  <li>
    <p>Reinforcement Learning</p>

    <ol>
      <li>
        <p>Model-Based Reinforcement Learning</p>

        <ol>
          <li>Unsupervised Learning for Physical Interaction through Video Prediction [Also, Robotics]</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>137. [https://arxiv.org/pdf/1605.07157.pdf](https://arxiv.org/pdf/1605.07157.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Continuous Deep Q-Learning with Model-based Acceleration</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>138. [http://proceedings.mlr.press/v48/gu16.pdf](http://proceedings.mlr.press/v48/gu16.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Value Prediction Network</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>139. [https://arxiv.org/pdf/1707.03497.pdf](https://arxiv.org/pdf/1707.03497.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Learning to Generate Long-term Future via Hierarchical Prediction</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>140. [https://arxiv.org/pdf/1704.05831.pdf](https://arxiv.org/pdf/1704.05831.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Discrete Sequential Prediction of Continuous Actions for Deep RL</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>141. [https://arxiv.org/pdf/1705.05035.pdf](https://arxiv.org/pdf/1705.05035.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Deep Visual Foresight for Planning Robot Motion [Also, Robotics]</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>142. [https://arxiv.org/pdf/1610.00696.pdf](https://arxiv.org/pdf/1610.00696.pdf)
</code></pre></div>        </div>

        <ol>
          <li>Temporal Difference Models: Model-Free Deep RL for Model-Based Control</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>143. [https://openreview.net/pdf?id=Skw0n-W0Z](https://openreview.net/pdf?id=Skw0n-W0Z)
</code></pre></div>        </div>
      </li>
      <li>
        <p>Multi-Task Learning</p>

        <ol>
          <li>Zero-Shot Task Generalization with Multi-Task Deep Reinforcement Learning</li>
        </ol>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>144. [https://arxiv.org/pdf/1706.05064.pdf](https://arxiv.org/pdf/1706.05064.pdf)
</code></pre></div>        </div>
      </li>
      <li>
        <p>Unsupervised Perceptual Rewards for Imitation Learning</p>

        <ol>
          <li><a href="https://openreview.net/pdf?id=Byf3mmNFl">https://openreview.net/pdf?id=Byf3mmNFl</a></li>
        </ol>
      </li>
      <li>
        <p>Trust-PCL: An Off-Policy Trust Region Method for Continuous Control</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1707.01891.pdf">https://arxiv.org/pdf/1707.01891.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Robust Adversarial Reinforcement Learning [Also, Multi-Agent Systems]</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1703.02702.pdf">https://arxiv.org/pdf/1703.02702.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>REBAR: Low-Variance, unbiased gradient estimates for discrete latent variable models</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1703.07370.pdf">https://arxiv.org/pdf/1703.07370.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Q-Prop: Sample Efficient Policy Gradient with an Off-Policy Critic</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1611.02247.pdf">https://arxiv.org/pdf/1611.02247.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Particle Value Functions</p>

        <ol>
          <li><a href="https://openreview.net/pdf?id=BJyBKyHKg">https://openreview.net/pdf?id=BJyBKyHKg</a></li>
        </ol>
      </li>
      <li>
        <p>Path Integral Guided Policy Search [Also, Robotics]</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1610.00529.pdf">https://arxiv.org/pdf/1610.00529.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Interpolated Policy Gradient: Merging On-Policy and Off-Policy Gradient Estimation for Deep Reinforcement Learning</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1706.00387.pdf">https://arxiv.org/pdf/1706.00387.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Improving Policy Gradient by Exploring Under-Appreciated Rewards</p>

        <ol>
          <li><a href="https://openreview.net/pdf?id=ryT4pvqll">https://openreview.net/pdf?id=ryT4pvqll</a></li>
        </ol>
      </li>
      <li>
        <p>Deep Reinforcement Learning for Robotic Manipulation with Asynchronous Off-Policy Updates</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1610.00633.pdf">https://arxiv.org/pdf/1610.00633.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Collective Robot Reinforcement Learning with Distributed Asynchronous Guided Policy Search</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1610.00673.pdf">https://arxiv.org/pdf/1610.00673.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Changing Model Behavior at Test Time Using Reinforcement Learning</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1702.07780.pdf">https://arxiv.org/pdf/1702.07780.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Bridging the Gap Between Value and Policy Based Reinforcement Learning</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1702.08892.pdf">https://arxiv.org/pdf/1702.08892.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>A comparative study of counterfactual estimators</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1704.00773.pdf">https://arxiv.org/pdf/1704.00773.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>PRM-RL: Long Range Robotic Navigatio nTasks by Combining Reinforcement Learning and Sampling-based Planning</p>

        <ol>
          <li><a href="https://arxiv.org/pdf/1710.03937.pdf">https://arxiv.org/pdf/1710.03937.pdf</a></li>
        </ol>
      </li>
      <li>
        <p>Path consistency Learning in Tsallis Entropy Regularized MDPs</p>

        <ol>
          <li><a href="https://arxiv.org/abs/1802.03501">https://arxiv.org/abs/1802.03501</a></li>
        </ol>
      </li>
      <li>
        <p>Leave No Trace: Learning to Reset for Safe and Autonomous Reinforcement Learning</p>
      </li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> 212. [https://openreview.net/pdf?id=S1vuO-bCW](https://openreview.net/pdf?id=S1vuO-bCW)
</code></pre></div>    </div>

    <ol>
      <li>Deep Bayesian Bandits Showdown</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> 213. https://openreview.net/pdf?id=SyYe6k-CW
</code></pre></div>    </div>
  </li>
  <li>
    <p>Metalearning</p>

    <ol>
      <li>Neural Programming</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> 214. Reinforcement Learning Neural Turing Machines

     145. [https://research.google.com/pubs/pub45478.html](https://research.google.com/pubs/pub45478.html)

 215. Neural Random-Access Machines

     146. [https://research.google.com/pubs/pub45472.html](https://research.google.com/pubs/pub45472.html)

 216. Neural Programmer: Inducing Latent Programs with Gradient Descent

     147. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44927.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44927.pdf)

 217. Neural GPUs Learn Algorithms

     148. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45139.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45139.pdf)

 218. Learning a Natural Language Interface with Neural Programmer

     149. https://arxiv.org/pdf/1611.08945.pdf
</code></pre></div>    </div>

    <ol>
      <li>Hyperparameter Optimization</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> 219. Toward Optimal Run Racing: Application to Deep Learning Calibration

     150. [https://arxiv.org/pdf/1706.03199.pdf](https://arxiv.org/pdf/1706.03199.pdf)

 220. Searching for Activation Functions

     151. [https://arxiv.org/pdf/1710.05941.pdf](https://arxiv.org/pdf/1710.05941.pdf)

 221. Neural Optimizer Search with Reinforcement Learning

     152. [https://arxiv.org/pdf/1709.07417.pdf](https://arxiv.org/pdf/1709.07417.pdf)

 222. Neural Combinatorial Optimization with Reinforcement Learning

     153. [https://openreview.net/pdf?id=Bk9mxlSFx](https://openreview.net/pdf?id=Bk9mxlSFx)

 223. Neural Architecture Search with Reinforcement Learning

     154. [https://arxiv.org/pdf/1611.01578.pdf](https://arxiv.org/pdf/1611.01578.pdf)

 224. Large-Scale Evolution of Image Classifiers

     155. [https://arxiv.org/pdf/1703.01041.pdf](https://arxiv.org/pdf/1703.01041.pdf)

 225. Searching for Activation Functions

     156. https://arxiv.org/pdf/1710.05941.pdf
</code></pre></div>    </div>

    <ol>
      <li>Learned Optimizers that Scale and Generalize</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> 226. [https://arxiv.org/pdf/1703.04813.pdf](https://arxiv.org/pdf/1703.04813.pdf)
</code></pre></div>    </div>

    <ol>
      <li>HyperNetworks</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> 227. [https://openreview.net/pdf?id=rkpACe1lx](https://openreview.net/pdf?id=rkpACe1lx)
</code></pre></div>    </div>

    <ol>
      <li>Supervised Learning of Unsupervised Learning Rules</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> 228. [http://metalearning.ml/papers/metalearn17_metz.pdf](http://metalearning.ml/papers/metalearn17_metz.pdf)
</code></pre></div>    </div>

    <ol>
      <li>MorphNet: Fast &amp; Simple Resource-Constrained Structure Learning of Deep Networks</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> 229. [https://arxiv.org/pdf/1711.06798.pdf](https://arxiv.org/pdf/1711.06798.pdf)
</code></pre></div>    </div>

    <ol>
      <li>A Meta-Learning Perspective on Cold-Start Recommendations for Items</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> 230. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46346.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46346.pdf)
</code></pre></div>    </div>

    <ol>
      <li>Meta-Learning for Semi-Supervised Few-Shot Classification</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> 231. [https://openreview.net/pdf?id=HJcSzz-CZ](https://openreview.net/pdf?id=HJcSzz-CZ)
</code></pre></div>    </div>

    <ol>
      <li>Generalizing Hamiltonian Monte Carlo with Neural Networks</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> 232. https://openreview.net/pdf?id=B1n8LexRZ
</code></pre></div>    </div>
  </li>
  <li>
    <p>Generative</p>

    <ol>
      <li>GANs</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>233. Improved Generator Objectives for GANs

    157. [https://arxiv.org/pdf/1612.02780.pdf](https://arxiv.org/pdf/1612.02780.pdf)

234. Unrolled Generative Adversarial Networks

    158. [https://openreview.net/pdf?id=BydrOIcle](https://openreview.net/pdf?id=BydrOIcle)

235. Improving Image Generative Models with Human Interactions

    159. [https://arxiv.org/pdf/1709.10459.pdf](https://arxiv.org/pdf/1709.10459.pdf)

236. Conditional Image Synthesis with Auxiliary Classifier GANs

    160. [https://arxiv.org/pdf/1610.09585.pdf](https://arxiv.org/pdf/1610.09585.pdf)

237. Are GANs Created Equal? A Large-Scale Study

    161. [https://arxiv.org/pdf/1711.10337.pdf](https://arxiv.org/pdf/1711.10337.pdf)

238. AdaGAN: Boosting Generative Models

    162. [https://arxiv.org/pdf/1701.02386.pdf](https://arxiv.org/pdf/1701.02386.pdf)

239. MaskGAN: Better Text Generation Via Filling in the _____

    163. [https://openreview.net/pdf?id=ByOExmWAb](https://openreview.net/pdf?id=ByOExmWAb)

240. Many Paths to Equilibrium: GANs Do Not Need to Decrease a Divergence at Every Step

    164. https://openreview.net/pdf?id=ByQpn1ZA-
</code></pre></div>    </div>

    <ol>
      <li>Experiments in Handwriting with a Neural Network</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>241. [https://distill.pub/2016/handwriting/](https://distill.pub/2016/handwriting/)
</code></pre></div>    </div>

    <ol>
      <li>From optimal transport to generative modeling: the VEGAN cookbook</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>242. [https://arxiv.org/pdf/1705.07642.pdf](https://arxiv.org/pdf/1705.07642.pdf)
</code></pre></div>    </div>

    <ol>
      <li>Density Estimation Using Real NVP</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>243. [https://arxiv.org/pdf/1605.08803.pdf](https://arxiv.org/pdf/1605.08803.pdf)
</code></pre></div>    </div>

    <ol>
      <li>A Neural Representation of Sketch Drawings</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>244. [https://arxiv.org/pdf/1704.03477.pdf](https://arxiv.org/pdf/1704.03477.pdf)
</code></pre></div>    </div>

    <ol>
      <li>Wasserstein Auto-Encoders</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>245. [https://arxiv.org/pdf/1711.01558.pdf](https://arxiv.org/pdf/1711.01558.pdf)
</code></pre></div>    </div>

    <ol>
      <li>Stochastic Variational Video Prediction</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>246. [https://openreview.net/pdf?id=rk49Mg-CW](https://openreview.net/pdf?id=rk49Mg-CW)
</code></pre></div>    </div>

    <ol>
      <li>Latent Constraints: Learning to Generate Conditionally From Unconditional Generative Models</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>247. https://openreview.net/pdf?id=Sy8XvGb0-
</code></pre></div>    </div>
  </li>
  <li>
    <p>Interpretability</p>

    <ol>
      <li>Deconvolution and Checkerboard Artifacts</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>248. [https://distill.pub/2016/deconv-checkerboard/](https://distill.pub/2016/deconv-checkerboard/)
</code></pre></div>    </div>

    <ol>
      <li>Visualizing Dataflow Graphs of Deep Learning Models in Tensorflow</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>249. [http://idl.cs.washington.edu/files/2018-TensorFlowGraph-VAST.pdf](http://idl.cs.washington.edu/files/2018-TensorFlowGraph-VAST.pdf)
</code></pre></div>    </div>

    <ol>
      <li>Towards A Rigorous Science of Interpretable Machine Learning</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>250. [https://arxiv.org/pdf/1702.08608.pdf](https://arxiv.org/pdf/1702.08608.pdf)
</code></pre></div>    </div>

    <ol>
      <li>The (Un)reliability of Saliency Methods</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>251. [https://arxiv.org/pdf/1711.00867.pdf](https://arxiv.org/pdf/1711.00867.pdf)
</code></pre></div>    </div>

    <ol>
      <li>Input Switched Affine Networks: An RNN Architecture Designed for Interpretability [Also, Recurrent Neural Networks]</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>252. [https://arxiv.org/pdf/1611.09434.pdf](https://arxiv.org/pdf/1611.09434.pdf)
</code></pre></div>    </div>

    <ol>
      <li>VisualBackProp: Efficient Visualization of CNNs</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>253. [https://arxiv.org/abs/1611.05418](https://arxiv.org/abs/1611.05418)
</code></pre></div>    </div>

    <ol>
      <li>Learning How to Explain Neural Networks: PatternNet and PatternAttribution</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>254. [https://openreview.net/pdf?id=Hkn7CBaTW](https://openreview.net/pdf?id=Hkn7CBaTW)
</code></pre></div>    </div>

    <ol>
      <li>Beyond Word Importance: Contextual Decomposition to Extract Interactions from LSTMs [Also, Recurrent Neural Networks]</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>255. https://openreview.net/pdf?id=rkRwGg-0Z
</code></pre></div>    </div>
  </li>
  <li>
    <p>Tools, Environments &amp; Datasets</p>

    <ol>
      <li>One Billion Word Benchmark for Measuring Progress in Statistical Language Modeling</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>256. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41880.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41880.pdf)
</code></pre></div>    </div>
  </li>
  <li>
    <p>Adversarial Examples</p>

    <ol>
      <li>Intriguing Properties of Neural Networks</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>257. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42503.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42503.pdf)
</code></pre></div>    </div>

    <ol>
      <li>Explaining and Harnessing Adversarial Examples</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>258. [https://arxiv.org/pdf/1412.6572.pdf](https://arxiv.org/pdf/1412.6572.pdf)
</code></pre></div>    </div>

    <ol>
      <li>Virtual Adversarial Training for Semi-Supervised Text Classification</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>259. [https://research.google.com/pubs/pub45403.html](https://research.google.com/pubs/pub45403.html)
</code></pre></div>    </div>

    <ol>
      <li>The Space of Transferable Adversarial Examples</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>260. [https://arxiv.org/pdf/1704.03453.pdf](https://arxiv.org/pdf/1704.03453.pdf)
</code></pre></div>    </div>

    <ol>
      <li>Adversarial Examples in the Physical World</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>261. [https://arxiv.org/pdf/1607.02533.pdf](https://arxiv.org/pdf/1607.02533.pdf)
</code></pre></div>    </div>

    <ol>
      <li>Adversarial Training Methods for Semi-Supervised Text Classification</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>262. [https://arxiv.org/pdf/1605.07725.pdf](https://arxiv.org/pdf/1605.07725.pdf)
</code></pre></div>    </div>

    <ol>
      <li>Adversarial Machine Learning at Scale</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>263. [https://arxiv.org/pdf/1611.01236.pdf](https://arxiv.org/pdf/1611.01236.pdf)
</code></pre></div>    </div>

    <ol>
      <li>Thermometer Encoding: One Hot Way to Resist Adversarial Examples</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>264. [https://openreview.net/pdf?id=S18Su--CW](https://openreview.net/pdf?id=S18Su--CW)
</code></pre></div>    </div>

    <ol>
      <li>Intriguing Properties of Adversarial Examples</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>265. [https://arxiv.org/pdf/1711.02846.pdf](https://arxiv.org/pdf/1711.02846.pdf)
</code></pre></div>    </div>

    <ol>
      <li>Ensemble Adversarial Training: Attacks and Defences</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>266. [https://openreview.net/pdf?id=rkZvSe-RZ](https://openreview.net/pdf?id=rkZvSe-RZ)
</code></pre></div>    </div>

    <ol>
      <li>Adversarial Spheres</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>267. https://arxiv.org/pdf/1801.02774.pdf
</code></pre></div>    </div>
  </li>
  <li>
    <p>Multi-Agent Systems</p>

    <ol>
      <li>Learning to Protect Communications with Adversarial Neural Cryptography</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>268. [https://arxiv.org/pdf/1610.06918.pdf](https://arxiv.org/pdf/1610.06918.pdf)
</code></pre></div>    </div>

    <ol>
      <li>Adversarial Autoencoders</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>269. [https://arxiv.org/pdf/1511.05644.pdf](https://arxiv.org/pdf/1511.05644.pdf)
</code></pre></div>    </div>

    <ol>
      <li>XGAN: Unsupervised Image-To-Image Translation for Many-To-Many Mappings</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>270. [https://arxiv.org/pdf/1711.05139.pdf](https://arxiv.org/pdf/1711.05139.pdf)
</code></pre></div>    </div>

    <ol>
      <li>Supervision via Competition: Robot Adversaries for Learning Tasks</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>271. https://arxiv.org/pdf/1610.01685.pdf
</code></pre></div>    </div>
  </li>
  <li>
    <p>Variational Inference</p>

    <ol>
      <li>Variational Boosting: Iteratively Refining Posterior Approximations</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>272. [https://arxiv.org/pdf/1611.06585.pdf](https://arxiv.org/pdf/1611.06585.pdf)
</code></pre></div>    </div>

    <ol>
      <li>Reducing Reparameterization Gradient Variance</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>273. [https://arxiv.org/pdf/1705.07880.pdf](https://arxiv.org/pdf/1705.07880.pdf)
</code></pre></div>    </div>

    <ol>
      <li>Filtering Variational Objectives</li>
    </ol>
  </li>
  <li>
    <p>Kernel Machines</p>

    <ol>
      <li>Fastfood - Approximating Kernel Expansions in Loglinear Time</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>274. [http://www-cs.stanford.edu/~quocle/LeSarlosSmola_ICML13.pdf](http://www-cs.stanford.edu/~quocle/LeSarlosSmola_ICML13.pdf)
</code></pre></div>    </div>

    <ol>
      <li>Random Features for Compositional Kernels</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>275. [https://arxiv.org/pdf/1703.07872.pdf](https://arxiv.org/pdf/1703.07872.pdf)
</code></pre></div>    </div>

    <ol>
      <li>The Geometry of Random Features</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>276. http://storage.googleapis.com/pub-tools-public-publication-data/pdf/70a89b15f9b160dd10248de8862d1584f03ddc22.pdf
</code></pre></div>    </div>
  </li>
  <li>
    <p>Collaborative Filtering</p>

    <ol>
      <li>Local Collaborative Ranking</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>277. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42242.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42242.pdf)
</code></pre></div>    </div>
  </li>
  <li>
    <p>Graphical / Relational Learning</p>

    <ol>
      <li>Large-Scale Object Classification Using Label Relation Graphs</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>278. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42854.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42854.pdf)
</code></pre></div>    </div>

    <ol>
      <li>Graph Searching Games and Width Measures for Directed Graphs</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>279. [http://drops.dagstuhl.de/opus/volltexte/2015/4902/pdf/2.pdf](http://drops.dagstuhl.de/opus/volltexte/2015/4902/pdf/2.pdf)
</code></pre></div>    </div>

    <ol>
      <li>Graph Partition Neural Networks for Semi-Supervised Classification</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>280. https://arxiv.org/pdf/1803.06272.pdf
</code></pre></div>    </div>
  </li>
  <li>
    <p>Miscellaneous</p>

    <ol>
      <li>Tensorflow: Learning Functions at Scale</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>281. [https://dl.acm.org/citation.cfm?id=2976746](https://dl.acm.org/citation.cfm?id=2976746)
</code></pre></div>    </div>

    <ol>
      <li>Deep Learning Games</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>282. [https://papers.nips.cc/paper/6315-deep-learning-games.pdf](https://papers.nips.cc/paper/6315-deep-learning-games.pdf)
</code></pre></div>    </div>

    <ol>
      <li>Tangent: Automatic Differentiation Using Source Code Transformation in Python</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>283. [https://arxiv.org/pdf/1711.02712.pdf](https://arxiv.org/pdf/1711.02712.pdf)
</code></pre></div>    </div>

    <ol>
      <li>ExtDict: Extensible Dictionaries for Data and Platform-Aware Large Scale Learning</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>284. [http://www.aceslab.org/sites/default/files/main_0.pdf](http://www.aceslab.org/sites/default/files/main_0.pdf)
</code></pre></div>    </div>

    <ol>
      <li>Dynamic Routing between Capsules</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>285. [https://research.google.com/pubs/pub46351.html](https://research.google.com/pubs/pub46351.html)
</code></pre></div>    </div>

    <ol>
      <li>Climbing a Shaky Ladder: Better ADaptive Risk Estimation</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>286. [https://arxiv.org/pdf/1706.02733.pdf](https://arxiv.org/pdf/1706.02733.pdf)
</code></pre></div>    </div>

    <ol>
      <li>Avoiding Discrimination through Causal Reasoning</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>287. [https://arxiv.org/pdf/1706.02744.pdf](https://arxiv.org/pdf/1706.02744.pdf)
</code></pre></div>    </div>

    <ol>
      <li>Who Said What: Modeling Individual Labelers Improves Classification</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>288. [https://arxiv.org/pdf/1703.08774.pdf](https://arxiv.org/pdf/1703.08774.pdf)
</code></pre></div>    </div>

    <ol>
      <li>Matrix Capsules with EM Routing</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>289. [https://openreview.net/pdf?id=HJWLfGWRb](https://openreview.net/pdf?id=HJWLfGWRb)
</code></pre></div>    </div>

    <ol>
      <li>Graph sketching-based Space-efficient Data Clustering</li>
    </ol>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>290. http://storage.googleapis.com/pub-tools-public-publication-data/pdf/7174df3a5627e483b5d120d8edb5843fa593577e.pdf
</code></pre></div>    </div>
  </li>
</ol>

<p>Major Researchers [10+ Papers / Founding]</p>

<ul>
  <li>
    <p>Jeff Dean</p>
  </li>
  <li>
    <p>Samy Bengio</p>
  </li>
  <li>
    <p>Geoffrey Hinton</p>
  </li>
  <li>
    <p>Andrew Ng</p>
  </li>
  <li>
    <p>Quoc Le</p>
  </li>
  <li>
    <p>Greg Corrado</p>
  </li>
  <li>
    <p>Vincent Vanhoucke</p>
  </li>
  <li>
    <p>Yoran Singer</p>
  </li>
  <li>
    <p>Ian Goodfellow</p>
  </li>
  <li>
    <p>Tomas Mikolov</p>
  </li>
  <li>
    <p>Ilya Sutskever</p>
  </li>
  <li>
    <p>Oriol Vinyals</p>
  </li>
  <li>
    <p>Marc’ Aurelio Ranzato</p>
  </li>
  <li>
    <p>Christian Szegedy</p>
  </li>
  <li>
    <p>Navdeep Jaitly</p>
  </li>
  <li>
    <p>Mohammad Norouzi</p>
  </li>
  <li>
    <p>Lukasz Kaiser</p>
  </li>
  <li>
    <p>Jonathon Shlens</p>
  </li>
</ul>

<p>Minor Researchers</p>

<ul>
  <li>
    <p>Rajat Monga</p>
  </li>
  <li>
    <p>Kai Chen</p>
  </li>
  <li>
    <p>Matthieu Devin</p>
  </li>
  <li>
    <p>Mark Mao</p>
  </li>
  <li>
    <p>Andrew Senior</p>
  </li>
  <li>
    <p>Paul Tucker</p>
  </li>
  <li>
    <p>Ke Yang</p>
  </li>
  <li>
    <p>Patrick Nguyen</p>
  </li>
  <li>
    <p>Dumitru Erhan</p>
  </li>
  <li>
    <p>Eugene Ie</p>
  </li>
  <li>
    <p>Andrew Rabinovich</p>
  </li>
  <li>
    <p>Jon Shlens</p>
  </li>
  <li>
    <p>Yoram Singer</p>
  </li>
  <li>
    <p>Ciprian Chelba</p>
  </li>
  <li>
    <p>Mike Schuster</p>
  </li>
  <li>
    <p>Qi Ge</p>
  </li>
  <li>
    <p>Thorsten Brants</p>
  </li>
  <li>
    <p>Tamas Sarlos</p>
  </li>
  <li>
    <p>Georg Heigold</p>
  </li>
  <li>
    <p>Andrea Frome</p>
  </li>
  <li>
    <p>Maya Gupta</p>
  </li>
  <li>
    <p>David Sussillo</p>
  </li>
  <li>
    <p>Dragonir Anguelov</p>
  </li>
  <li>
    <p>Alexander Toshev</p>
  </li>
  <li>
    <p>Andrew Dai</p>
  </li>
  <li>
    <p>Anelia Angelova</p>
  </li>
  <li>
    <p>Alex Krizhevsky</p>
  </li>
  <li>
    <p>Lucasz Kaiser</p>
  </li>
  <li>
    <p>Terry Koo</p>
  </li>
  <li>
    <p>Slav Petrov</p>
  </li>
  <li>
    <p>Tara Sainath</p>
  </li>
  <li>
    <p>Hasim Sak</p>
  </li>
  <li>
    <p>Pierre Sermanet</p>
  </li>
  <li>
    <p>Esteban Real</p>
  </li>
  <li>
    <p>Peter Liu</p>
  </li>
  <li>
    <p>Sergey Levine</p>
  </li>
  <li>
    <p>Amit Daniely</p>
  </li>
  <li>
    <p>Roy Frostig</p>
  </li>
  <li>
    <p>Martin Abadi</p>
  </li>
  <li>
    <p>Zhifeng Chen</p>
  </li>
  <li>
    <p>Yonghui Wu</p>
  </li>
  <li>
    <p>Dale Schuurmans</p>
  </li>
  <li>
    <p>Jianmin Chen</p>
  </li>
  <li>
    <p>Rafal Jozefowicz</p>
  </li>
  <li>
    <p>Sergey Ioffe</p>
  </li>
  <li>
    <p>Honglak Lee</p>
  </li>
  <li>
    <p>Manjunath Kudlur</p>
  </li>
  <li>
    <p>Karol Kurach</p>
  </li>
  <li>
    <p>Minh-Thang Luong</p>
  </li>
  <li>
    <p>John Nahm</p>
  </li>
  <li>
    <p>Alexander Alemi</p>
  </li>
  <li>
    <p>Jascha Sohl-Dckstein</p>
  </li>
  <li>
    <p>Noam Shazeer</p>
  </li>
  <li>
    <p>David Ha</p>
  </li>
  <li>
    <p>Shan Carter</p>
  </li>
  <li>
    <p>Chris Olah</p>
  </li>
  <li>
    <p>Ignacio Moreno</p>
  </li>
  <li>
    <p>Douglas Eck</p>
  </li>
  <li>
    <p>Natasha Jaques</p>
  </li>
  <li>
    <p>Shixiang Gu</p>
  </li>
  <li>
    <p>Konstantinos Bousmalis</p>
  </li>
  <li>
    <p>Francois Chollet</p>
  </li>
  <li>
    <p>Geoffrey Irving</p>
  </li>
  <li>
    <p>Amarnag Subramanya</p>
  </li>
  <li>
    <p>Michael Ringgaard</p>
  </li>
  <li>
    <p>Fernando Pereira</p>
  </li>
  <li>
    <p>Adam Roberts</p>
  </li>
  <li>
    <p>Cinjon Resnick</p>
  </li>
  <li>
    <p>Anjuli Kannan</p>
  </li>
  <li>
    <p>Ryan Adams</p>
  </li>
  <li>
    <p>David Dohan</p>
  </li>
  <li>
    <p>Luke Metz</p>
  </li>
  <li>
    <p>Kelvin Xu</p>
  </li>
  <li>
    <p>Jan Chorowski</p>
  </li>
  <li>
    <p>Colin Raffel</p>
  </li>
  <li>
    <p>Dieterich Lawson</p>
  </li>
  <li>
    <p>George Papandreou</p>
  </li>
  <li>
    <p>Kevin Murphy</p>
  </li>
  <li>
    <p>Jonathan Tompson</p>
  </li>
  <li>
    <p>Olivier Bousquet</p>
  </li>
  <li>
    <p>Sylvain Gelly</p>
  </li>
  <li>
    <p>Olivier Teytaud</p>
  </li>
  <li>
    <p>Damien Vincent</p>
  </li>
  <li>
    <p>Eric Jang</p>
  </li>
  <li>
    <p>Jasmine Hsu</p>
  </li>
  <li>
    <p>Been Kim</p>
  </li>
  <li>
    <p>Bart van Merrienboer</p>
  </li>
  <li>
    <p>Alexander Wiltschko</p>
  </li>
  <li>
    <p>Dan Moldovan</p>
  </li>
  <li>
    <p>Yuxuan Wang</p>
  </li>
  <li>
    <p>RJ Skerry-Ryan</p>
  </li>
  <li>
    <p>James Davidson</p>
  </li>
  <li>
    <p>Ron Weiss</p>
  </li>
  <li>
    <p>Jan Chorowski</p>
  </li>
  <li>
    <p>Yonghui Wu</p>
  </li>
  <li>
    <p>Zhifeng Chen</p>
  </li>
  <li>
    <p>Kunal Talwar</p>
  </li>
  <li>
    <p>Barret Zoph</p>
  </li>
  <li>
    <p>Maithra Raghu</p>
  </li>
  <li>
    <p>Justin Gilmer</p>
  </li>
  <li>
    <p>Jeffrey Pennington</p>
  </li>
  <li>
    <p>Samuel Schoenholz</p>
  </li>
  <li>
    <p>Gabriel Pereyra</p>
  </li>
  <li>
    <p>George Tucker</p>
  </li>
  <li>
    <p>Vineet Gupta</p>
  </li>
  <li>
    <p>Ryan Dahl</p>
  </li>
  <li>
    <p>Azalia Mirhoseini</p>
  </li>
  <li>
    <p>Andy Davis</p>
  </li>
  <li>
    <p>Ashish Vaswani</p>
  </li>
  <li>
    <p>Krzysztof Maziarz</p>
  </li>
  <li>
    <p>Vikas Sindhwani</p>
  </li>
  <li>
    <p>Irwan Bello</p>
  </li>
  <li>
    <p>Hugo Larochelle</p>
  </li>
  <li>
    <p>Vijay Vasudevan</p>
  </li>
  <li>
    <p>Hieu Pham</p>
  </li>
  <li>
    <p>Jesse Engel</p>
  </li>
  <li>
    <p>Denny Britz</p>
  </li>
  <li>
    <p>Anna Goldie</p>
  </li>
  <li>
    <p>Connor Schenck</p>
  </li>
  <li>
    <p>Ruben Villegas</p>
  </li>
  <li>
    <p>Yuliang Zou</p>
  </li>
  <li>
    <p>Sungryull Sohn</p>
  </li>
  <li>
    <p>Danijar Hafner</p>
  </li>
  <li>
    <p>Alex Irpan</p>
  </li>
  <li>
    <p>James Davidson</p>
  </li>
  <li>
    <p>Chung-Cheng Chiu</p>
  </li>
  <li>
    <p>Kevin Swersky</p>
  </li>
  <li>
    <p>Olga Wichrowska</p>
  </li>
  <li>
    <p>Jakob Forester</p>
  </li>
  <li>
    <p>Andrew Lampinen</p>
  </li>
  <li>
    <p>David So</p>
  </li>
  <li>
    <p>Fred Bertsch</p>
  </li>
  <li>
    <p>Reza Mahjourian</p>
  </li>
  <li>
    <p>Yasaman Bahri</p>
  </li>
  <li>
    <p>Ofir Nachum</p>
  </li>
  <li>
    <p>Melody Guan</p>
  </li>
  <li>
    <p>Julian Ibarz</p>
  </li>
  <li>
    <p>Benoit Steiner</p>
  </li>
  <li>
    <p>Rasmus Larsen</p>
  </li>
  <li>
    <p>Ethan Holly</p>
  </li>
  <li>
    <p>Gal Chechik</p>
  </li>
  <li>
    <p>Augustus Odena</p>
  </li>
  <li>
    <p>Christopher Olah</p>
  </li>
  <li>
    <p>Jasmine Collins</p>
  </li>
  <li>
    <p>Michal Jastrzebski</p>
  </li>
  <li>
    <p>Philip Haeusser</p>
  </li>
  <li>
    <p>Mario Lucic</p>
  </li>
  <li>
    <p>Richard Sproat</p>
  </li>
  <li>
    <p>Alexey Kurakin</p>
  </li>
  <li>
    <p>Takeru Miyato</p>
  </li>
  <li>
    <p>Kristofer Schlachter</p>
  </li>
  <li>
    <p>Tomer Koren</p>
  </li>
  <li>
    <p>Ayush Sekhari</p>
  </li>
  <li>
    <p>Matthew Kelcey</p>
  </li>
  <li>
    <p>Laura Downs</p>
  </li>
</ul>

<p>Genealogy</p>

<p>Founding Team</p>

<ul>
  <li>
    <p>Jeff Dean</p>
  </li>
  <li>
    <p>Samy Bengio</p>
  </li>
  <li>
    <p>Geoffrey Hinton</p>
  </li>
  <li>
    <p>Andrew Ng</p>
  </li>
  <li>
    <p>Quoc Le</p>
  </li>
  <li>
    <p>Greg Corrado</p>
  </li>
  <li>
    <p>Vincent Vanhoucke</p>
  </li>
  <li>
    <p>Yoran Singer</p>
  </li>
  <li>
    <p>Ian Goodfellow</p>
  </li>
  <li>
    <p>Tomas Mikolov</p>
  </li>
  <li>
    <p>Rajat Monga</p>
  </li>
  <li>
    <p>Kai Chen (Brain NY)</p>
  </li>
  <li>
    <p>Matthieu Devin</p>
  </li>
  <li>
    <p>Mark Mao</p>
  </li>
  <li>
    <p>Marc’ Aurelio Ranzato (Brain NY)</p>
  </li>
  <li>
    <p>Andrew Senior</p>
  </li>
  <li>
    <p>Paul Tucker</p>
  </li>
  <li>
    <p>Ke Yang</p>
  </li>
  <li>
    <p>Patrick Nguyen</p>
  </li>
  <li>
    <p>Yoram Singer</p>
  </li>
  <li>
    <p>Dzmitry Bahdanau</p>
  </li>
</ul>

<p>In the early days, the exploration was mainly in scaling deep learning and discovering new applications to speech recognition, image categorization and language modeling.</p>

<p>Tensorflowers: Mart´ın Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Mane, Rajat Monga, Sherry Moore, Derek Murray, ´ Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viegas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng</p>

<p>Massive acceleration of Brain papers into ICLR 2016… Tensorflowers start making their way onto papers.</p>

<p>Noisy Counts (Scraped)</p>

<p>[29, ‘Oriol Vinyals’],
 [27, ‘Samy Bengio’],
 [23, ‘Ilya Sutskever’],
 [20, ‘Navdeep Jaitly’],
 [16, ‘Sergey Levine’],
 [14, ‘Mohammad Norouzi’],1
 [14, ‘Ian Goodfellow’],
 [13, ‘Lukasz Kaiser’],
 [13, ‘Jonathon Shlens’],
 [12, ‘Vincent Vanhoucke’],
 [10, ‘Quoc Le’],
 [10, ‘Geoffrey Hinton’],
 [9, ‘Dumitru Erhan’],
 [8, ‘Shixiang Gu’],
 [8, ‘Rajat Monga’],
 [8, ‘Honglak Lee’],
 [8, ‘Greg Corrado’],
 [8, ‘Christian Szegedy’],
 [8, ‘Andrew Senior’],
 [7, ‘Yoram Singer’],
 [7, ‘Tomas Mikolov’],
 [7, ‘Sylvain Gelly’],
 [7, ‘Olivier Bousquet’],
 [7, ‘Karol Kurach’],
 [7, ‘Georg Heigold’],
 [7, ‘Anelia Angelova’],
 [6, ‘Zhifeng Chen’],
 [6, ‘Rafal Jozefowicz’],
 [6, ‘Ofir Nachum’],
 [6, ‘Matthieu Devin’],
 [6, ‘Martin Abadi’],
 [6, ‘James Davidson’],
 [6, ‘Dieterich Lawson’],
 [6, ‘Dale Schuurmans’],
 [5, ‘Yonghui Wu’],
 [5, ‘Yonghui Wu’],
 [5, ‘Tara Sainath’],
 [5, ‘Mike Schuster’],
 [5, ‘Manjunath Kudlur’],
 [5, ‘Kevin Murphy’],
 [5, ‘Justin Gilmer’],
 [5, ‘George Tucker’],
 [5, ‘Douglas Eck’],
 [4, ‘Pierre Sermanet’],
 [4, ‘Noam Shazeer’],
 [4, ‘Maithra Raghu’],
 [4, ‘Kunal Talwar’],
 [4, ‘Kelvin Xu’],
 [4, ‘Kai Chen’],
 [4, ‘Jeff Dean’],
 [4, ‘Jan Chorowski’],
 [4, ‘Geoffrey Irving’],
 [4, ‘David Sussillo’],
 [4, ‘David Ha’],
 [4, ‘Colin Raffel’],
 [4, ‘Chris Olah’],
 [4, ‘Andrea Frome’],
 [4, ‘Amit Daniely’],
 [4, ‘Alexander Toshev’],
 [3, ‘Vikas Sindhwani’],
 [3, ‘Vijay Vasudevan’],
 [3, ‘Tomer Koren’],
 [3, ‘Paul Tucker’],
 [3, ‘Patrick Nguyen’],
 [3, ‘Olivier Teytaud’],
 [3, ‘Natasha Jaques’],
 [3, ‘Konstantinos Bousmalis’],
 [3, ‘Julian Ibarz’],
 [3, ‘Jonathan Tompson’],
 [3, ‘Jeffrey Pennington’],
 [3, ‘Hasim Sak’],
 [3, ‘Denny Britz’],
 [3, ‘Damien Vincent’],
 [3, ‘Benoit Steiner’],
 [3, ‘Barret Zoph’],
 [3, ‘Azalia Mirhoseini’],
 [3, ‘Augustus Odena’],
 [3, ‘Andy Davis’],
 [3, ‘Andrew Rabinovich’],
 [3, ‘Alex Krizhevsky’],
 [2, ‘Vineet Gupta’],
 [2, ‘Sergey Ioffe’],
 [2, ‘Ryan Dahl’],
 [2, ‘Ruben Villegas’],
 [2, ‘Roy Frostig’],
 [2, ‘Peter Liu’],
 [2, ‘Melody Guan’],
 [2, ‘Luke Metz’],
 [2, ‘Ke Yang’],
 [2, ‘Jianmin Chen’],
 [2, ‘Irwan Bello’],
 [2, ‘Hugo Larochelle’],
 [2, ‘Hieu Pham’],
 [2, ‘Fred Bertsch’],
 [2, ‘Francois Chollet’],
 [2, ‘Esteban Real’],
 [2, ‘Eric Jang’],
 [2, ‘Cinjon Resnick’],
 [2, ‘Been Kim’],
 [2, ‘Ashish Vaswani’],
 [2, ‘Anna Goldie’],
 [2, ‘Anjuli Kannan’],
 [2, ‘Andrew Dai’],
 [2, ‘Amarnag Subramanya’],
 [2, ‘Alexey Kurakin’],
 [2, ‘Adam Roberts’],
 [1, ‘Yuxuan Wang’],
 [1, ‘Yuliang Zou’],
 [1, ‘Yasaman Bahri’],
 [1, ‘Thorsten Brants’],
 [1, ‘Terry Koo’],
 [1, ‘Tamas Sarlos’],
 [1, ‘Takeru Miyato’],
 [1, ‘Sungryull Sohn’],
 [1, ‘Slav Petrov’],
 [1, ‘Shan Carter’],
 [1, ‘Ryan Adams’],
 [1, ‘Richard Sproat’],
 [1, ‘Reza Mahjourian’],
 [1, ‘Rasmus Larsen’],
 [1, ‘RJ Skerry-Ryan’],
 [1, ‘Qi Ge’],
 [1, ‘Philip Haeusser’],
 [1, ‘Olga Wichrowska’],
 [1, ‘Michal Jastrzebski’],
 [1, ‘Mark Mao’],
 [1, ‘Krzysztof Maziarz’],
 [1, ‘Kristofer Schlachter’],
 [1, ‘Kevin Swersky’],
 [1, ‘Jesse Engel’],
 [1, ‘Jasmine Hsu’],
 [1, ‘Jasmine Collins’],
 [1, ‘Ignacio Moreno’],
 [1, ‘George Papandreou’],
 [1, ‘Gal Chechik’],
 [1, ‘Gabriel Pereyra’],
 [1, ‘Fernando Pereira’],
 [1, ‘Eugene Ie’],
 [1, ‘Ethan Holly’],
 [1, ‘David Dohan’],
 [1, ‘Danijar Hafner’],
 [1, ‘Dan Moldovan’],
 [1, ‘Connor Schenck’],
 [1, ‘Ciprian Chelba’],
 [1, ‘Chung-Cheng Chiu’],
 [1, ‘Christopher Olah’],
 [1, ‘Ayush Sekhari’],
 [1, ‘Andrew Ng’],
 [1, ‘Andrew Lampinen’],
 [1, ‘Alex Irpan’],</p>


  </div><a class="u-url" href="/machinelearning/2018/06/07/google-brain-research-overview.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">
<!-- 
    <div class="footer-col-wrapper">
      <div class="footer-col one-half">
      <h2 class="footer-heading">Jeremy Nixon</h2>
        <ul class="contact-list">
          <li class="p-name">Jeremy Nixon</li><li><a class="u-email" href="mailto:jnixon2@gmail.com">jnixon2@gmail.com</a></li></ul>
      </div>
 -->
      <div style="text-align: center; font-style: italic;">
        <p>Reach to the sky from the bottom.</p>
      </div>

<!--       <div class="social-links"><ul class="social-media-list"><li><a href="https://github.com/jeremynixon"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">jeremynixon</span></a></li><li><a href="https://www.twitter.com/JvNixon"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">JvNixon</span></a></li></ul>
</div> -->

    </div>
      <img src="https://github.com/JeremyNixon/JeremyNixon.github.io/raw/master/_site/images/Creative-Hand.jpg" alt="Moment of Creation" style="max-width:100%;">
  </div>

</footer></body>

</html>
