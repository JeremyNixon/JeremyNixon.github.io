<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.4.0 -->
<title>Systematized Predictive Modeling | Grounded Abstraction</title>
<meta name="generator" content="Jekyll v3.8.0" />
<meta property="og:title" content="Systematized Predictive Modeling" />
<meta name="author" content="Jeremy Nixon" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Preprocessing Zero mean (subtract the mean from each predictor) to center the data. Divide by standard deviation to scale the data. DateTime One-Hot Code Look For skewness, log/sqrt/Box Cox transform if necessary (Boxcox) Resolve Outliers (and understand their meaning) (apply spatial sign if model is sensitive to outliers) Eliminate Missing Data (Can be problematic if missingness is predictive. Tree Based Models can deal with missing data) Imputation/Interpolation (KNN or intermediate regression model)" />
<meta property="og:description" content="Preprocessing Zero mean (subtract the mean from each predictor) to center the data. Divide by standard deviation to scale the data. DateTime One-Hot Code Look For skewness, log/sqrt/Box Cox transform if necessary (Boxcox) Resolve Outliers (and understand their meaning) (apply spatial sign if model is sensitive to outliers) Eliminate Missing Data (Can be problematic if missingness is predictive. Tree Based Models can deal with missing data) Imputation/Interpolation (KNN or intermediate regression model)" />
<link rel="canonical" href="http://localhost:4000/machinelearning/2015/06/03/systematized-predictive-modeling.html" />
<meta property="og:url" content="http://localhost:4000/machinelearning/2015/06/03/systematized-predictive-modeling.html" />
<meta property="og:site_name" content="Grounded Abstraction" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2015-06-03T00:00:00-07:00" />
<script type="application/ld+json">
{"description":"Preprocessing Zero mean (subtract the mean from each predictor) to center the data. Divide by standard deviation to scale the data. DateTime One-Hot Code Look For skewness, log/sqrt/Box Cox transform if necessary (Boxcox) Resolve Outliers (and understand their meaning) (apply spatial sign if model is sensitive to outliers) Eliminate Missing Data (Can be problematic if missingness is predictive. Tree Based Models can deal with missing data) Imputation/Interpolation (KNN or intermediate regression model)","author":{"@type":"Person","name":"Jeremy Nixon"},"@type":"BlogPosting","url":"http://localhost:4000/machinelearning/2015/06/03/systematized-predictive-modeling.html","headline":"Systematized Predictive Modeling","dateModified":"2015-06-03T00:00:00-07:00","datePublished":"2015-06-03T00:00:00-07:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/machinelearning/2015/06/03/systematized-predictive-modeling.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Grounded Abstraction" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Grounded Abstraction</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">Identity.</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Systematized Predictive Modeling</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2015-06-03T00:00:00-07:00" itemprop="datePublished">Jun 3, 2015
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p><em>Preprocessing</em></p>
<ol>
  <li>Zero mean (subtract the mean from each predictor) to center the data.</li>
  <li>Divide by standard deviation to scale the data.</li>
  <li>DateTime</li>
  <li>One-Hot Code</li>
  <li>Look For skewness, log/sqrt/Box Cox transform if necessary (Boxcox)</li>
  <li>Resolve Outliers (and understand their meaning) (apply spatial sign if model is sensitive to outliers)</li>
  <li>Eliminate Missing Data (Can be problematic if missingness is predictive. Tree Based Models can deal with missing data)</li>
  <li>Imputation/Interpolation (KNN or intermediate regression model)</li>
</ol>

<hr />
<p><br /></p>

<p><em>Exploratory Data Analysis</em></p>
<ol>
  <li>Maximal Information Coefficient Matrix / Correlation Matrix</li>
  <li>Box-Chart Everything</li>
  <li>Scatter Every Combination of Features</li>
  <li>Pivot Tables</li>
  <li>Group by particular features</li>
  <li>Histogram Everything</li>
  <li>Outlier Analysis</li>
  <li>Transform Variables (Square, Cube, Inverse, Log) and Plot</li>
  <li>Summary (Mean, Mode, Minimum, Maximum, Upper/Lower Quartiles, Identify Outliers)</li>
</ol>

<hr />
<p><br /></p>

<p><em>Data Reduction</em></p>
<ol>
  <li>Principal Component Analysis 
2.Linear Discriminant Analysis (For Classification)</li>
  <li>Feature Selection (Only use the components that account for a majority of the information when Modeling</li>
  <li>Remove Low/Zero Variance Predictors</li>
  <li>Remove multicollinear heavily correlated features</li>
  <li>Isomap</li>
  <li>Lasso</li>
</ol>

<hr />
<p><br /></p>

<p><em>Algorithms for Regression</em></p>
<ol>
  <li>Linear Regression
    <ul>
      <li>Ridge Regression / Lasso / Elastic Net</li>
      <li>Best Subset Selection</li>
      <li>Forward and Backward Stepwise, Stagewise</li>
    </ul>
  </li>
  <li>Partial Least Squares</li>
  <li>Principal Components Regression</li>
  <li>Neural Networks
    <ul>
      <li>CNN</li>
      <li>RNN
  -LSTM</li>
    </ul>
  </li>
  <li>Multivariate Adaptive Regression Splines</li>
  <li>Support Vector Regressor</li>
  <li>K-Nearest Neighbors</li>
  <li>Regression Decision Trees</li>
  <li>Bagged Trees</li>
  <li>Random Forests</li>
  <li>Extremely Random Forests</li>
  <li>Gradient Boosted Trees</li>
  <li>Generalized Linear Model</li>
  <li>Generalized Additive Model</li>
</ol>

<hr />
<p><br /></p>

<p><em>Evaluating Regression</em></p>
<ol>
  <li>RMSE</li>
  <li>MAE</li>
  <li>Median</li>
  <li>R2</li>
  <li>Visualization</li>
</ol>

<hr />
<p><br /></p>

<p><em>Algorithms for Classification</em></p>
<ol>
  <li>Logistic Regression
    <ul>
      <li>L1, L2, Elastic Net</li>
    </ul>
  </li>
  <li>Discriminant Analysis</li>
  <li>Linear Discriminant Analysis</li>
  <li>Quadratic Discriminant Analysis</li>
  <li>Neural Networks
    <ul>
      <li>CNN</li>
      <li>RNN
        <ul>
          <li>LSTM</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Support Vector Classifier</li>
  <li>K-Nearest Neighbors</li>
  <li>Naive Bayes</li>
  <li>Classification Trees</li>
  <li>Bagged Trees</li>
  <li>Random Forests</li>
  <li>Extremely Random Forests</li>
  <li>Gradient Boosted Trees</li>
  <li>Generalized Additive Model</li>
</ol>

<hr />
<p><br /></p>

<p><em>Evaluating Classification</em></p>
<ol>
  <li>ROC Curve</li>
  <li>Confusion Matrix</li>
  <li>F1 Score</li>
  <li>Heat Map</li>
  <li>Overall accuracy rate</li>
  <li>Kappa Statistic</li>
  <li>Sensitivity</li>
  <li>Specificity</li>
  <li>AUC</li>
</ol>

<hr />
<p><br /></p>

<p><em>Unsupervised Learning</em></p>
<ol>
  <li>K-Means
    <ul>
      <li>K-Means++</li>
      <li>K-Medoids</li>
    </ul>
  </li>
  <li>Hierarchical Agglomerative Clustering
    <ul>
      <li>Single Linkage, Complete Linkage, Average Linkage, Centroid Criterion</li>
    </ul>
  </li>
  <li>Principal Components Analysis</li>
  <li>Spectral Clustering</li>
  <li>Affinity Propagation</li>
  <li>Biclustering</li>
  <li>Gaussian Mixture Model</li>
</ol>

<hr />
<p><br /></p>

<p><em>Classification Class Imbalance</em></p>
<ol>
  <li>Model Tuning (Tune Parameters For Sensitivity)</li>
  <li>Alternate Cutoffs (Using ROC Curve)</li>
  <li>Adjusting Prior Probability</li>
  <li>Unequal Case Weights</li>
  <li>Down Sampling</li>
  <li>Up Sampling</li>
  <li>Alter Cost Function</li>
  <li>Dynamic Structure (Cascade of classifiers)</li>
</ol>

<hr />
<p><br /></p>

<p><em>Feature Evaluation</em></p>
<ol>
  <li>Coefficients in Linear Models</li>
  <li>Random Forest Importances (variance for regression, information gain for classification)</li>
  <li>Pearson Correlation with Outcome</li>
  <li>Maximal Information Coefficient (MIC)</li>
  <li>Distance Correlation (code)</li>
  <li>Model with/without feature</li>
  <li>Randomly shuffle the feature between data points, check difference in model quality</li>
  <li>Lasso Automatic Selection</li>
  <li>Mean Decrease Accuracy (code)</li>
  <li>Stability Selection</li>
  <li>Recursive Feature Elimination</li>
</ol>

<hr />
<p><br /></p>

<p><em>Parameter Tuning</em></p>
<ol>
  <li>Cross Validation</li>
  <li>Bootstrap</li>
  <li>Grid Search (ex)</li>
</ol>

<hr />
<p><br /></p>

<p><em>Text Features</em></p>
<ol>
  <li>n-Grams</li>
  <li>Word Vector Representations (Word 2 Vec)</li>
  <li>Bag of words</li>
  <li>Word counts</li>
  <li>Lengths</li>
  <li>Tf-idf</li>
  <li>Term frequency, weighted by its rarity</li>
  <li>topic modeling (LDA)</li>
</ol>

<hr />
<p><br /></p>

<p><em>Modeling Techniques</em></p>
<ol>
  <li>Feature Engineering
    <ul>
      <li>Basis Expansions</li>
      <li>Combine Features</li>
      <li>average values, median values, variances, sums, differences, maximums or minimums, and counts.</li>
    </ul>
  </li>
  <li>Stacking (using output of one algorithm as input to the next)</li>
  <li>Internal Prediction</li>
  <li>Blending (Especially with differentiated models)</li>
  <li>Account For Missing Data (It can be information)</li>
  <li>External Data</li>
  <li>Acquire Domain Knowledge for Feature Engineering</li>
  <li>Random Forest, Boosters, Trees Importances for Feature Exploration</li>
  <li>Clustering for feature creation</li>
  <li>Distance to Class Centroid</li>
</ol>

  </div><a class="u-url" href="/machinelearning/2015/06/03/systematized-predictive-modeling.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">
<!-- 
    <div class="footer-col-wrapper">
      <div class="footer-col one-half">
      <h2 class="footer-heading">Grounded Abstraction</h2>
        <ul class="contact-list">
          <li class="p-name">Jeremy Nixon</li><li><a class="u-email" href="mailto:jnixon2@gmail.com">jnixon2@gmail.com</a></li></ul>
      </div>
 -->
      <div style="text-align: center;">
        <p>Reach to the sky from the bottom.</p>
      </div>

<!--       <div class="social-links"><ul class="social-media-list"><li><a href="https://github.com/jeremynixon"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">jeremynixon</span></a></li><li><a href="https://www.twitter.com/JvNixon"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">JvNixon</span></a></li></ul>
</div> -->

    </div>
      <img src="https://github.com/JeremyNixon/JeremyNixon.github.io/raw/master/_site/images/Creative-Hand.jpg" alt="Moment of Creation" style="max-width:100%;">
  </div>

</footer></body>

</html>
