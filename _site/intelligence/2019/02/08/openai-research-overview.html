<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Open AI Research Overview | Jeremy Nixon</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Open AI Research Overview" />
<meta name="author" content="Jeremy Nixon" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="By Jeremy Nixon [jnixon2@gmail.com]. Nov. 2017. Categories: Domain in which the paper’s innovation is novel. Reinforcement Learning Multi-Agent Exploration Imitation Learning Deep Learning Memory Program Learning Representation Learning Variational Inference Generative Models Evolution Applications Security / Safety Robotics Environments Reinforcement Learning Multi-Agent Learning with Opponent-Learning Awareness Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments Emergence of Grounded Compositional Language in Multi-Agent Populations Exploration Parameter Space Noise for Exploration UCB and InfoGain Exploration via Q-Ensembles Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning VIME: Variational Information Maximizing Exploration Imitation Learning Third-Person Imitation Learning One-Shot Imitation Learning RL2: Fast Reinforcement Learning via Slow Reinforcement Learning Teacher-Student Curriculum Learning Equivalence Between Policy Gradients and Soft Q-Learning Prediction and Control with Temporal Segment Models Deep Learning Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks Memory Hindsight Experience Replay [Also, Reinforcement Learning] Program Learning Extensions and Limitations of the Neural GPU Representation Learning Variational Lossy Autoencoder Variational Inference Improving Variational Inference with Inverse Autoregressive Flow Generative Models Generative Adversarial Networks InfoGan: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets [Also, Representation Learning] Improved Techniques for Training GANs On the Quantitative Analysis of Decoder-Based Generative Models A Connection between Generative Adversarial Networks, Inverse Reinforcement Learning, and Energy Based Models [Also Reinforcement Learning] PixelCNN++: Improving the Pixel CNN with Discretized Logistic Mixture Likelihood and Other Modifications Learning to Generate Reviews and Discovering Sentiment Evolution Evolution Strategies as a Scalable Alternative to Reinforcement Learning Applications Security / Safety Deep Reinforcement Learning from Human Preferences Concrete Problems in AI Safety Adversarial Attacks on Neural Network Policies Adversarial Training Methods for Semi-Supervised Text Classification Semi-Supervised Knowledge Transfer for Deep Learning from Private Training Data Debate Amplification Robotics Domain Randomization for Transferring Deep NEural Networks from Simulation to the Real World Transfer from Simulation to Real World through Learning Deep Inverse Dynamics Model Environments Infrastructure for Deep Learning Universe OpenAI Gym OpenAI Researchers Paul Christiano Ryan Lowe Jean Harb Pieter Abbeel Igor Mordatch Matthias Plappert Rein Houthooft Prafulla Dhariwal Szymon Sidor Richard Y. Chen Xi Chen Marcin Andrychowicz John Schulman Alec Radford Rafal Jozefowicz Yan Duan Bradly C. Stadie Jonathan Ho Jonas Schneider Ilya Sutskever Wojciech Zaremba Rachel Fong Josh Tobin Alex Ray Nikhil Mishra Ian Goodfellow Tim Salimans Diederik P. Kingma Andrej Karpathy Yuri Burda Zain Shah Trevor Blackwell Vicki Cheung Salaries of top employees [Pg. 28] Hours &amp; Salaries of top employees [Pg. 7] OpenAI spent 11 million in 2016, 7 million on salary. For comparison, Deepmind spend 138 million in 2016." />
<meta property="og:description" content="By Jeremy Nixon [jnixon2@gmail.com]. Nov. 2017. Categories: Domain in which the paper’s innovation is novel. Reinforcement Learning Multi-Agent Exploration Imitation Learning Deep Learning Memory Program Learning Representation Learning Variational Inference Generative Models Evolution Applications Security / Safety Robotics Environments Reinforcement Learning Multi-Agent Learning with Opponent-Learning Awareness Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments Emergence of Grounded Compositional Language in Multi-Agent Populations Exploration Parameter Space Noise for Exploration UCB and InfoGain Exploration via Q-Ensembles Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning VIME: Variational Information Maximizing Exploration Imitation Learning Third-Person Imitation Learning One-Shot Imitation Learning RL2: Fast Reinforcement Learning via Slow Reinforcement Learning Teacher-Student Curriculum Learning Equivalence Between Policy Gradients and Soft Q-Learning Prediction and Control with Temporal Segment Models Deep Learning Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks Memory Hindsight Experience Replay [Also, Reinforcement Learning] Program Learning Extensions and Limitations of the Neural GPU Representation Learning Variational Lossy Autoencoder Variational Inference Improving Variational Inference with Inverse Autoregressive Flow Generative Models Generative Adversarial Networks InfoGan: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets [Also, Representation Learning] Improved Techniques for Training GANs On the Quantitative Analysis of Decoder-Based Generative Models A Connection between Generative Adversarial Networks, Inverse Reinforcement Learning, and Energy Based Models [Also Reinforcement Learning] PixelCNN++: Improving the Pixel CNN with Discretized Logistic Mixture Likelihood and Other Modifications Learning to Generate Reviews and Discovering Sentiment Evolution Evolution Strategies as a Scalable Alternative to Reinforcement Learning Applications Security / Safety Deep Reinforcement Learning from Human Preferences Concrete Problems in AI Safety Adversarial Attacks on Neural Network Policies Adversarial Training Methods for Semi-Supervised Text Classification Semi-Supervised Knowledge Transfer for Deep Learning from Private Training Data Debate Amplification Robotics Domain Randomization for Transferring Deep NEural Networks from Simulation to the Real World Transfer from Simulation to Real World through Learning Deep Inverse Dynamics Model Environments Infrastructure for Deep Learning Universe OpenAI Gym OpenAI Researchers Paul Christiano Ryan Lowe Jean Harb Pieter Abbeel Igor Mordatch Matthias Plappert Rein Houthooft Prafulla Dhariwal Szymon Sidor Richard Y. Chen Xi Chen Marcin Andrychowicz John Schulman Alec Radford Rafal Jozefowicz Yan Duan Bradly C. Stadie Jonathan Ho Jonas Schneider Ilya Sutskever Wojciech Zaremba Rachel Fong Josh Tobin Alex Ray Nikhil Mishra Ian Goodfellow Tim Salimans Diederik P. Kingma Andrej Karpathy Yuri Burda Zain Shah Trevor Blackwell Vicki Cheung Salaries of top employees [Pg. 28] Hours &amp; Salaries of top employees [Pg. 7] OpenAI spent 11 million in 2016, 7 million on salary. For comparison, Deepmind spend 138 million in 2016." />
<link rel="canonical" href="http://localhost:4000/intelligence/2019/02/08/openai-research-overview.html" />
<meta property="og:url" content="http://localhost:4000/intelligence/2019/02/08/openai-research-overview.html" />
<meta property="og:site_name" content="Jeremy Nixon" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-02-08T00:00:00-08:00" />
<script type="application/ld+json">
{"url":"http://localhost:4000/intelligence/2019/02/08/openai-research-overview.html","headline":"Open AI Research Overview","dateModified":"2019-02-08T00:00:00-08:00","datePublished":"2019-02-08T00:00:00-08:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/intelligence/2019/02/08/openai-research-overview.html"},"author":{"@type":"Person","name":"Jeremy Nixon"},"description":"By Jeremy Nixon [jnixon2@gmail.com]. Nov. 2017. Categories: Domain in which the paper’s innovation is novel. Reinforcement Learning Multi-Agent Exploration Imitation Learning Deep Learning Memory Program Learning Representation Learning Variational Inference Generative Models Evolution Applications Security / Safety Robotics Environments Reinforcement Learning Multi-Agent Learning with Opponent-Learning Awareness Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments Emergence of Grounded Compositional Language in Multi-Agent Populations Exploration Parameter Space Noise for Exploration UCB and InfoGain Exploration via Q-Ensembles Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning VIME: Variational Information Maximizing Exploration Imitation Learning Third-Person Imitation Learning One-Shot Imitation Learning RL2: Fast Reinforcement Learning via Slow Reinforcement Learning Teacher-Student Curriculum Learning Equivalence Between Policy Gradients and Soft Q-Learning Prediction and Control with Temporal Segment Models Deep Learning Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks Memory Hindsight Experience Replay [Also, Reinforcement Learning] Program Learning Extensions and Limitations of the Neural GPU Representation Learning Variational Lossy Autoencoder Variational Inference Improving Variational Inference with Inverse Autoregressive Flow Generative Models Generative Adversarial Networks InfoGan: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets [Also, Representation Learning] Improved Techniques for Training GANs On the Quantitative Analysis of Decoder-Based Generative Models A Connection between Generative Adversarial Networks, Inverse Reinforcement Learning, and Energy Based Models [Also Reinforcement Learning] PixelCNN++: Improving the Pixel CNN with Discretized Logistic Mixture Likelihood and Other Modifications Learning to Generate Reviews and Discovering Sentiment Evolution Evolution Strategies as a Scalable Alternative to Reinforcement Learning Applications Security / Safety Deep Reinforcement Learning from Human Preferences Concrete Problems in AI Safety Adversarial Attacks on Neural Network Policies Adversarial Training Methods for Semi-Supervised Text Classification Semi-Supervised Knowledge Transfer for Deep Learning from Private Training Data Debate Amplification Robotics Domain Randomization for Transferring Deep NEural Networks from Simulation to the Real World Transfer from Simulation to Real World through Learning Deep Inverse Dynamics Model Environments Infrastructure for Deep Learning Universe OpenAI Gym OpenAI Researchers Paul Christiano Ryan Lowe Jean Harb Pieter Abbeel Igor Mordatch Matthias Plappert Rein Houthooft Prafulla Dhariwal Szymon Sidor Richard Y. Chen Xi Chen Marcin Andrychowicz John Schulman Alec Radford Rafal Jozefowicz Yan Duan Bradly C. Stadie Jonathan Ho Jonas Schneider Ilya Sutskever Wojciech Zaremba Rachel Fong Josh Tobin Alex Ray Nikhil Mishra Ian Goodfellow Tim Salimans Diederik P. Kingma Andrej Karpathy Yuri Burda Zain Shah Trevor Blackwell Vicki Cheung Salaries of top employees [Pg. 28] Hours &amp; Salaries of top employees [Pg. 7] OpenAI spent 11 million in 2016, 7 million on salary. For comparison, Deepmind spend 138 million in 2016.","@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Jeremy Nixon" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Jeremy Nixon</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">Identity.</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Open AI Research Overview</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2019-02-08T00:00:00-08:00" itemprop="datePublished">Feb 8, 2019
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>By Jeremy Nixon [<a href="mailto:jnixon2@gmail.com">jnixon2@gmail.com</a>]. Nov. 2017.
Categories: Domain in which the paper’s innovation is novel.</p>
<ol>
  <li>Reinforcement Learning
    <ul>
      <li>Multi-Agent</li>
      <li>Exploration</li>
      <li>Imitation Learning</li>
    </ul>
  </li>
  <li>Deep Learning</li>
  <li>Memory</li>
  <li>Program Learning</li>
  <li>Representation Learning</li>
  <li>Variational Inference</li>
  <li>Generative Models</li>
  <li>Evolution</li>
  <li>Applications
    <ul>
      <li>Security / Safety</li>
      <li>Robotics</li>
    </ul>
  </li>
  <li>
    <p>Environments</p>
  </li>
  <li>Reinforcement Learning
    <ul>
      <li>Multi-Agent
        <ul>
          <li><a href="https://arxiv.org/abs/1709.04326">Learning with Opponent-Learning Awareness</a></li>
          <li><a href="https://arxiv.org/abs/1706.02275">Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments</a></li>
          <li><a href="https://arxiv.org/abs/1703.04908">Emergence of Grounded Compositional Language in Multi-Agent Populations</a></li>
        </ul>
      </li>
      <li>Exploration
        <ul>
          <li><a href="https://arxiv.org/abs/1706.01905">Parameter Space Noise for Exploration</a></li>
          <li><a href="https://arxiv.org/abs/1706.01502">UCB and InfoGain Exploration via Q-Ensembles</a></li>
          <li><a href="https://arxiv.org/abs/1611.04717">Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning</a></li>
          <li><a href="https://arxiv.org/abs/1605.09674">VIME: Variational Information Maximizing Exploration</a></li>
        </ul>
      </li>
      <li>Imitation Learning
        <ul>
          <li><a href="https://arxiv.org/abs/1703.01703">Third-Person Imitation Learning</a></li>
          <li><a href="https://arxiv.org/abs/1703.07326">One-Shot Imitation Learning</a></li>
        </ul>
      </li>
      <li><a href="https://arxiv.org/abs/1611.02779">RL2: Fast Reinforcement Learning via Slow Reinforcement Learning</a></li>
      <li><a href="https://arxiv.org/abs/1707.00183">Teacher-Student Curriculum Learning</a></li>
      <li><a href="https://arxiv.org/abs/1704.06440">Equivalence Between Policy Gradients and Soft Q-Learning</a></li>
      <li><a href="https://arxiv.org/abs/1703.04070">Prediction and Control with Temporal Segment Models</a></li>
    </ul>
  </li>
  <li>Deep Learning
    <ul>
      <li><a href="https://arxiv.org/abs/1602.07868">Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks</a></li>
    </ul>
  </li>
  <li>Memory
    <ul>
      <li><a href="https://arxiv.org/pdf/1707.01495.pdf">Hindsight Experience Replay [Also, Reinforcement Learning]</a></li>
    </ul>
  </li>
  <li>Program Learning
    <ul>
      <li><a href="https://arxiv.org/abs/1611.00736">Extensions and Limitations of the Neural GPU</a></li>
    </ul>
  </li>
  <li>Representation Learning
    <ul>
      <li><a href="https://arxiv.org/abs/1611.02731">Variational Lossy Autoencoder</a></li>
    </ul>
  </li>
  <li>Variational Inference
    <ul>
      <li><a href="https://arxiv.org/abs/1606.04934">Improving Variational Inference with Inverse Autoregressive Flow</a></li>
    </ul>
  </li>
  <li>Generative Models
    <ul>
      <li>Generative Adversarial Networks
        <ul>
          <li><a href="https://arxiv.org/abs/1606.03657">InfoGan: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets [Also, Representation Learning]</a></li>
          <li><a href="https://arxiv.org/abs/1606.03498">Improved Techniques for Training GANs</a></li>
        </ul>
      </li>
      <li><a href="https://arxiv.org/abs/1611.04273">On the Quantitative Analysis of Decoder-Based Generative Models</a></li>
      <li><a href="https://arxiv.org/pdf/1611.03852.pdf">A Connection between Generative Adversarial Networks, Inverse Reinforcement Learning, and Energy Based Models [Also Reinforcement Learning]</a></li>
      <li><a href="https://arxiv.org/abs/1701.05517">PixelCNN++: Improving the Pixel CNN with Discretized Logistic Mixture Likelihood and Other Modifications</a></li>
      <li><a href="https://arxiv.org/abs/1704.01444">Learning to Generate Reviews and Discovering Sentiment</a></li>
    </ul>
  </li>
  <li>Evolution
    <ul>
      <li><a href="https://arxiv.org/abs/1703.03864">Evolution Strategies as a Scalable Alternative to Reinforcement Learning</a></li>
    </ul>
  </li>
  <li>Applications
    <ul>
      <li>Security / Safety
        <ul>
          <li><a href="https://arxiv.org/abs/1706.03741">Deep Reinforcement Learning from Human Preferences</a></li>
          <li><a href="https://arxiv.org/abs/1606.06565">Concrete Problems in AI Safety</a></li>
          <li><a href="https://arxiv.org/abs/1702.02284">Adversarial Attacks on Neural Network Policies</a></li>
          <li><a href="https://arxiv.org/abs/1605.07725">Adversarial Training Methods for Semi-Supervised Text Classification</a></li>
          <li><a href="https://arxiv.org/abs/1610.05755">Semi-Supervised Knowledge Transfer for Deep Learning from Private Training Data</a></li>
          <li><a href="https://arxiv.org/pdf/1805.00899.pdf">Debate Amplification</a></li>
        </ul>
      </li>
      <li>Robotics
        <ul>
          <li><a href="https://arxiv.org/abs/1703.06907">Domain Randomization for Transferring Deep NEural Networks from Simulation to the Real World</a></li>
          <li><a href="https://arxiv.org/abs/1610.03518">Transfer from Simulation to Real World through Learning Deep Inverse Dynamics Model</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Environments
    <ul>
      <li><a href="https://blog.openai.com/infrastructure-for-deep-learning/">Infrastructure for Deep Learning</a></li>
      <li><a href="https://blog.openai.com/universe/">Universe</a></li>
      <li><a href="https://arxiv.org/abs/1606.01540">OpenAI Gym</a></li>
    </ul>
  </li>
</ol>

<p>OpenAI Researchers</p>
<ol>
  <li>Paul Christiano</li>
  <li><del>Ryan Lowe</del></li>
  <li><del>Jean Harb</del></li>
  <li><del>Pieter Abbeel</del></li>
  <li><del>Igor Mordatch</del></li>
  <li>Matthias Plappert</li>
  <li><del>Rein Houthooft</del></li>
  <li>Prafulla Dhariwal</li>
  <li>Szymon Sidor</li>
  <li>Richard Y. Chen</li>
  <li><del>Xi Chen</del></li>
  <li><del>Marcin Andrychowicz</del></li>
  <li>John Schulman</li>
  <li>Alec Radford</li>
  <li><del>Rafal Jozefowicz</del></li>
  <li><del>Yan Duan</del></li>
  <li><del>Bradly C. Stadie</del></li>
  <li><del>Jonathan Ho</del></li>
  <li>Jonas Schneider</li>
  <li>Ilya Sutskever</li>
  <li>Wojciech Zaremba</li>
  <li><del>Rachel Fong</del></li>
  <li>Josh Tobin</li>
  <li>Alex Ray</li>
  <li><del>Nikhil Mishra</del></li>
  <li><del>Ian Goodfellow</del></li>
  <li><del>Tim Salimans</del></li>
  <li><del>Diederik P. Kingma</del></li>
  <li><del>Andrej Karpathy</del></li>
  <li><del>Yuri Burda</del></li>
  <li><del>Zain Shah</del></li>
  <li><del>Trevor Blackwell</del></li>
  <li><del>Vicki Cheung</del></li>
</ol>

<p><a href="http://990s.foundationcenter.org/990_pdf_archive/810/810861541/810861541_201612_990.pdf">Salaries of top employees</a> [Pg. 28]
<a href="http://www.guidestar.org/FinDocuments/2016/810/861/2016-810861541-0eb61629-9.pdf">Hours &amp; Salaries of top employees</a> [Pg. 7]
OpenAI spent 11 million in 2016, 7 million on salary. For comparison, Deepmind spend 138 million in 2016.</p>


  </div><a class="u-url" href="/intelligence/2019/02/08/openai-research-overview.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">
<!-- 
    <div class="footer-col-wrapper">
      <div class="footer-col one-half">
      <h2 class="footer-heading">Jeremy Nixon</h2>
        <ul class="contact-list">
          <li class="p-name">Jeremy Nixon</li><li><a class="u-email" href="mailto:jnixon2@gmail.com">jnixon2@gmail.com</a></li></ul>
      </div>
 -->
      <div style="text-align: center; font-style: italic;">
        <p>Reach to the sky from the bottom.</p>
      </div>

<!--       <div class="social-links"><ul class="social-media-list"><li><a href="https://github.com/jeremynixon"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">jeremynixon</span></a></li><li><a href="https://www.twitter.com/JvNixon"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">JvNixon</span></a></li></ul>
</div> -->

    </div>
      <img src="https://github.com/JeremyNixon/JeremyNixon.github.io/raw/master/_site/images/Creative-Hand.jpg" alt="Moment of Creation" style="max-width:100%;">
  </div>

</footer></body>

</html>
