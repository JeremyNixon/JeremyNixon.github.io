<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-06-11T01:06:40-07:00</updated><id>http://localhost:4000/</id><title type="html">Grounded Abstraction</title><subtitle>Reach to the sky from the bottom.</subtitle><entry><title type="html">Systematizing Creativity - Models and Techniques</title><link href="http://localhost:4000/jekyll/update/2018/06/08/systematizing-creativity-models-and-techniques.html" rel="alternate" type="text/html" title="Systematizing Creativity - Models and Techniques" /><published>2018-06-08T05:02:46-07:00</published><updated>2018-06-08T05:02:46-07:00</updated><id>http://localhost:4000/jekyll/update/2018/06/08/systematizing-creativity-models-and-techniques</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/06/08/systematizing-creativity-models-and-techniques.html">&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;Solve Creativity. Use it to solve everything else.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;Categories of Technique&lt;/em&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Intentionally enter default mode over ideas&lt;/li&gt;
  &lt;li&gt;Abstract and Generalize / Transfer over similar problems &amp;amp; solutions&lt;/li&gt;
  &lt;li&gt;Composition / Recombination&lt;/li&gt;
  &lt;li&gt;Idea Lists&lt;/li&gt;
  &lt;li&gt;Decomposition&lt;/li&gt;
  &lt;li&gt;Randomness&lt;/li&gt;
  &lt;li&gt;Idea Mapping, Graphs of Relationships between Ideas&lt;/li&gt;
  &lt;li&gt;Leading questions&lt;/li&gt;
  &lt;li&gt;Reframe / Question Assumptions&lt;/li&gt;
  &lt;li&gt;Multiple levels of analysis&lt;/li&gt;
  &lt;li&gt;Think ground up, from first principles&lt;/li&gt;
  &lt;li&gt;Automation&lt;/li&gt;
  &lt;li&gt;Thought Habits / Mental.&lt;/li&gt;
  &lt;li&gt;Invert&lt;/li&gt;
  &lt;li&gt;Activities&lt;/li&gt;
  &lt;li&gt;Social Solutions&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/Creative-Hand.jpg&quot; alt=&quot;Moment of Creation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Techniques&lt;/em&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Intentionally enter default mode over ideas&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Load up an idea / problem / question and:
        &lt;ul&gt;
          &lt;li&gt;Go for a walk&lt;/li&gt;
          &lt;li&gt;Take a shower&lt;/li&gt;
          &lt;li&gt;Sleep
            &lt;ul&gt;
              &lt;li&gt;Start to fall asleep, wake up as you do (use alarm or keys in the hand)&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Hypnagogia&quot;&gt;Hypnagogia&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Meditation
            &lt;ul&gt;
              &lt;li&gt;Sit in silence with the target as an object&lt;br /&gt;
  	&lt;br /&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;hr /&gt;
    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Abstract and Generalize / Transfer over similar problems &amp;amp; solutions&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Model vs. Technique - see what works in the space, ask why to get a model. Generalize from the model to generate more techniques.&lt;/li&gt;
      &lt;li&gt;Metaphor Generation
        &lt;ul&gt;
          &lt;li&gt;Idea list over metaphors for a given problem / solution / object&lt;/li&gt;
          &lt;li&gt;Transfer solutions and insights from the related domains&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Find a source idea, categorize it, generalize to finding more instances of that category.
        &lt;ul&gt;
          &lt;li&gt;Ex. Properties of Representation, Systematizing Creativity&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;List solutions to a problem and generalize&lt;/li&gt;
      &lt;li&gt;List related problems and generalize from their solutions&lt;br /&gt;
  	&lt;br /&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;hr /&gt;
    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Composition / Recombination&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Idea List for concept set&lt;/li&gt;
      &lt;li&gt;Run recombination over generated concepts
        &lt;ol&gt;
          &lt;li&gt;Hold the concepts in mind, asking how they relate to one another&lt;br /&gt;
  	&lt;br /&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;hr /&gt;
    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Idea Lists&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;List Creation + Time Pressure
        &lt;ul&gt;
          &lt;li&gt;Choose a topic / prompt / question.&lt;/li&gt;
          &lt;li&gt;10m Time Constraint.&lt;/li&gt;
          &lt;li&gt;Fill list to 10 ideas.&lt;/li&gt;
          &lt;li&gt;If time becomes a limiting factor, let novelty / quality fall.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Alternative versions:
        &lt;ul&gt;
          &lt;li&gt;Go into diffuse mode over an idea list, with no time limit&lt;/li&gt;
          &lt;li&gt;Create a huge list (with a low barrier to idea entry) and prune it
            &lt;ul&gt;
              &lt;li&gt;This resolves the psychological conflict between creative ideation and rigor / quality&lt;br /&gt;
  	&lt;br /&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;hr /&gt;
    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Decomposition (Mapping out the space)&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Break into component pieces, in multiple directions
        &lt;ul&gt;
          &lt;li&gt;Ex. Machine learning becomes Linear Algebra + Calculus + Probability Theory + Computer Science, which break into their own subregions&lt;/li&gt;
          &lt;li&gt;Ex. Scientific Field becomes Major Papers + Categories of the topic + Conferences + Major Researchers + Quality Sites&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Mutually Exclusive, Collectively Exhaustive&lt;/li&gt;
      &lt;li&gt;Deconstruction + Optimization&lt;/li&gt;
      &lt;li&gt;Actually do science ‘to split’&lt;br /&gt;
  	&lt;br /&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;hr /&gt;
    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Randomness&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Randomize. Generate random ideas by specifying some parameters, and make them work / use them as prompts.&lt;/li&gt;
      &lt;li&gt;Randomly show words that serve as prompts&lt;/li&gt;
      &lt;li&gt;Stream of Consciousness&lt;br /&gt;
  	&lt;br /&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;hr /&gt;
    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Idea Mapping, Graphs of Relationships between Ideas&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Create a graph of the relationships between critical ideas in a space&lt;br /&gt;
  	&lt;br /&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;hr /&gt;
    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Leading questions&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Recursive ‘Why?’&lt;/li&gt;
      &lt;li&gt;Imagine the future (problem is solved, for ex.). What happened? Work backwards.&lt;/li&gt;
      &lt;li&gt;What are the sacred beliefs? What can’t be thought?&lt;/li&gt;
      &lt;li&gt;“what if” questions&lt;/li&gt;
      &lt;li&gt;“how might we” questions&lt;/li&gt;
      &lt;li&gt;Invert - “what if the opposite is true”&lt;/li&gt;
      &lt;li&gt;Eliminate - “does it even matter”&lt;/li&gt;
      &lt;li&gt;“What if I need to solve it once and for all”&lt;/li&gt;
      &lt;li&gt;Scalability - “What if I need to solve it for everyone”&lt;/li&gt;
      &lt;li&gt;What is the meta level idea?&lt;/li&gt;
      &lt;li&gt;What questions do I have about this?&lt;/li&gt;
      &lt;li&gt;What would other people think of?&lt;br /&gt;
  	&lt;br /&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;hr /&gt;
    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Reframe / Question Assumptions&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Constraints
        &lt;ul&gt;
          &lt;li&gt;Create resource constraints (time, attention, money, assumptions, etc.)&lt;/li&gt;
          &lt;li&gt;Create resource excess (time, attention, money, etc.)&lt;/li&gt;
          &lt;li&gt;Eliminating options&lt;/li&gt;
          &lt;li&gt;What are the upstream constraints in the system?&lt;/li&gt;
          &lt;li&gt;Define boundaries of solution spaces better
            &lt;ul&gt;
              &lt;li&gt;Find upstream constraints&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Apply different modes of processing
        &lt;ul&gt;
          &lt;li&gt;What would a supervillain do? (Prompt framing) / Supervillain mode&lt;/li&gt;
          &lt;li&gt;Emotional - Get into emotional state and generate ideas
            &lt;ul&gt;
              &lt;li&gt;Anger&lt;/li&gt;
              &lt;li&gt;Arousal&lt;/li&gt;
              &lt;li&gt;Gratefulness&lt;/li&gt;
              &lt;li&gt;Adoration&lt;/li&gt;
              &lt;li&gt;Frustration&lt;/li&gt;
              &lt;li&gt;Excitement&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Types of Thinker - What would I generate if I was a:
            &lt;ul&gt;
              &lt;li&gt;Mathematician&lt;/li&gt;
              &lt;li&gt;Technologist&lt;/li&gt;
              &lt;li&gt;Computer Scientist&lt;/li&gt;
              &lt;li&gt;Philosopher&lt;/li&gt;
              &lt;li&gt;Psychologist&lt;/li&gt;
              &lt;li&gt;Economist&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;find inspiration in other areas:
            &lt;ul&gt;
              &lt;li&gt;math&lt;/li&gt;
              &lt;li&gt;mythology&lt;/li&gt;
              &lt;li&gt;writings about principles&lt;/li&gt;
              &lt;li&gt;Physics&lt;/li&gt;
              &lt;li&gt;Etc&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Environmental
            &lt;ul&gt;
              &lt;li&gt;Work in a cluttered environment&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Game Lenses, list of generic lenses&lt;/li&gt;
          &lt;li&gt;Asking what would Hufflepuff / Gryffindor / me would do&lt;/li&gt;
          &lt;li&gt;Asking what a friend would do&lt;/li&gt;
          &lt;li&gt;Predicting what someone will say and
            &lt;ul&gt;
              &lt;li&gt;Then asking them, for interesting feedback&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;What? / Why? / How?&lt;br /&gt;
  	&lt;br /&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;hr /&gt;
    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Multiple levels of analysis&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Multiple levels of abstraction - ask what alternate levels of analysis exist, through decomposition and abstraction over the current level of analysis
        &lt;ul&gt;
          &lt;li&gt;Multiple frames - think at lower and higher levels of analysis, simultaneously. Ask how they interact.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Meta-object two space
        &lt;ul&gt;
          &lt;li&gt;Simultaneously optimizing the object and the meta level&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;hr /&gt;
    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Think ground up, from first principles&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Ask what the underlying goal is for a space, and for what solutions would serve that goal. For each solution, think of the components necessary to make that solution happen.
        &lt;ul&gt;
          &lt;li&gt;What are the basic principles of x?
&lt;br /&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;hr /&gt;
    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Automation&lt;/strong&gt; [&lt;a href=&quot;https://docs.google.com/document/d/10e4BJO_krtuSB0vI5Yo7KL98iFFeONCGZPaIFsCa8AM/edit?usp=sharing&quot;&gt;See Expanded Version&lt;/a&gt;]&lt;br /&gt;
  	&lt;br /&gt;&lt;/p&gt;

    &lt;hr /&gt;
    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Thought Habits / Mental&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Idea List Habitually&lt;/li&gt;
      &lt;li&gt;Brainstorm Habitually&lt;/li&gt;
      &lt;li&gt;Create and refine a distinct open mode&lt;/li&gt;
      &lt;li&gt;Create imminent desire for coming up with relevant ideas&lt;/li&gt;
      &lt;li&gt;System 1 + Generalization
        &lt;ul&gt;
          &lt;li&gt;Take an intuitive response and understand its mechanism. Turn the mechanism into a generator.&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;hr /&gt;
    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Invert&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Take any technique, and do the opposite over some parameter&lt;/li&gt;
      &lt;li&gt;Imagine ways of not doing it, or preventing the goal from being reached: adversarial&lt;br /&gt;
	&lt;br /&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;hr /&gt;
    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Activities&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;List Creation + Time Pressure&lt;/li&gt;
      &lt;li&gt;Writing
        &lt;ul&gt;
          &lt;li&gt;Write freely over the topic / question / prompt&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Brainstorm [thought dumping]&lt;/li&gt;
      &lt;li&gt;Defend a difficult position, adversarial conversation&lt;/li&gt;
      &lt;li&gt;Drawing&lt;/li&gt;
      &lt;li&gt;Giving a speech to the air&lt;/li&gt;
      &lt;li&gt;Improv Games&lt;br /&gt;
	&lt;br /&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;hr /&gt;
    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Social Solutions&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Crowdsourcing ideas&lt;/li&gt;
      &lt;li&gt;Read Books / Articles on Topic&lt;/li&gt;
      &lt;li&gt;Debate the topic&lt;/li&gt;
      &lt;li&gt;Look up what other people have been saying about it
        &lt;ul&gt;
          &lt;li&gt;discuss things with others&lt;/li&gt;
          &lt;li&gt;check social media&lt;/li&gt;
          &lt;li&gt;find differing discussions online&lt;/li&gt;
          &lt;li&gt;Mapping ideas generation for other people!&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Work with other dissimilar people&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;!-- ![Moment of Creation](Creative-Hand.jpg) --&gt;</content><author><name></name></author><summary type="html">Solve Creativity. Use it to solve everything else.</summary></entry><entry><title type="html">Google Brain Research Overview</title><link href="http://localhost:4000/jekyll/update/2018/06/07/google-brain-research-overview.html" rel="alternate" type="text/html" title="Google Brain Research Overview" /><published>2018-06-07T05:02:46-07:00</published><updated>2018-06-07T05:02:46-07:00</updated><id>http://localhost:4000/jekyll/update/2018/06/07/google-brain-research-overview</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/06/07/google-brain-research-overview.html">&lt;p&gt;By Jeremy Nixon [&lt;a href=&quot;mailto:jnixon2@gmail.com&quot;&gt;jnixon2@gmail.com&lt;/a&gt;]. Nov 2017.&lt;/p&gt;

&lt;p&gt;Overview&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Categorization of Breakthroughs / Contents&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Major / Minor Researchers List (All appearing on papers)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Genealogy&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sorted Researchers by Paper Count&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Deep Learning&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Scalability and Speed&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Convolutional Neural Networks&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Recurrent Neural Networks&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Privacy&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Understanding / Theory&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Regularization&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Applications&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Speech Recognition&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Image Categorization&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Image Captioning&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Machine Translation&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Natural Language Understanding&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Multi-Modal&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Pedestrian Detection&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Grasp Detection&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Go&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Video&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Dialogue&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;3D Object Reconstruction&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Speaker Verification&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Health Care&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Theorem Proving&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Music&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Pose Estimation&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Speech Generation&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Super Resolution&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Chemistry&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Robotics&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;Autonomous Vehicles&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Physics&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Device Placement&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Games&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Art&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Unsupervised Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Attention&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Memory&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Transfer Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Representation Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Reinforcement Learning&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Model-Based Reinforcement Learning&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Multi-Task Learning&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Metalearning&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Neural Programming&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Hyperparameter Optimization&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Generative&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;GANs&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Interpretability&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Tools, Environments &amp;amp; Datasets&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Adversarial Examples&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Multi-Agent Systems&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Variational Inference&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kernel Machines&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Collaborative Filtering&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Graphical / Relational Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Miscellaneous&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Deep Learning&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Scalability and Speed&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;Large Scale Distributed Deep Networks
            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40565.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40565.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Multiframe Deep Neural Networks for Acoustic Modeling&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40810.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40810.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Asynchronous Stochastic Optimization for Sequence Training of Deep Neural Networks&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42248.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42248.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Tensorflow: Large-Scale Machine Learning on Heterogeneous Distributed Systems&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45166.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45166.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Distilling the Knowledge in a Neural Network&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44873.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44873.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Deep Networks with Large Output Spaces&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1412.7479.pdf&quot;&gt;https://arxiv.org/pdf/1412.7479.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;TensorFlow: A System for Large-Scale Machine Learning&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://www.usenix.org/system/files/conference/osdi16/osdi16-abadi.pdf&quot;&gt;https://www.usenix.org/system/files/conference/osdi16/osdi16-abadi.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Revisiting Distributed Synchronous SGD&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45187.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45187.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Depthwise Separable Convolutions for Neural Machine Translation&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1706.03059&quot;&gt;https://arxiv.org/abs/1706.03059&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Large Scale Distributed Neural Network Training Through Online Distillation&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://openreview.net/pdf?id=rkr1UDeC-&quot;&gt;https://openreview.net/pdf?id=rkr1UDeC-&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;https://openreview.net/pdf?id=SkhQHMW0W&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Convolutional Neural Networks&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;Going Deeper with Convolutions [Inception]&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43022.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43022.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Rethinking the Inception Architecture for Computer Vision&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44903.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44903.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45169.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45169.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Towards Understanding the Invertibility of Convolutional Neural Networks&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;https://arxiv.org/pdf/1705.08664.pdf&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Recurrent Neural Networks&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;Sequence to Sequence Learning with Neural Networks&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43155.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43155.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Sequence Discriminative Distributed Training of Long Short-Term Memory Recurrent Neural Networks&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42547.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42547.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Recurrent Neural Network Regularization [Also, Language Modeling]&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1409.2329&quot;&gt;https://arxiv.org/abs/1409.2329&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Semi-supervised Sequence Learning&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44267.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44267.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Learning to Execute&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://research.google.com/pubs/pub45474.html&quot;&gt;https://research.google.com/pubs/pub45474.html&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;An Empirical Exploration of Recurrent Network Architectures&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://research.google.com/pubs/pub45473.html&quot;&gt;https://research.google.com/pubs/pub45473.html&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;A Simple Way to Initialize Recurrent Networks of Rectified Linear Units&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44961.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44961.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Using Fast Weights to Attend to the Recent Past&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1610.06258.pdf&quot;&gt;https://arxiv.org/pdf/1610.06258.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Unsupervised Pre-training for Sequence to Sequence Learning&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1611.02683.pdf&quot;&gt;https://arxiv.org/pdf/1611.02683.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Order Matters: Sequence to Sequence for Sets&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44871.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44871.pdf&lt;/a&gt;`&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Multi-Task Sequence to Sequence Learning&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44928.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44928.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Generating Sentences from a Continuous Space&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45404.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45404.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Exponential expressivity in deep neural networks through transient chaos&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1606.05340.pdf&quot;&gt;https://arxiv.org/pdf/1606.05340.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;An Online Sequence-to-Sequence Model Using Partial Conditioning&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45167.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45167.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;A Neural Transducer&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1511.04868.pdf&quot;&gt;https://arxiv.org/pdf/1511.04868.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Tuning Recurrent Neural Networks with Reinforcement Learning&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://openreview.net/pdf?id=Syyv2e-Kx&quot;&gt;https://openreview.net/pdf?id=Syyv2e-Kx&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Sequence Tutor: Conservative Fine-Tuning of Sequence Generation Models with KL-control&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1611.02796.pdf&quot;&gt;https://arxiv.org/pdf/1611.02796.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;SGD Learns the Conjugate Kernel Class of the Network&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1702.08503.pdf&quot;&gt;https://arxiv.org/pdf/1702.08503.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Learning Hierarchical Information Flow with Recurrent Neural Modules&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1706.05744.pdf&quot;&gt;https://arxiv.org/pdf/1706.05744.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Latent Sequence Decompositions&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1610.03035.pdf&quot;&gt;https://arxiv.org/pdf/1610.03035.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Capacity and Trainability in Recurrent Neural Networks&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://openreview.net/pdf?id=BydARw9ex&quot;&gt;https://openreview.net/pdf?id=BydARw9ex&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Initialization Matters: Orthogonal Predictive State Recurrent Neural Networks&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;https://openreview.net/pdf?id=HJJ23bW0b&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Privacy&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;Deep Learning with Differential Privacy&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45428.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45428.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Semi-Supervised Knowledge Transfer for Deep Learning from Private Training Data&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1610.05755.pdf&quot;&gt;https://arxiv.org/pdf/1610.05755.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Glimmers: Resolving the Privacy / Trust Quagmire&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46128.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46128.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Scalable Private Learning with PATE&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1802.08908.pdf&quot;&gt;https://arxiv.org/pdf/1802.08908.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Learning Differentially Private Recurrent Language Models [Also, Language Modeling]&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;https://openreview.net/pdf?id=BJ0hF1Z0b&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Understanding / Theory&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;Qualitatively Characterizing Neural Network Optimization Problems&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1412.6544.pdf&quot;&gt;https://arxiv.org/pdf/1412.6544.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Toward Deeper Understanding of Neural Networks: The Power of Initialization and a Dual View on Expressivity&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1602.05897.pdf&quot;&gt;https://arxiv.org/pdf/1602.05897.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Understanding Deep Learning Requires Re-Thinking Generalization&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1611.03530.pdf&quot;&gt;https://arxiv.org/pdf/1611.03530.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Sharp Minima Can Generalize for Deep Nets&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1703.04933.pdf&quot;&gt;https://arxiv.org/pdf/1703.04933.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;On the Expressive Power of Deep Neural Networks&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1606.05336.pdf&quot;&gt;https://arxiv.org/pdf/1606.05336.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Nonlinear Random Matrix Theory for Deep Learning&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46342.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46342.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Mean Field Residual Networks: On the Edge of Chaos&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/6879-mean-field-residual-networks-on-the-edge-of-chaos.pdf&quot;&gt;http://papers.nips.cc/paper/6879-mean-field-residual-networks-on-the-edge-of-chaos.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Identity Matters in Deep Learning&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1611.04231.pdf&quot;&gt;https://arxiv.org/pdf/1611.04231.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Geometry of Neural Network Loss Surfaces via Random Matrix Theory&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;http://proceedings.mlr.press/v70/pennington17a/pennington17a.pdf&quot;&gt;http://proceedings.mlr.press/v70/pennington17a/pennington17a.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Explaining the Learning Dynamics of Direct Feedback Alignment&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://openreview.net/pdf?id=HkXKUTVFl&quot;&gt;https://openreview.net/pdf?id=HkXKUTVFl&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Deep Information Propagation&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://openreview.net/pdf?id=H1W1UN9gg&quot;&gt;https://openreview.net/pdf?id=H1W1UN9gg&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;The Emergence of Spectral Universality in Deep Networks&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1802.09979.pdf&quot;&gt;https://arxiv.org/pdf/1802.09979.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Sensitivity and Generalization in Neural Networks: An Empirical Study&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1802.08760.pdf&quot;&gt;https://arxiv.org/pdf/1802.08760.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Gradient Descent with identity initialization efficiently learns positive definite linear transformations by deep residual networks&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1802.06093.pdf&quot;&gt;https://arxiv.org/pdf/1802.06093.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Deep Neural Networks as Gaussian Processes&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://openreview.net/pdf?id=B1EA-M-0Z&quot;&gt;https://openreview.net/pdf?id=B1EA-M-0Z&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;A Bayesian Perspective on Generalization and Stochastic Gradient Descent&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://openreview.net/pdf?id=BJij4yg0Z&quot;&gt;https://openreview.net/pdf?id=BJij4yg0Z&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Regularization&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;Adding Gradient Noise Improves Learning for Very Deep Networks&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45137.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45137.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Surprising Properties of Dropout in Deep Networks&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;http://www.phillong.info/publications/HL17_deep_dropout.pdf&quot;&gt;http://www.phillong.info/publications/HL17_deep_dropout.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Regularizing Neural Networks by Penalizing Confident Output Distributions&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1701.06548.pdf&quot;&gt;https://arxiv.org/pdf/1701.06548.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;A Unified Approach to Adaptive Regularization in Online and Stochastic Optimization&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;https://arxiv.org/pdf/1706.06569.pdf&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Training Highly Multiclass Classifiers&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41872.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41872.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Random Walk Initialization for Training Very Deep Feedforward Networks&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1412.6558.pdf&quot;&gt;https://arxiv.org/pdf/1412.6558.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Learning Factored Representations in a Deep Mixture of Experts&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1312.4314.pdf&quot;&gt;https://arxiv.org/pdf/1312.4314.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Training Deep Neural Networks on Noisy Labels with Bootstrapping&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43273.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43273.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Convolutional, Long Short-Term Memory, Fully Connected Deep Neural Networks&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43455.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43455.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Reward Augmented Maximum Likelihood for Neural Structured Prediction&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45580.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45580.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;MuProp: Unbiased Backpropagation for Stochastic Neural Networks&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1511.05176v3.pdf&quot;&gt;https://arxiv.org/pdf/1511.05176v3.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Chained predictions using convolutional neural networks&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://research.google.com/pubs/pub45945.html&quot;&gt;https://research.google.com/pubs/pub45945.html&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Training a Subsampling Mechanism in Expectation&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://openreview.net/pdf?id=BJBkkaNYe&quot;&gt;https://openreview.net/pdf?id=BJBkkaNYe&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Resurrecting the Sigmoid in deep learning through dynamical isometry: theory and practice&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46341.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46341.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://openreview.net/pdf?id=B1ckMDqlg&quot;&gt;https://openreview.net/pdf?id=B1ckMDqlg&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;On Blackbox Backpropagation and Jacobian Sensing&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://research.google.com/pubs/pub46347.html&quot;&gt;https://research.google.com/pubs/pub46347.html&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Deep Value Networks Learn to Evaluate and Iteratively Refine Structured Outputs&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1703.04363.pdf&quot;&gt;https://arxiv.org/pdf/1703.04363.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Critical Hyper-Parameters: No Random, No Cry&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1706.03200.pdf&quot;&gt;https://arxiv.org/pdf/1706.03200.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Distilling a Neural Network into a Soft Decision Tree&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1711.09784.pdf&quot;&gt;https://arxiv.org/pdf/1711.09784.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Categorical Reparameterization with Gumbel-Softmax&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1611.01144.pdf&quot;&gt;https://arxiv.org/pdf/1611.01144.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Training Confidence-Calibrated Classifiers For Detecting Out-of-Distribution Samples&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://openreview.net/pdf?id=ryiAv2xAZ&quot;&gt;https://openreview.net/pdf?id=ryiAv2xAZ&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Fidelity-Weighted Learning&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://openreview.net/pdf?id=B1X0mzZCW&quot;&gt;https://openreview.net/pdf?id=B1X0mzZCW&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Don’t Decay the Learning Rate, Increase the Batch Size&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;https://openreview.net/pdf?id=B1Yy1BxCZ&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Applications&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Speech Recognition&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;Deep Neural Networks for Acoustic Modeling in Speech Recognition&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/38131.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/38131.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Application of Pre-trained Deep Neural Networks to Large Vocabulary Speech Recognition&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/38130.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/38130.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;On Rectified Linear Units for Speech Processing&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40811.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40811.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Multilingual Acoustic Models Using Distributed Deep Neural Networks&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40807.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40807.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;An Empirical Study of Learning Rates in DNNs for Speech Recognition&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40808.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40808.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Word Embeddings for Speech Recognition&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42543.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42543.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Autoregressive product of multi-frame predictions can improve the accuracy of hybrid models&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42947.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42947.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Learning the Speech Front-end with Raw Waveform CLDNNs&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43960.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43960.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Acoustic Modeling for Google Home&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;http://www.cs.cmu.edu/~chanwook/MyPapers/b_li_interspeech_2017.pdf&quot;&gt;http://www.cs.cmu.edu/~chanwook/MyPapers/b_li_interspeech_2017.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Multilingual Speech Recognition With a Single End-to-End Model&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1711.01694.pdf&quot;&gt;https://arxiv.org/pdf/1711.01694.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;An Analysis of Incorporating an External Language Model into a Sequence-to-Sequence Model&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;https://arxiv.org/pdf/1712.01996.pdf&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Image Classification&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;Using Web Co-occurrence Statistics for Improving Image Categorization&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42244.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42244.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;The Unreasonable Effectiveness of Noisy Data for Fine-Grained Recognition&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1511.06789.pdf&quot;&gt;https://arxiv.org/pdf/1511.06789.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Image Captioning&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;Grounded Compositional Semantics for Finding and Describing Images with Sentences&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://nlp.stanford.edu/~socherr/SocherKarpathyLeManningNg_TACL2013.pdf&quot;&gt;https://nlp.stanford.edu/~socherr/SocherKarpathyLeManningNg_TACL2013.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Show and Tell: A Neural Image Caption Generator&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43274.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43274.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Learning Semantic Relationships for Better Action Retrieval in Images&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43443.pdf&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Machine Translation&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;Exploiting Similarities among Languages for Machine Translation&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44931.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44931.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Addressing the Rare Word Problem in Neural Machine Translation&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44929.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44929.pdf&lt;/a&gt;&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;81. [https://arxiv.org/abs/1609.08144](https://arxiv.org/abs/1609.08144)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Sequence-to-Sequence Models Can Directly Translate Foreign Speech&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;82. [https://arxiv.org/pdf/1703.08581.pdf](https://arxiv.org/pdf/1703.08581.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Massive Exploration of Neural Machine Translation Architectures&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;83. https://arxiv.org/pdf/1703.03906.pdf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Natural Language Understanding&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;Efficient Estimation of Word Representations in Vector Space&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;84. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41224.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41224.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Distributed Representations of Words and Their Compositionality&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;85. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44876.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44876.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Zero-Shot Learning by Convex Combination of Semantic Embeddings&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;86. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42371.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42371.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Distributed Representations of Sentences and Documents&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;87. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44930.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44930.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Sentence Compression by Deletion with LSTMs&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;88. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43852.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43852.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Grammar as a Foreign Language&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;89. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43799.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43799.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;BilBOWA: Fast Bilingual Distributed Representations without Word Alignments&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;90. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45190.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45190.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Multilingual Language Processing From Bytes&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;91. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45170.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45170.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Exploring the Limits of Language Modeling&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;92. [https://arxiv.org/pdf/1602.02410.pdf](https://arxiv.org/pdf/1602.02410.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Towards better decoding and language model integration in sequence to sequence models&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;93. [https://arxiv.org/pdf/1612.02695.pdf](https://arxiv.org/pdf/1612.02695.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Learning to Skim Text&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;94. [https://arxiv.org/pdf/1704.06877.pdf](https://arxiv.org/pdf/1704.06877.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Get To The Point: Summarization with Pointer-Generator Networks&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;95. [https://arxiv.org/pdf/1704.04368.pdf](https://arxiv.org/pdf/1704.04368.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Generating Wikipedia by Summarizing Long Sequences&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;96. [https://openreview.net/pdf?id=Hyg0vbWC-](https://openreview.net/pdf?id=Hyg0vbWC-)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;An Efficient Framework for Learning Sentence Representations&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;97. https://openreview.net/pdf?id=rJvJXZb0W
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Multi-Modal&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;DeViSE: A Deep Visual-Semantic Embedding Model&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;98. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41869.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41869.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Modulating Early Visual Processing by Language&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;99. [https://arxiv.org/pdf/1707.00683.pdf](https://arxiv.org/pdf/1707.00683.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Context-aware Captions from Context-agnostic Supervision&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;100. [http://openaccess.thecvf.com/content_cvpr_2017/papers/Vedantam_Context-Aware_Captions_From_CVPR_2017_paper.pdf](http://openaccess.thecvf.com/content_cvpr_2017/papers/Vedantam_Context-Aware_Captions_From_CVPR_2017_paper.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Better Text Understanding Through Image-To-Text Transfer&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;101. https://arxiv.org/pdf/1705.08386.pdf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Pedestrian Detection&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;Real Time Pedestrian Detection with Deep Network Cascades&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;102. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43850.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43850.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Pedestrian Detection with a Large Field-Of-View Deep Network&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;103. https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43849.pdf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Grasp Detection&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;Real-Time Grasp Detection Using Convolutional Neural Networks&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;104. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43875.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43875.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Go&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;Move Evaluation in Go Using Deep Convolutional Neural Networks&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;105. [https://arxiv.org/pdf/1412.6564.pdf](https://arxiv.org/pdf/1412.6564.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Mastering the game of Go with deep neural networks and tree search&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;106. https://www.nature.com/articles/nature16961
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Video&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;Beyond Short Snippets: Deep Networks for Video Classification&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;107. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43793.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43793.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Dialogue&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;A Neural Conversational Model&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;108. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44925.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44925.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Smart Reply: Automated Response Suggestion for Email&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;109. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45189.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45189.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Adversarial Evaluation of Dialogue Models&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;110. [https://arxiv.org/pdf/1701.08198.pdf](https://arxiv.org/pdf/1701.08198.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Generating High-Quality and Informative Conversation Responses with Sequence-to-Sequence Models&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;111. https://arxiv.org/pdf/1701.03185.pdf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;3D Object Reconstruction&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1612.00814.pdf&quot;&gt;https://arxiv.org/pdf/1612.00814.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Speaker Verification&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;End-to-End Text-Dependent Speaker Verification&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;112. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44681.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44681.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Health Care&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;113. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45732.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45732.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Theorem Proving&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;DeepMath - Deep Sequence Models for Premise Selection&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;114. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45402.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45402.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Deep Network Guided Proof Search&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;115. https://arxiv.org/pdf/1701.06972.pdf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Music&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;Audio Deepdream: Optimizing Raw Audio with Convolutional Networks&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;116. https://18798-presscdn-pagely.netdna-ssl.com/ismir2016/wp-content/uploads/sites/2294/2016/08/ardila-audio.pdf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Generating Music by Fine-Tuning Recurrent Neural Networks with Reinforcement Learning&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;117. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45871.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45871.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;118. https://arxiv.org/pdf/1704.01279.pdf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Pose Estimation&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;Towards Accurate Multi-person Pose Estimation in the Wild&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;119. [https://arxiv.org/pdf/1701.01779.pdf](https://arxiv.org/pdf/1701.01779.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Speech Generation&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;Tacotron: Towards End-to-End Speech Synthesis&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;120. [https://arxiv.org/pdf/1703.10135.pdf](https://arxiv.org/pdf/1703.10135.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;RNN Approaches to Text Normalization: A Challenge&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;121. [https://arxiv.org/pdf/1611.00068.pdf](https://arxiv.org/pdf/1611.00068.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;On Using Backpropagation for Speech texture Generation and Voice Cnversion&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;122. [https://arxiv.org/pdf/1712.08363.pdf](https://arxiv.org/pdf/1712.08363.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Natural TTS Synthesis by Conditioning Wavenet on Mel Spectrogram Prediction [Tacotron 2]&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;123. https://arxiv.org/pdf/1712.05884.pdf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Super Resolution&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;Pixel Recursive Super Resolution&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;124. [https://arxiv.org/pdf/1702.00783.pdf](https://arxiv.org/pdf/1702.00783.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Chemistry&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;Neural Message Passing for Quantum Chemistry&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;125. [https://arxiv.org/pdf/1704.01212.pdf](https://arxiv.org/pdf/1704.01212.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Robotics&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;Autonomous Vehicles&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;126. Learning with Proxy Supervision for End-To-End Visual Learning

    1. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45985.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45985.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Learning Robotic Manipulation of Granular Media&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;127. [https://arxiv.org/pdf/1709.02833.pdf](https://arxiv.org/pdf/1709.02833.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;128. [https://drive.google.com/file/d/0B0mFoBMu8f8BaHYzOXZMdzVOalU/view](https://drive.google.com/file/d/0B0mFoBMu8f8BaHYzOXZMdzVOalU/view)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;End-to-End Learning of Semantic Grasping&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;129. [https://arxiv.org/pdf/1707.01932.pdf](https://arxiv.org/pdf/1707.01932.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Cognitive Mapping and Planning for Visual Navigation&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;130. [https://arxiv.org/pdf/1702.03920.pdf](https://arxiv.org/pdf/1702.03920.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;131. https://arxiv.org/pdf/1709.07857.pdf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Physics&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;Accelerating Eulerian Fluid Simulation with Convolutional Networks&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;132. [https://arxiv.org/pdf/1607.03597.pdf](https://arxiv.org/pdf/1607.03597.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Device Placement&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;Device Placement Optimization with Reinforcement Learning&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;133. [https://arxiv.org/pdf/1706.04972.pdf](https://arxiv.org/pdf/1706.04972.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;A Hierarchical Model for Device Placement&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;134. [https://openreview.net/pdf?id=Hkc-TeZ0W](https://openreview.net/pdf?id=Hkc-TeZ0W)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Games&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;Can Deep Reinforcement Learning Solve Erdos-Selfridge-Spencer Games?&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;135. [https://arxiv.org/pdf/1711.02301.pdf](https://arxiv.org/pdf/1711.02301.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Art&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;A Neural Representation of Sketch Drawings&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;136. https://arxiv.org/pdf/1704.03477.pdf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Unsupervised Learning&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Building High-level Features Using Large Scale Unsupervised Learning&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/38115.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/38115.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Towards Principled Unsupervised Learning&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1511.06440.pdf&quot;&gt;https://arxiv.org/pdf/1511.06440.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Time-Contrastive Networks: Self-Supervised Learning from Video&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1704.06888.pdf&quot;&gt;https://arxiv.org/pdf/1704.06888.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Stochastic Variational Video prediction [Also, Model-Based RL]&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1710.11252.pdf&quot;&gt;https://arxiv.org/pdf/1710.11252.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Short and Deep: Sketching Neural Networks&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://openreview.net/pdf?id=r1br_2Kge&quot;&gt;https://openreview.net/pdf?id=r1br_2Kge&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Geometry-Based Next Frame Prediction from Monocular Video&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45984.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45984.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Decomposing Motion and Content for Natural Video Sequence Prediction&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://sites.google.com/a/umich.edu/rubenevillegas/iclr2017&quot;&gt;https://sites.google.com/a/umich.edu/rubenevillegas/iclr2017&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Cross-View Training for Semi-Supervised Learning&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;https://openreview.net/forum?id=BJubPWZRW&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Attention&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;On Learning Where to Look&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://research.google.com/pubs/pub45477.html&quot;&gt;https://research.google.com/pubs/pub45477.html&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Pointer Networks&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1506.03134.pdf&quot;&gt;https://arxiv.org/pdf/1506.03134.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Attention for Fine-Grained Categorization&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1412.7054.pdf&quot;&gt;https://arxiv.org/pdf/1412.7054.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Listen, Attend and Spell&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44926.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44926.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Collective Entity Resolution with Multi-Focal Attention&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45395.pdf&quot;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45395.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Attend, Infer, Repeat: Fast Scene Understanding with Generative Models&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1603.08575.pdf&quot;&gt;https://arxiv.org/pdf/1603.08575.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Online and Linear-Time Attention by Enforcing Monotonic Alignments&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://research.google.com/pubs/pub46110.html&quot;&gt;https://research.google.com/pubs/pub46110.html&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Learning Hard Alignments with Variational Inference [Hard Attention]&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1705.05524.pdf&quot;&gt;https://arxiv.org/pdf/1705.05524.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Efficient Attention using a Fixed-Size Memory Representation&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1707.00110.pdf&quot;&gt;https://arxiv.org/pdf/1707.00110.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Attention is All You Need&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1706.03762.pdf&quot;&gt;https://arxiv.org/pdf/1706.03762.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;An Analysis of “Attention” in Sequence-to-Sequence Models&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;http://www.isca-speech.org/archive/Interspeech_2017/pdfs/0232.PDF&quot;&gt;http://www.isca-speech.org/archive/Interspeech_2017/pdfs/0232.PDF&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Monotonic Chunkwise Attention&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;https://openreview.net/pdf?id=Hko85plCW&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Memory&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Learning to Remember Rare Events&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;https://openreview.net/pdf?id=SJTQLdqlg&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Transfer Learning&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Net2Net: Accelerating Learning via Knowledge Transfer&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1511.05641.pdf&quot;&gt;https://arxiv.org/pdf/1511.05641.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Domain Separation Networks&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1608.06019.pdf&quot;&gt;https://arxiv.org/pdf/1608.06019.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Unsupervised Pixel-Level Domain Adaptation with Generative Adversarial Networks&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1612.05424.pdf&quot;&gt;https://arxiv.org/pdf/1612.05424.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;PathNet: Evolution Channels Gradient Descent in Super Neural networks&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1701.08734.pdf&quot;&gt;https://arxiv.org/pdf/1701.08734.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;One Model to Learn Them All&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1706.05137.pdf&quot;&gt;https://arxiv.org/pdf/1706.05137.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Exploring the structure of a real-time, arbitrary neural artistic stylization network&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1705.06830.pdf&quot;&gt;https://arxiv.org/pdf/1705.06830.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;A Brief Study of In-Domain Transfer and Learning from Fewer Samples using a Few Simple Priors&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;https://arxiv.org/pdf/1707.03979.pdf&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Representation Learning&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1706.05806.pdf&quot;&gt;https://arxiv.org/pdf/1706.05806.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;A Learned Representation for Artistic Style&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1610.07629.pdf&quot;&gt;https://arxiv.org/pdf/1610.07629.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Learning Latent Permutations with Gumbel-Sinkhorn Networks&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;https://openreview.net/pdf?id=Byt3oJ-0W&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Reinforcement Learning&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Model-Based Reinforcement Learning&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;Unsupervised Learning for Physical Interaction through Video Prediction [Also, Robotics]&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;137. [https://arxiv.org/pdf/1605.07157.pdf](https://arxiv.org/pdf/1605.07157.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Continuous Deep Q-Learning with Model-based Acceleration&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;138. [http://proceedings.mlr.press/v48/gu16.pdf](http://proceedings.mlr.press/v48/gu16.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Value Prediction Network&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;139. [https://arxiv.org/pdf/1707.03497.pdf](https://arxiv.org/pdf/1707.03497.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Learning to Generate Long-term Future via Hierarchical Prediction&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;140. [https://arxiv.org/pdf/1704.05831.pdf](https://arxiv.org/pdf/1704.05831.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Discrete Sequential Prediction of Continuous Actions for Deep RL&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;141. [https://arxiv.org/pdf/1705.05035.pdf](https://arxiv.org/pdf/1705.05035.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Deep Visual Foresight for Planning Robot Motion [Also, Robotics]&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;142. [https://arxiv.org/pdf/1610.00696.pdf](https://arxiv.org/pdf/1610.00696.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ol&gt;
          &lt;li&gt;Temporal Difference Models: Model-Free Deep RL for Model-Based Control&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;143. [https://openreview.net/pdf?id=Skw0n-W0Z](https://openreview.net/pdf?id=Skw0n-W0Z)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Multi-Task Learning&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;Zero-Shot Task Generalization with Multi-Task Deep Reinforcement Learning&lt;/li&gt;
        &lt;/ol&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;144. [https://arxiv.org/pdf/1706.05064.pdf](https://arxiv.org/pdf/1706.05064.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Unsupervised Perceptual Rewards for Imitation Learning&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://openreview.net/pdf?id=Byf3mmNFl&quot;&gt;https://openreview.net/pdf?id=Byf3mmNFl&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Trust-PCL: An Off-Policy Trust Region Method for Continuous Control&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1707.01891.pdf&quot;&gt;https://arxiv.org/pdf/1707.01891.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Robust Adversarial Reinforcement Learning [Also, Multi-Agent Systems]&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1703.02702.pdf&quot;&gt;https://arxiv.org/pdf/1703.02702.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;REBAR: Low-Variance, unbiased gradient estimates for discrete latent variable models&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1703.07370.pdf&quot;&gt;https://arxiv.org/pdf/1703.07370.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Q-Prop: Sample Efficient Policy Gradient with an Off-Policy Critic&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1611.02247.pdf&quot;&gt;https://arxiv.org/pdf/1611.02247.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Particle Value Functions&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://openreview.net/pdf?id=BJyBKyHKg&quot;&gt;https://openreview.net/pdf?id=BJyBKyHKg&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Path Integral Guided Policy Search [Also, Robotics]&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1610.00529.pdf&quot;&gt;https://arxiv.org/pdf/1610.00529.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Interpolated Policy Gradient: Merging On-Policy and Off-Policy Gradient Estimation for Deep Reinforcement Learning&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1706.00387.pdf&quot;&gt;https://arxiv.org/pdf/1706.00387.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Improving Policy Gradient by Exploring Under-Appreciated Rewards&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://openreview.net/pdf?id=ryT4pvqll&quot;&gt;https://openreview.net/pdf?id=ryT4pvqll&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Deep Reinforcement Learning for Robotic Manipulation with Asynchronous Off-Policy Updates&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1610.00633.pdf&quot;&gt;https://arxiv.org/pdf/1610.00633.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Collective Robot Reinforcement Learning with Distributed Asynchronous Guided Policy Search&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1610.00673.pdf&quot;&gt;https://arxiv.org/pdf/1610.00673.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Changing Model Behavior at Test Time Using Reinforcement Learning&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1702.07780.pdf&quot;&gt;https://arxiv.org/pdf/1702.07780.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Bridging the Gap Between Value and Policy Based Reinforcement Learning&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1702.08892.pdf&quot;&gt;https://arxiv.org/pdf/1702.08892.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;A comparative study of counterfactual estimators&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1704.00773.pdf&quot;&gt;https://arxiv.org/pdf/1704.00773.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;PRM-RL: Long Range Robotic Navigatio nTasks by Combining Reinforcement Learning and Sampling-based Planning&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1710.03937.pdf&quot;&gt;https://arxiv.org/pdf/1710.03937.pdf&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Path consistency Learning in Tsallis Entropy Regularized MDPs&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1802.03501&quot;&gt;https://arxiv.org/abs/1802.03501&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Leave No Trace: Learning to Reset for Safe and Autonomous Reinforcement Learning&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; 212. [https://openreview.net/pdf?id=S1vuO-bCW](https://openreview.net/pdf?id=S1vuO-bCW)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Deep Bayesian Bandits Showdown&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; 213. https://openreview.net/pdf?id=SyYe6k-CW
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Metalearning&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Neural Programming&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; 214. Reinforcement Learning Neural Turing Machines

     145. [https://research.google.com/pubs/pub45478.html](https://research.google.com/pubs/pub45478.html)

 215. Neural Random-Access Machines

     146. [https://research.google.com/pubs/pub45472.html](https://research.google.com/pubs/pub45472.html)

 216. Neural Programmer: Inducing Latent Programs with Gradient Descent

     147. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44927.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44927.pdf)

 217. Neural GPUs Learn Algorithms

     148. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45139.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45139.pdf)

 218. Learning a Natural Language Interface with Neural Programmer

     149. https://arxiv.org/pdf/1611.08945.pdf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Hyperparameter Optimization&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; 219. Toward Optimal Run Racing: Application to Deep Learning Calibration

     150. [https://arxiv.org/pdf/1706.03199.pdf](https://arxiv.org/pdf/1706.03199.pdf)

 220. Searching for Activation Functions

     151. [https://arxiv.org/pdf/1710.05941.pdf](https://arxiv.org/pdf/1710.05941.pdf)

 221. Neural Optimizer Search with Reinforcement Learning

     152. [https://arxiv.org/pdf/1709.07417.pdf](https://arxiv.org/pdf/1709.07417.pdf)

 222. Neural Combinatorial Optimization with Reinforcement Learning

     153. [https://openreview.net/pdf?id=Bk9mxlSFx](https://openreview.net/pdf?id=Bk9mxlSFx)

 223. Neural Architecture Search with Reinforcement Learning

     154. [https://arxiv.org/pdf/1611.01578.pdf](https://arxiv.org/pdf/1611.01578.pdf)

 224. Large-Scale Evolution of Image Classifiers

     155. [https://arxiv.org/pdf/1703.01041.pdf](https://arxiv.org/pdf/1703.01041.pdf)

 225. Searching for Activation Functions

     156. https://arxiv.org/pdf/1710.05941.pdf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Learned Optimizers that Scale and Generalize&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; 226. [https://arxiv.org/pdf/1703.04813.pdf](https://arxiv.org/pdf/1703.04813.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;HyperNetworks&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; 227. [https://openreview.net/pdf?id=rkpACe1lx](https://openreview.net/pdf?id=rkpACe1lx)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Supervised Learning of Unsupervised Learning Rules&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; 228. [http://metalearning.ml/papers/metalearn17_metz.pdf](http://metalearning.ml/papers/metalearn17_metz.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;MorphNet: Fast &amp;amp; Simple Resource-Constrained Structure Learning of Deep Networks&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; 229. [https://arxiv.org/pdf/1711.06798.pdf](https://arxiv.org/pdf/1711.06798.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;A Meta-Learning Perspective on Cold-Start Recommendations for Items&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; 230. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46346.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46346.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Meta-Learning for Semi-Supervised Few-Shot Classification&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; 231. [https://openreview.net/pdf?id=HJcSzz-CZ](https://openreview.net/pdf?id=HJcSzz-CZ)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Generalizing Hamiltonian Monte Carlo with Neural Networks&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; 232. https://openreview.net/pdf?id=B1n8LexRZ
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Generative&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;GANs&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;233. Improved Generator Objectives for GANs

    157. [https://arxiv.org/pdf/1612.02780.pdf](https://arxiv.org/pdf/1612.02780.pdf)

234. Unrolled Generative Adversarial Networks

    158. [https://openreview.net/pdf?id=BydrOIcle](https://openreview.net/pdf?id=BydrOIcle)

235. Improving Image Generative Models with Human Interactions

    159. [https://arxiv.org/pdf/1709.10459.pdf](https://arxiv.org/pdf/1709.10459.pdf)

236. Conditional Image Synthesis with Auxiliary Classifier GANs

    160. [https://arxiv.org/pdf/1610.09585.pdf](https://arxiv.org/pdf/1610.09585.pdf)

237. Are GANs Created Equal? A Large-Scale Study

    161. [https://arxiv.org/pdf/1711.10337.pdf](https://arxiv.org/pdf/1711.10337.pdf)

238. AdaGAN: Boosting Generative Models

    162. [https://arxiv.org/pdf/1701.02386.pdf](https://arxiv.org/pdf/1701.02386.pdf)

239. MaskGAN: Better Text Generation Via Filling in the _____

    163. [https://openreview.net/pdf?id=ByOExmWAb](https://openreview.net/pdf?id=ByOExmWAb)

240. Many Paths to Equilibrium: GANs Do Not Need to Decrease a Divergence at Every Step

    164. https://openreview.net/pdf?id=ByQpn1ZA-
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Experiments in Handwriting with a Neural Network&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;241. [https://distill.pub/2016/handwriting/](https://distill.pub/2016/handwriting/)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;From optimal transport to generative modeling: the VEGAN cookbook&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;242. [https://arxiv.org/pdf/1705.07642.pdf](https://arxiv.org/pdf/1705.07642.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Density Estimation Using Real NVP&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;243. [https://arxiv.org/pdf/1605.08803.pdf](https://arxiv.org/pdf/1605.08803.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;A Neural Representation of Sketch Drawings&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;244. [https://arxiv.org/pdf/1704.03477.pdf](https://arxiv.org/pdf/1704.03477.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Wasserstein Auto-Encoders&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;245. [https://arxiv.org/pdf/1711.01558.pdf](https://arxiv.org/pdf/1711.01558.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Stochastic Variational Video Prediction&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;246. [https://openreview.net/pdf?id=rk49Mg-CW](https://openreview.net/pdf?id=rk49Mg-CW)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Latent Constraints: Learning to Generate Conditionally From Unconditional Generative Models&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;247. https://openreview.net/pdf?id=Sy8XvGb0-
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Interpretability&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Deconvolution and Checkerboard Artifacts&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;248. [https://distill.pub/2016/deconv-checkerboard/](https://distill.pub/2016/deconv-checkerboard/)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Visualizing Dataflow Graphs of Deep Learning Models in Tensorflow&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;249. [http://idl.cs.washington.edu/files/2018-TensorFlowGraph-VAST.pdf](http://idl.cs.washington.edu/files/2018-TensorFlowGraph-VAST.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Towards A Rigorous Science of Interpretable Machine Learning&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;250. [https://arxiv.org/pdf/1702.08608.pdf](https://arxiv.org/pdf/1702.08608.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;The (Un)reliability of Saliency Methods&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;251. [https://arxiv.org/pdf/1711.00867.pdf](https://arxiv.org/pdf/1711.00867.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Input Switched Affine Networks: An RNN Architecture Designed for Interpretability [Also, Recurrent Neural Networks]&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;252. [https://arxiv.org/pdf/1611.09434.pdf](https://arxiv.org/pdf/1611.09434.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;VisualBackProp: Efficient Visualization of CNNs&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;253. [https://arxiv.org/abs/1611.05418](https://arxiv.org/abs/1611.05418)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Learning How to Explain Neural Networks: PatternNet and PatternAttribution&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;254. [https://openreview.net/pdf?id=Hkn7CBaTW](https://openreview.net/pdf?id=Hkn7CBaTW)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Beyond Word Importance: Contextual Decomposition to Extract Interactions from LSTMs [Also, Recurrent Neural Networks]&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;255. https://openreview.net/pdf?id=rkRwGg-0Z
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Tools, Environments &amp;amp; Datasets&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;One Billion Word Benchmark for Measuring Progress in Statistical Language Modeling&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;256. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41880.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41880.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Adversarial Examples&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Intriguing Properties of Neural Networks&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;257. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42503.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42503.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Explaining and Harnessing Adversarial Examples&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;258. [https://arxiv.org/pdf/1412.6572.pdf](https://arxiv.org/pdf/1412.6572.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Virtual Adversarial Training for Semi-Supervised Text Classification&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;259. [https://research.google.com/pubs/pub45403.html](https://research.google.com/pubs/pub45403.html)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;The Space of Transferable Adversarial Examples&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;260. [https://arxiv.org/pdf/1704.03453.pdf](https://arxiv.org/pdf/1704.03453.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Adversarial Examples in the Physical World&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;261. [https://arxiv.org/pdf/1607.02533.pdf](https://arxiv.org/pdf/1607.02533.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Adversarial Training Methods for Semi-Supervised Text Classification&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;262. [https://arxiv.org/pdf/1605.07725.pdf](https://arxiv.org/pdf/1605.07725.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Adversarial Machine Learning at Scale&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;263. [https://arxiv.org/pdf/1611.01236.pdf](https://arxiv.org/pdf/1611.01236.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Thermometer Encoding: One Hot Way to Resist Adversarial Examples&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;264. [https://openreview.net/pdf?id=S18Su--CW](https://openreview.net/pdf?id=S18Su--CW)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Intriguing Properties of Adversarial Examples&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;265. [https://arxiv.org/pdf/1711.02846.pdf](https://arxiv.org/pdf/1711.02846.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Ensemble Adversarial Training: Attacks and Defences&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;266. [https://openreview.net/pdf?id=rkZvSe-RZ](https://openreview.net/pdf?id=rkZvSe-RZ)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Adversarial Spheres&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;267. https://arxiv.org/pdf/1801.02774.pdf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Multi-Agent Systems&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Learning to Protect Communications with Adversarial Neural Cryptography&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;268. [https://arxiv.org/pdf/1610.06918.pdf](https://arxiv.org/pdf/1610.06918.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Adversarial Autoencoders&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;269. [https://arxiv.org/pdf/1511.05644.pdf](https://arxiv.org/pdf/1511.05644.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;XGAN: Unsupervised Image-To-Image Translation for Many-To-Many Mappings&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;270. [https://arxiv.org/pdf/1711.05139.pdf](https://arxiv.org/pdf/1711.05139.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Supervision via Competition: Robot Adversaries for Learning Tasks&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;271. https://arxiv.org/pdf/1610.01685.pdf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Variational Inference&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Variational Boosting: Iteratively Refining Posterior Approximations&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;272. [https://arxiv.org/pdf/1611.06585.pdf](https://arxiv.org/pdf/1611.06585.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Reducing Reparameterization Gradient Variance&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;273. [https://arxiv.org/pdf/1705.07880.pdf](https://arxiv.org/pdf/1705.07880.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Filtering Variational Objectives&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kernel Machines&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Fastfood - Approximating Kernel Expansions in Loglinear Time&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;274. [http://www-cs.stanford.edu/~quocle/LeSarlosSmola_ICML13.pdf](http://www-cs.stanford.edu/~quocle/LeSarlosSmola_ICML13.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Random Features for Compositional Kernels&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;275. [https://arxiv.org/pdf/1703.07872.pdf](https://arxiv.org/pdf/1703.07872.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;The Geometry of Random Features&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;276. http://storage.googleapis.com/pub-tools-public-publication-data/pdf/70a89b15f9b160dd10248de8862d1584f03ddc22.pdf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Collaborative Filtering&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Local Collaborative Ranking&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;277. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42242.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42242.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Graphical / Relational Learning&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Large-Scale Object Classification Using Label Relation Graphs&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;278. [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42854.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42854.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Graph Searching Games and Width Measures for Directed Graphs&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;279. [http://drops.dagstuhl.de/opus/volltexte/2015/4902/pdf/2.pdf](http://drops.dagstuhl.de/opus/volltexte/2015/4902/pdf/2.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Graph Partition Neural Networks for Semi-Supervised Classification&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;280. https://arxiv.org/pdf/1803.06272.pdf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Miscellaneous&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Tensorflow: Learning Functions at Scale&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;281. [https://dl.acm.org/citation.cfm?id=2976746](https://dl.acm.org/citation.cfm?id=2976746)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Deep Learning Games&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;282. [https://papers.nips.cc/paper/6315-deep-learning-games.pdf](https://papers.nips.cc/paper/6315-deep-learning-games.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Tangent: Automatic Differentiation Using Source Code Transformation in Python&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;283. [https://arxiv.org/pdf/1711.02712.pdf](https://arxiv.org/pdf/1711.02712.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;ExtDict: Extensible Dictionaries for Data and Platform-Aware Large Scale Learning&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;284. [http://www.aceslab.org/sites/default/files/main_0.pdf](http://www.aceslab.org/sites/default/files/main_0.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Dynamic Routing between Capsules&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;285. [https://research.google.com/pubs/pub46351.html](https://research.google.com/pubs/pub46351.html)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Climbing a Shaky Ladder: Better ADaptive Risk Estimation&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;286. [https://arxiv.org/pdf/1706.02733.pdf](https://arxiv.org/pdf/1706.02733.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Avoiding Discrimination through Causal Reasoning&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;287. [https://arxiv.org/pdf/1706.02744.pdf](https://arxiv.org/pdf/1706.02744.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Who Said What: Modeling Individual Labelers Improves Classification&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;288. [https://arxiv.org/pdf/1703.08774.pdf](https://arxiv.org/pdf/1703.08774.pdf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Matrix Capsules with EM Routing&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;289. [https://openreview.net/pdf?id=HJWLfGWRb](https://openreview.net/pdf?id=HJWLfGWRb)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;Graph sketching-based Space-efficient Data Clustering&lt;/li&gt;
    &lt;/ol&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;290. http://storage.googleapis.com/pub-tools-public-publication-data/pdf/7174df3a5627e483b5d120d8edb5843fa593577e.pdf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Major Researchers [10+ Papers / Founding]&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Jeff Dean&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Samy Bengio&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Geoffrey Hinton&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Andrew Ng&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Quoc Le&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Greg Corrado&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Vincent Vanhoucke&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Yoran Singer&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ian Goodfellow&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Tomas Mikolov&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ilya Sutskever&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Oriol Vinyals&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Marc’ Aurelio Ranzato&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Christian Szegedy&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Navdeep Jaitly&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Mohammad Norouzi&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Lukasz Kaiser&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Jonathon Shlens&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Minor Researchers&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Rajat Monga&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kai Chen&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Matthieu Devin&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Mark Mao&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Andrew Senior&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Paul Tucker&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ke Yang&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Patrick Nguyen&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Dumitru Erhan&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Eugene Ie&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Andrew Rabinovich&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Jon Shlens&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Yoram Singer&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ciprian Chelba&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Mike Schuster&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Qi Ge&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Thorsten Brants&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Tamas Sarlos&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Georg Heigold&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Andrea Frome&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Maya Gupta&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;David Sussillo&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Dragonir Anguelov&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Alexander Toshev&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Andrew Dai&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Anelia Angelova&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Alex Krizhevsky&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Lucasz Kaiser&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Terry Koo&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Slav Petrov&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Tara Sainath&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Hasim Sak&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Pierre Sermanet&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Esteban Real&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Peter Liu&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sergey Levine&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Amit Daniely&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Roy Frostig&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Martin Abadi&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Zhifeng Chen&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Yonghui Wu&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Dale Schuurmans&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Jianmin Chen&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Rafal Jozefowicz&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sergey Ioffe&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Honglak Lee&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Manjunath Kudlur&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Karol Kurach&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Minh-Thang Luong&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;John Nahm&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Alexander Alemi&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Jascha Sohl-Dckstein&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Noam Shazeer&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;David Ha&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Shan Carter&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Chris Olah&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ignacio Moreno&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Douglas Eck&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Natasha Jaques&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Shixiang Gu&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Konstantinos Bousmalis&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Francois Chollet&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Geoffrey Irving&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Amarnag Subramanya&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Michael Ringgaard&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Fernando Pereira&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Adam Roberts&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Cinjon Resnick&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Anjuli Kannan&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ryan Adams&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;David Dohan&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Luke Metz&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kelvin Xu&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Jan Chorowski&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Colin Raffel&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Dieterich Lawson&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;George Papandreou&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kevin Murphy&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Jonathan Tompson&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Olivier Bousquet&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sylvain Gelly&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Olivier Teytaud&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Damien Vincent&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Eric Jang&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Jasmine Hsu&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Been Kim&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Bart van Merrienboer&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Alexander Wiltschko&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Dan Moldovan&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Yuxuan Wang&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;RJ Skerry-Ryan&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;James Davidson&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ron Weiss&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Jan Chorowski&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Yonghui Wu&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Zhifeng Chen&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kunal Talwar&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Barret Zoph&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Maithra Raghu&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Justin Gilmer&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Jeffrey Pennington&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Samuel Schoenholz&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Gabriel Pereyra&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;George Tucker&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Vineet Gupta&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ryan Dahl&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Azalia Mirhoseini&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Andy Davis&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ashish Vaswani&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Krzysztof Maziarz&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Vikas Sindhwani&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Irwan Bello&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Hugo Larochelle&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Vijay Vasudevan&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Hieu Pham&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Jesse Engel&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Denny Britz&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Anna Goldie&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Connor Schenck&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ruben Villegas&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Yuliang Zou&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sungryull Sohn&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Danijar Hafner&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Alex Irpan&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;James Davidson&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Chung-Cheng Chiu&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kevin Swersky&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Olga Wichrowska&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Jakob Forester&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Andrew Lampinen&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;David So&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Fred Bertsch&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Reza Mahjourian&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Yasaman Bahri&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ofir Nachum&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Melody Guan&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Julian Ibarz&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Benoit Steiner&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Rasmus Larsen&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ethan Holly&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Gal Chechik&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Augustus Odena&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Christopher Olah&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Jasmine Collins&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Michal Jastrzebski&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Philip Haeusser&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Mario Lucic&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Richard Sproat&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Alexey Kurakin&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Takeru Miyato&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kristofer Schlachter&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Tomer Koren&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ayush Sekhari&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Matthew Kelcey&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Laura Downs&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Genealogy&lt;/p&gt;

&lt;p&gt;Founding Team&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Jeff Dean&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Samy Bengio&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Geoffrey Hinton&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Andrew Ng&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Quoc Le&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Greg Corrado&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Vincent Vanhoucke&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Yoran Singer&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ian Goodfellow&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Tomas Mikolov&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Rajat Monga&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kai Chen (Brain NY)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Matthieu Devin&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Mark Mao&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Marc’ Aurelio Ranzato (Brain NY)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Andrew Senior&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Paul Tucker&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ke Yang&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Patrick Nguyen&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Yoram Singer&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Dzmitry Bahdanau&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the early days, the exploration was mainly in scaling deep learning and discovering new applications to speech recognition, image categorization and language modeling.&lt;/p&gt;

&lt;p&gt;Tensorflowers: Mart´ın Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Mane, Rajat Monga, Sherry Moore, Derek Murray, ´ Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viegas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng&lt;/p&gt;

&lt;p&gt;Massive acceleration of Brain papers into ICLR 2016… Tensorflowers start making their way onto papers.&lt;/p&gt;

&lt;p&gt;Noisy Counts (Scraped)&lt;/p&gt;

&lt;p&gt;[29, ‘Oriol Vinyals’],
 [27, ‘Samy Bengio’],
 [23, ‘Ilya Sutskever’],
 [20, ‘Navdeep Jaitly’],
 [16, ‘Sergey Levine’],
 [14, ‘Mohammad Norouzi’],1
 [14, ‘Ian Goodfellow’],
 [13, ‘Lukasz Kaiser’],
 [13, ‘Jonathon Shlens’],
 [12, ‘Vincent Vanhoucke’],
 [10, ‘Quoc Le’],
 [10, ‘Geoffrey Hinton’],
 [9, ‘Dumitru Erhan’],
 [8, ‘Shixiang Gu’],
 [8, ‘Rajat Monga’],
 [8, ‘Honglak Lee’],
 [8, ‘Greg Corrado’],
 [8, ‘Christian Szegedy’],
 [8, ‘Andrew Senior’],
 [7, ‘Yoram Singer’],
 [7, ‘Tomas Mikolov’],
 [7, ‘Sylvain Gelly’],
 [7, ‘Olivier Bousquet’],
 [7, ‘Karol Kurach’],
 [7, ‘Georg Heigold’],
 [7, ‘Anelia Angelova’],
 [6, ‘Zhifeng Chen’],
 [6, ‘Rafal Jozefowicz’],
 [6, ‘Ofir Nachum’],
 [6, ‘Matthieu Devin’],
 [6, ‘Martin Abadi’],
 [6, ‘James Davidson’],
 [6, ‘Dieterich Lawson’],
 [6, ‘Dale Schuurmans’],
 [5, ‘Yonghui Wu’],
 [5, ‘Yonghui Wu’],
 [5, ‘Tara Sainath’],
 [5, ‘Mike Schuster’],
 [5, ‘Manjunath Kudlur’],
 [5, ‘Kevin Murphy’],
 [5, ‘Justin Gilmer’],
 [5, ‘George Tucker’],
 [5, ‘Douglas Eck’],
 [4, ‘Pierre Sermanet’],
 [4, ‘Noam Shazeer’],
 [4, ‘Maithra Raghu’],
 [4, ‘Kunal Talwar’],
 [4, ‘Kelvin Xu’],
 [4, ‘Kai Chen’],
 [4, ‘Jeff Dean’],
 [4, ‘Jan Chorowski’],
 [4, ‘Geoffrey Irving’],
 [4, ‘David Sussillo’],
 [4, ‘David Ha’],
 [4, ‘Colin Raffel’],
 [4, ‘Chris Olah’],
 [4, ‘Andrea Frome’],
 [4, ‘Amit Daniely’],
 [4, ‘Alexander Toshev’],
 [3, ‘Vikas Sindhwani’],
 [3, ‘Vijay Vasudevan’],
 [3, ‘Tomer Koren’],
 [3, ‘Paul Tucker’],
 [3, ‘Patrick Nguyen’],
 [3, ‘Olivier Teytaud’],
 [3, ‘Natasha Jaques’],
 [3, ‘Konstantinos Bousmalis’],
 [3, ‘Julian Ibarz’],
 [3, ‘Jonathan Tompson’],
 [3, ‘Jeffrey Pennington’],
 [3, ‘Hasim Sak’],
 [3, ‘Denny Britz’],
 [3, ‘Damien Vincent’],
 [3, ‘Benoit Steiner’],
 [3, ‘Barret Zoph’],
 [3, ‘Azalia Mirhoseini’],
 [3, ‘Augustus Odena’],
 [3, ‘Andy Davis’],
 [3, ‘Andrew Rabinovich’],
 [3, ‘Alex Krizhevsky’],
 [2, ‘Vineet Gupta’],
 [2, ‘Sergey Ioffe’],
 [2, ‘Ryan Dahl’],
 [2, ‘Ruben Villegas’],
 [2, ‘Roy Frostig’],
 [2, ‘Peter Liu’],
 [2, ‘Melody Guan’],
 [2, ‘Luke Metz’],
 [2, ‘Ke Yang’],
 [2, ‘Jianmin Chen’],
 [2, ‘Irwan Bello’],
 [2, ‘Hugo Larochelle’],
 [2, ‘Hieu Pham’],
 [2, ‘Fred Bertsch’],
 [2, ‘Francois Chollet’],
 [2, ‘Esteban Real’],
 [2, ‘Eric Jang’],
 [2, ‘Cinjon Resnick’],
 [2, ‘Been Kim’],
 [2, ‘Ashish Vaswani’],
 [2, ‘Anna Goldie’],
 [2, ‘Anjuli Kannan’],
 [2, ‘Andrew Dai’],
 [2, ‘Amarnag Subramanya’],
 [2, ‘Alexey Kurakin’],
 [2, ‘Adam Roberts’],
 [1, ‘Yuxuan Wang’],
 [1, ‘Yuliang Zou’],
 [1, ‘Yasaman Bahri’],
 [1, ‘Thorsten Brants’],
 [1, ‘Terry Koo’],
 [1, ‘Tamas Sarlos’],
 [1, ‘Takeru Miyato’],
 [1, ‘Sungryull Sohn’],
 [1, ‘Slav Petrov’],
 [1, ‘Shan Carter’],
 [1, ‘Ryan Adams’],
 [1, ‘Richard Sproat’],
 [1, ‘Reza Mahjourian’],
 [1, ‘Rasmus Larsen’],
 [1, ‘RJ Skerry-Ryan’],
 [1, ‘Qi Ge’],
 [1, ‘Philip Haeusser’],
 [1, ‘Olga Wichrowska’],
 [1, ‘Michal Jastrzebski’],
 [1, ‘Mark Mao’],
 [1, ‘Krzysztof Maziarz’],
 [1, ‘Kristofer Schlachter’],
 [1, ‘Kevin Swersky’],
 [1, ‘Jesse Engel’],
 [1, ‘Jasmine Hsu’],
 [1, ‘Jasmine Collins’],
 [1, ‘Ignacio Moreno’],
 [1, ‘George Papandreou’],
 [1, ‘Gal Chechik’],
 [1, ‘Gabriel Pereyra’],
 [1, ‘Fernando Pereira’],
 [1, ‘Eugene Ie’],
 [1, ‘Ethan Holly’],
 [1, ‘David Dohan’],
 [1, ‘Danijar Hafner’],
 [1, ‘Dan Moldovan’],
 [1, ‘Connor Schenck’],
 [1, ‘Ciprian Chelba’],
 [1, ‘Chung-Cheng Chiu’],
 [1, ‘Christopher Olah’],
 [1, ‘Ayush Sekhari’],
 [1, ‘Andrew Ng’],
 [1, ‘Andrew Lampinen’],
 [1, ‘Alex Irpan’],&lt;/p&gt;</content><author><name></name></author><summary type="html">By Jeremy Nixon [jnixon2@gmail.com]. Nov 2017.</summary></entry><entry><title type="html">Wisdom Language Patterns</title><link href="http://localhost:4000/jekyll/update/2018/06/07/wisdom-language-patterns.html" rel="alternate" type="text/html" title="Wisdom Language Patterns" /><published>2018-06-07T05:02:46-07:00</published><updated>2018-06-07T05:02:46-07:00</updated><id>http://localhost:4000/jekyll/update/2018/06/07/wisdom-language-patterns</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/06/07/wisdom-language-patterns.html">&lt;ol&gt;
  &lt;li&gt;Acceptance
    &lt;ul&gt;
      &lt;li&gt;As dissolving conflict&lt;/li&gt;
      &lt;li&gt;As the path to peace&lt;/li&gt;
      &lt;li&gt;Fatalism
        &lt;ul&gt;
          &lt;li&gt;We shall all die someday&lt;/li&gt;
          &lt;li&gt;Eventually, it shall all come to pass&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Emphasize Questions over Answers&lt;/li&gt;
  &lt;li&gt;Paradox / Contradiction (Must both be x and not be x)&lt;/li&gt;
  &lt;li&gt;Harmony&lt;/li&gt;
  &lt;li&gt;Metaphor standing in for argument&lt;/li&gt;
  &lt;li&gt;Narrative standing in for argument&lt;/li&gt;
  &lt;li&gt;Patience
    &lt;ul&gt;
      &lt;li&gt;Wait for understanding to take action&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Alignment
    &lt;ul&gt;
      &lt;li&gt;As a solution to internal conflict&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Integration
    &lt;ul&gt;
      &lt;li&gt;De-escalation of internal conflict&lt;/li&gt;
      &lt;li&gt;As opposed to willpower, which escalates internal conflict&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Peace, Calm, Serenity&lt;/li&gt;
  &lt;li&gt;Awareness&lt;/li&gt;
  &lt;li&gt;The Mind&lt;/li&gt;
  &lt;li&gt;Conscience, Consciousness&lt;/li&gt;
  &lt;li&gt;Reflection&lt;/li&gt;
  &lt;li&gt;Deep / Depth / Layers&lt;/li&gt;
  &lt;li&gt;Balance
    &lt;ul&gt;
      &lt;li&gt;Force / Willpower / Effort / Discipline vs. Alignment / Integration / Harmony&lt;/li&gt;
      &lt;li&gt;Light vs. Darkness&lt;/li&gt;
      &lt;li&gt;Yin vs. Yang&lt;/li&gt;
      &lt;li&gt;Chaos vs. Order&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Dichotomy
    &lt;ul&gt;
      &lt;li&gt;It is not x, but y&lt;/li&gt;
      &lt;li&gt;Your x is not my y&lt;/li&gt;
      &lt;li&gt;Do not do x, but do y&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Fluidity&lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><summary type="html">Acceptance As dissolving conflict As the path to peace Fatalism We shall all die someday Eventually, it shall all come to pass Emphasize Questions over Answers Paradox / Contradiction (Must both be x and not be x) Harmony Metaphor standing in for argument Narrative standing in for argument Patience Wait for understanding to take action Alignment As a solution to internal conflict Integration De-escalation of internal conflict As opposed to willpower, which escalates internal conflict Peace, Calm, Serenity Awareness The Mind Conscience, Consciousness Reflection Deep / Depth / Layers Balance Force / Willpower / Effort / Discipline vs. Alignment / Integration / Harmony Light vs. Darkness Yin vs. Yang Chaos vs. Order Dichotomy It is not x, but y Your x is not my y Do not do x, but do y Fluidity</summary></entry><entry><title type="html">How to Think</title><link href="http://localhost:4000/hyperanalytic/2015/06/23/how-to-think.html" rel="alternate" type="text/html" title="How to Think" /><published>2015-06-23T05:02:46-07:00</published><updated>2015-06-23T05:02:46-07:00</updated><id>http://localhost:4000/hyperanalytic/2015/06/23/how-to-think</id><content type="html" xml:base="http://localhost:4000/hyperanalytic/2015/06/23/how-to-think.html">&lt;!-- &lt;h2 class='post_title'&gt;How to Think&lt;/h2&gt;
&lt;p&gt; --&gt;
&lt;p&gt;Nobody that I’ve met has had a great answer to how to get a mapping from concepts and frameworks to problems to solve, where their intuition brings the most salient, information-full frameworks and concepts to mind as soon as they encounter a problem. This is definitely how my brain seems to work and so improving this would lead to great outcomes.
&lt;!-- &lt;/p&gt;&lt;p&gt; --&gt;&lt;/p&gt;

&lt;p&gt;The plan is to run this framework against problems in life systematically, until the models become an integral part of habitual thought. System 1 can do the work of aggregating their results after I see enough data, and the framework will expose the strongest ways to think about problems immediately.
&lt;!-- &lt;/p&gt;&lt;p&gt; --&gt;&lt;/p&gt;

&lt;p&gt;What follows is a master list of this framework.
&lt;!-- &lt;/p&gt;&lt;p&gt; --&gt;
&lt;!-- &lt;div class='post_title'&gt; --&gt;&lt;/p&gt;

&lt;p&gt;Models Master List (Letting Things Blow Up)
&lt;!-- &lt;/p&gt;&lt;p&gt; --&gt;&lt;/p&gt;

&lt;p&gt;Behavioral Economics / Psychology&lt;/p&gt;

&lt;p&gt;Prospect Theory&lt;/p&gt;

&lt;p&gt;Reference Dependence&lt;/p&gt;

&lt;p&gt;Loss / Risk / Uncertainty Aversion&lt;/p&gt;

&lt;p&gt;Growth vs Fixed Mindset&lt;/p&gt;

&lt;p&gt;System 1 / System 2&lt;/p&gt;

&lt;p&gt;Goal Factoring&lt;/p&gt;

&lt;p&gt;Ego (Positional Negotiation)&lt;/p&gt;

&lt;p&gt;Environment as Main Determinant of Behavior (Social and Physical)&lt;/p&gt;

&lt;p&gt;Assume that some options are eliminated&lt;/p&gt;

&lt;p&gt;Prevention Focus vs Promotion Focus&lt;/p&gt;

&lt;p&gt;When we consider the best and worst states, what context do we think exists?&lt;/p&gt;

&lt;p&gt;Identify Aversive Factors&lt;/p&gt;

&lt;p&gt;Inferential Distance&lt;/p&gt;

&lt;p&gt;Steelman each idea&lt;/p&gt;

&lt;p&gt;Exposure Therapy&lt;/p&gt;

&lt;p&gt;Groupthink&lt;/p&gt;

&lt;p&gt;Confirmation Bias&lt;/p&gt;

&lt;p&gt;Selection Effects&lt;/p&gt;

&lt;p&gt;Availability Bias&lt;/p&gt;

&lt;p&gt;Cognitive Dissonance (Consistency plus Sour Grapes)&lt;/p&gt;

&lt;p&gt;Social Proof&lt;/p&gt;

&lt;p&gt;No Brainer (Do the Obvious Thing)&lt;/p&gt;

&lt;p&gt;Reciprocation&lt;/p&gt;

&lt;p&gt;Maslow’s Hammer (The tools you have determine the solutions you see)&lt;/p&gt;

&lt;p&gt;Habits&lt;/p&gt;

&lt;p&gt;Economics&lt;/p&gt;

&lt;p&gt;Incentives&lt;/p&gt;

&lt;p&gt;Opportunity Cost (Necessity of trade-offs)&lt;/p&gt;

&lt;p&gt;Marginal Value&lt;/p&gt;

&lt;p&gt;Supply Demand (Scarcity, scarce resources)&lt;/p&gt;

&lt;p&gt;Diminishing Marginal Returns&lt;/p&gt;

&lt;p&gt;Option Value (Value in Exploration)&lt;/p&gt;

&lt;p&gt;Comparative Advantage / Specialization&lt;/p&gt;

&lt;p&gt;Equilibrium&lt;/p&gt;

&lt;p&gt;Hyperbolic Discounting&lt;/p&gt;

&lt;p&gt;Arbitrage&lt;/p&gt;

&lt;p&gt;Deadweight Loss (Resource Misallocation)&lt;/p&gt;

&lt;p&gt;Elasticity (First derivative, response magnitude of supply/demand to changing price)&lt;/p&gt;

&lt;p&gt;Tragedy of the Commons (Free Rider Problem)&lt;/p&gt;

&lt;p&gt;Externalities&lt;/p&gt;

&lt;p&gt;Moral Hazard / Principal Agent Problem&lt;/p&gt;

&lt;p&gt;Expected Value&lt;/p&gt;

&lt;p&gt;Mathematics&lt;/p&gt;

&lt;p&gt;Check Derivative and Second Derivative, not just Objective Function&lt;/p&gt;

&lt;p&gt;Nonlinearity&lt;/p&gt;

&lt;p&gt;Invert&lt;/p&gt;

&lt;p&gt;Principle Component Analysis&lt;/p&gt;

&lt;p&gt;Statistics&lt;/p&gt;

&lt;p&gt;Antifragility (Gains from volatility)&lt;/p&gt;

&lt;p&gt;Option (Short or long volatility)&lt;/p&gt;

&lt;p&gt;Optionality&lt;/p&gt;

&lt;p&gt;Narrative Fallacy&lt;/p&gt;

&lt;p&gt;Search for Objective Data to Inform Decisions&lt;/p&gt;

&lt;p&gt;Intensity (Variance)&lt;/p&gt;

&lt;p&gt;Conditional probabilities multiply - theorizing is extremely difficult&lt;/p&gt;

&lt;p&gt;Power Law Distribution vs Normal Distribution&lt;/p&gt;

&lt;p&gt;Outliers&lt;/p&gt;

&lt;p&gt;Law of Large Numbers (Poker style optimal play)&lt;/p&gt;

&lt;p&gt;Mean Regression&lt;/p&gt;

&lt;p&gt;Bias / Variance&lt;/p&gt;

&lt;p&gt;Tight / Aggressive approach to decisions&lt;/p&gt;

&lt;p&gt;Pareto Principle (80/20 rule, Curate, Triage)&lt;/p&gt;

&lt;p&gt;Biology&lt;/p&gt;

&lt;p&gt;Evolution&lt;/p&gt;

&lt;p&gt;Natural Selection&lt;/p&gt;

&lt;p&gt;Memes&lt;/p&gt;

&lt;p&gt;Physics&lt;/p&gt;

&lt;p&gt;Critical Mass&lt;/p&gt;

&lt;p&gt;First Principles Foundational Thought&lt;/p&gt;

&lt;p&gt;Chemistry&lt;/p&gt;

&lt;p&gt;Dose Dependence&lt;/p&gt;

&lt;p&gt;Catalyst&lt;/p&gt;

&lt;p&gt;Philosophy&lt;/p&gt;

&lt;p&gt;Consider the Meta Level&lt;/p&gt;

&lt;p&gt;Consequentialism&lt;/p&gt;

&lt;p&gt;Problem of Induction / Empiricism&lt;/p&gt;

&lt;p&gt;Values Framework&lt;/p&gt;

&lt;p&gt;Simplicity (Occam’s Razor)&lt;/p&gt;

&lt;p&gt;Engineering&lt;/p&gt;

&lt;p&gt;Bottleneck&lt;/p&gt;

&lt;p&gt;Backup System&lt;/p&gt;

&lt;p&gt;Positive / Negative Feedback&lt;/p&gt;

&lt;p&gt;Curate&lt;/p&gt;

&lt;p&gt;Heuristics&lt;/p&gt;

&lt;p&gt;What would I think if I was another type of person? Different Identity?&lt;/p&gt;

&lt;p&gt;Habits&lt;/p&gt;

&lt;p&gt;History&lt;/p&gt;

&lt;p&gt;When has this problem or approach been tried or solved in the past?&lt;/p&gt;

&lt;p&gt;Sociology&lt;/p&gt;

&lt;p&gt;Identity&lt;/p&gt;

&lt;p&gt;With social roles&lt;/p&gt;

&lt;p&gt;With organizations&lt;/p&gt;

&lt;p&gt;With status levels&lt;/p&gt;

&lt;p&gt;Computer Science&lt;/p&gt;

&lt;p&gt;Systematize (Write an Algorithm / Process)&lt;/p&gt;

&lt;p&gt;Exploration-Exploitation&lt;/p&gt;

&lt;p&gt;Divide and Conquer (Split problem into pieces)&lt;/p&gt;

&lt;p&gt;Premature Optimization&lt;/p&gt;

&lt;p&gt;Tree Structure (Graphical Structure)&lt;/p&gt;</content><author><name></name></author><summary type="html">Nobody that I’ve met has had a great answer to how to get a mapping from concepts and frameworks to problems to solve, where their intuition brings the most salient, information-full frameworks and concepts to mind as soon as they encounter a problem. This is definitely how my brain seems to work and so improving this would lead to great outcomes.</summary></entry><entry><title type="html">Optimize for Volatility, not Average Capacity</title><link href="http://localhost:4000/jekyll/update/2015/06/22/optimize-for-volatility.html" rel="alternate" type="text/html" title="Optimize for Volatility, not Average Capacity" /><published>2015-06-22T05:02:46-07:00</published><updated>2015-06-22T05:02:46-07:00</updated><id>http://localhost:4000/jekyll/update/2015/06/22/optimize-for-volatility</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2015/06/22/optimize-for-volatility.html">&lt;p&gt;There are a number of interrelated ideas that I’d like to connect. Those are Optionality, Trial and Error, Exploration-Exploitation, Experimentation, Natural Selection, Comfort Zones, Creative Destruction, and certainly a swath of other critical ideas.&lt;/p&gt;

&lt;p&gt;The central idea is Optionality - in many cases, you get the upside from volatility. You sample over and over from a distribution (you can imagine meeting potential friends/romantic partners, or trying out classes or a major at college, or there being many mutations of a gene in a population) and take the best, or at least the better, option.&lt;/p&gt;

&lt;p&gt;In all situations like this (and they are everywhere), volatility is more important than the average.&lt;/p&gt;

&lt;p&gt;In Exploration-Exploitation, optionality lets you exploit by taking the best solution thusfar and using it as your model for behavior. When there’s high variance in what you’re exploring - say you’re sampling different dishes at a restaurant - if some dishes are amazing and some are awful, you get the upside - amazing dishes all the time - as soon as you start exploiting. If there isn’t much volatility - if every dish is basically the same - even if the dishes are quite good, you don’t end up as well off as when there’s variation that you can take advantage of.&lt;/p&gt;

&lt;p&gt;Personal experimentation is a form of exploration, where you try out a new behavior, style of living, or a new habit. When there’s more variation in the change in life quality, you get much more out of experimentation.&lt;/p&gt;

&lt;p&gt;Natural selection benefits from high levels of mutation in a population, because that allows for faster adaptation to an environment and faster improvements in fitness at the species level.&lt;/p&gt;

&lt;p&gt;In Trial and Error, there’s a binary outcome and you sample over and over until you get a success. Then you can use that success again and again.&lt;/p&gt;

&lt;p&gt;People who are said to be staying inside their comfort zones are suffering from the absence of optionality - by refusing to explore the space, they end up with a weak payoff.&lt;/p&gt;

&lt;p&gt;Creative destruction is critical for the growth of economic systems, and thrives off of the volatility inherent in the life and death of industry. By taking the upside to variance, capitalistic societies grow off of optionality.&lt;/p&gt;

&lt;p&gt;This foundational principle underlies almost all value creation. It calls for us to optimize systems for volatility, not average capacity. Education, business, personal lifestyle - all of these have much to gain from volatility. And so the common heuristic that volatility is bad or dangerous or scary is only true at the lower fractal level. At the system one level up, the variance is essential to growth.&lt;/p&gt;</content><author><name></name></author><summary type="html">There are a number of interrelated ideas that I’d like to connect. Those are Optionality, Trial and Error, Exploration-Exploitation, Experimentation, Natural Selection, Comfort Zones, Creative Destruction, and certainly a swath of other critical ideas. The central idea is Optionality - in many cases, you get the upside from volatility. You sample over and over from a distribution (you can imagine meeting potential friends/romantic partners, or trying out classes or a major at college, or there being many mutations of a gene in a population) and take the best, or at least the better, option. In all situations like this (and they are everywhere), volatility is more important than the average. In Exploration-Exploitation, optionality lets you exploit by taking the best solution thusfar and using it as your model for behavior. When there’s high variance in what you’re exploring - say you’re sampling different dishes at a restaurant - if some dishes are amazing and some are awful, you get the upside - amazing dishes all the time - as soon as you start exploiting. If there isn’t much volatility - if every dish is basically the same - even if the dishes are quite good, you don’t end up as well off as when there’s variation that you can take advantage of. Personal experimentation is a form of exploration, where you try out a new behavior, style of living, or a new habit. When there’s more variation in the change in life quality, you get much more out of experimentation. Natural selection benefits from high levels of mutation in a population, because that allows for faster adaptation to an environment and faster improvements in fitness at the species level. In Trial and Error, there’s a binary outcome and you sample over and over until you get a success. Then you can use that success again and again. People who are said to be staying inside their comfort zones are suffering from the absence of optionality - by refusing to explore the space, they end up with a weak payoff. Creative destruction is critical for the growth of economic systems, and thrives off of the volatility inherent in the life and death of industry. By taking the upside to variance, capitalistic societies grow off of optionality. This foundational principle underlies almost all value creation. It calls for us to optimize systems for volatility, not average capacity. Education, business, personal lifestyle - all of these have much to gain from volatility. And so the common heuristic that volatility is bad or dangerous or scary is only true at the lower fractal level. At the system one level up, the variance is essential to growth.</summary></entry><entry><title type="html">Idea Flow</title><link href="http://localhost:4000/hyperanalytic/2015/06/21/ideaflow.html" rel="alternate" type="text/html" title="Idea Flow" /><published>2015-06-21T05:02:46-07:00</published><updated>2015-06-21T05:02:46-07:00</updated><id>http://localhost:4000/hyperanalytic/2015/06/21/ideaflow</id><content type="html" xml:base="http://localhost:4000/hyperanalytic/2015/06/21/ideaflow.html">&lt;p&gt;Idea flow is the name I give to the visceral sense that ideas are moving through your life at speed - you can think of it as a rate, a number of ideas per day, that create a sense of intellectual exploration and growth.&lt;/p&gt;

&lt;p&gt;The greatest speeds have been achieved with dramatic amounts of reading. The experiment from Sophomore summer where I read 4 books a week is the prime example. My mind was chock full and flying each and every day.&lt;/p&gt;

&lt;p&gt;Idea flow always exists, the question is how much is there and how does it feel. As a hyperanalytic addict, I find that it’s invigorating and look to maximize it (constrained optimization). I also have searched for ways to capture as much of the flow as possible and install it into habitual thought.&lt;/p&gt;

&lt;p&gt;A few methods that consistently generate flow:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Write. Free Writing, Essays, Book Writing, etc.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Find the best online communities that I can and comment/post about topics that I care about in the space.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Idea Lists. Time limited brainstorming, forcing myself to get to a high count.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Read. 4 books a week was the time of greatest idea flow for me. Doing that as a lifestyle was extremely time consuming and even more rewarding.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Social - Meeting regularly with my smartest friends.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Professors. They give the best worldview critiques and are great for looking up solutions and generating ideas.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Taking the best books and compress them into runable algorithms. Experiment based off of them and run them regularly.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Set out all of the best ideas in a field or space. Search exhaustively. And then compress the space into the strongest and most general ideas, and train thinking with that frame.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;!-- Check out the [Jekyll docs][jekyll-docs] for more info on how to get the most out of Jekyll. File all bugs/feature requests at [Jekyll’s GitHub repo][jekyll-gh]. If you have questions, you can ask them on [Jekyll Talk][jekyll-talk].

[jekyll-docs]: https://jekyllrb.com/docs/home
[jekyll-gh]:   https://github.com/jekyll/jekyll
[jekyll-talk]: https://talk.jekyllrb.com/ --&gt;</content><author><name></name></author><summary type="html">Idea flow is the name I give to the visceral sense that ideas are moving through your life at speed - you can think of it as a rate, a number of ideas per day, that create a sense of intellectual exploration and growth.</summary></entry><entry><title type="html">What Forces Motivate People to Ascend to Greatness?</title><link href="http://localhost:4000/hyperanalytic/2015/06/20/ascend-to-greatness.html" rel="alternate" type="text/html" title="What Forces Motivate People to Ascend to Greatness?" /><published>2015-06-20T05:02:46-07:00</published><updated>2015-06-20T05:02:46-07:00</updated><id>http://localhost:4000/hyperanalytic/2015/06/20/ascend-to-greatness</id><content type="html" xml:base="http://localhost:4000/hyperanalytic/2015/06/20/ascend-to-greatness.html">&lt;p&gt;Response to Carl Shan.&lt;/p&gt;

&lt;p&gt;Hi Carl,&lt;/p&gt;

&lt;p&gt;I would add embracing obsession.&lt;/p&gt;

&lt;p&gt;Oliver Emberton sums up a lot of it with this line: “Monomaniacal focus on a single goal is perhaps the ultimate success strategem.”(&lt;a href=&quot;https://oliveremberton.com/2014/if-you-want-to-follow-your-dreams-you-have-to-say-no-to-all-the-alternatives/&quot;&gt;On Saying No&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Personally, obsession was the primary driver for me ascending in the Ultimate world to become a &lt;a href=&quot;http://skydmagazine.com/2014/05/2014-callahan-award-top-10/&quot;&gt;top 10 college player&lt;/a&gt; in ~2 years.&lt;/p&gt;

&lt;p&gt;But the words that have really stuck with me are from Justine Musk on Quora, answering ‘“&lt;a href=&quot;https://www.quora.com/How-can-I-be-as-great-as-Bill-Gates-Steve-Jobs-Elon-Musk-and-Richard-Branson&quot;&gt;How can I be as great as Bill Gates, Steve Jobs, Elon Musk, and Richard Branson?&lt;/a&gt;”.&lt;/p&gt;

&lt;p&gt;In Zero to One Peter Thiel points towards obsession and variance with Definite Optimism: “A definite view, by contrast, favors firm convictions. Instead of pursuing many-sided mediocrity and calling it “well-roundedness,” a definite person determines the one best thing to do and then does it. Instead of working tirelessly to make herself indistinguishable, she strives to be great at something substantive—to be a monopoly of one.”&lt;/p&gt;

&lt;p&gt;Embracing personal volatility is also critical. Extreme personalities tend to create variance that’s necessary for contrary thought and for conviction. And the contrarian capable of seeing truths in the world that evade others’ perception needs thrives off of a unique thinking style.&lt;/p&gt;

&lt;p&gt;I love Brandon Liu’s addition of responsibility. I think that this may fall under your sense of ‘duty’, where Brandon’s example is a special case of duty toward people around you. Soldiers regularly point to a sense of brotherhood as the core of their motivation in the face of death.&lt;/p&gt;

&lt;p&gt;Sense of responsibility hit me hard reading Ashlee Vance’s bio on Elon Musk, where he writes that “Musk came to see man’s fate in the universe as a personal obligation.”&lt;/p&gt;

&lt;p&gt;But the &lt;a href=&quot;http://hyperanalytic.net/elon-musk&quot;&gt;broad takeaway from me&lt;/a&gt; from that bio was the importance of conviction. Conviction allows decisiveness, it clarifies decision making and lets a person dedicate all of their resources to optimizing the path in front of them and &lt;a href=&quot;http://lesswrong.com/lw/jh0/deregulating_distraction_moving_towards_the_goal/&quot;&gt;move towards the goal&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;There are many reasons people choose not to pursue greatness. Many of these reasons are aligned with a pretty reasonable utility function. There are huge costs associated with ascending to greatness - deep relationships are put through a struggle, life is unstable, and there are high chances of failure on top of the costs. If your value structure doesn’t demand ambition, impact, or glory, it’s not obvious that those costs are worth it. Greatness often requires blistering amounts of hard work, much of it painful. Elon’s favorite line is that starting a company is like eating glass and staring into the abyss.&lt;/p&gt;

&lt;p&gt;People aren’t naturally optimizers (with resource constraints), and tend to play the role of doing their job or studying their field. They satisfice - do just enough to satisfy their lifestyle requirements and ego. People with particularly large egos end up pursuing greatness to validate an elevated sense of self worth, which is part of what I think you point to when you list insecurity.&lt;/p&gt;

&lt;p&gt;There’s an extremely potent force in a person’s social and informational environment - cultural expectations drive the types of life outcome that people value. If you want to change your values, choosing a social environment is one of the easiest methods. And the information that a person consumes drives their values and motivations.&lt;/p&gt;

&lt;p&gt;Finally, there’s an impact from feedback that is related to social environment. In skill building, getting social validation for an ability can create a virtuous cycle where improvement leads to increased respect and reputation which drives even more skill building. Starting this feedback loop attaining a reputation will lead you to defend that reputation. This was the major driver for my ascension in Ultimate, and so I always point to this force as creating passion / obsession.&lt;/p&gt;

&lt;p&gt;Finally, there’s often some tradeoff to be made between being able to signal greatness and having a true impact.&lt;/p&gt;

&lt;p&gt;You can imagine that the winner in a competitive structure feels a sense of greatness. But the marginal difference between that winner competing or not competing is tiny. And that difference is the way we should evaluate impact - look at a hypothetical counterfactual world where that person didn’t participate and measure the difference.&lt;/p&gt;

&lt;p&gt;Our society will shower the winner with wealth and power. But the marginal impact may have been tiny, if their closest competitor would have done basically the same thing.&lt;/p&gt;

&lt;p&gt;The person who makes a large marginal impact by doing something completely unique often gets substantially less validation, wealth and power. And they won’t show up on your list of great people. Neither will the people who’ve achieved massive internal accomplishment but limited external accomplishment. If the goal is genuinely impact, and not fame/wealth/validation/power, this may be a better way.&lt;/p&gt;

&lt;p&gt;TLDR: I’d add Obsession, Variance, +1 to Responsibility, Conviction, Environment, and Feedback Loops.&lt;/p&gt;

&lt;!-- Check out the [Jekyll docs][jekyll-docs] for more info on how to get the most out of Jekyll. File all bugs/feature requests at [Jekyll’s GitHub repo][jekyll-gh]. If you have questions, you can ask them on [Jekyll Talk][jekyll-talk].

[jekyll-docs]: https://jekyllrb.com/docs/home
[jekyll-gh]:   https://github.com/jekyll/jekyll
[jekyll-talk]: https://talk.jekyllrb.com/ --&gt;</content><author><name></name></author><summary type="html">Response to Carl Shan.</summary></entry></feed>