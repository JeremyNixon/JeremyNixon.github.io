<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-02-08T19:04:11-08:00</updated><id>http://localhost:4000/</id><title type="html">Grounded Abstraction</title><subtitle>Reach to the sky from the bottom.</subtitle><entry><title type="html">Tradeoffs in Personality / Identity Space</title><link href="http://localhost:4000/thinking/2019/02/08/tradeoffs.html" rel="alternate" type="text/html" title="Tradeoffs in Personality / Identity Space" /><published>2019-02-08T17:42:46-08:00</published><updated>2019-02-08T17:42:46-08:00</updated><id>http://localhost:4000/thinking/2019/02/08/tradeoffs</id><content type="html" xml:base="http://localhost:4000/thinking/2019/02/08/tradeoffs.html">&lt;p&gt;While it is possible to overcome many of these, the tradeoffs exist by default and can be seen over and over.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Validating a helpless / victim narrative vs. cutting against it.&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Ex., you should just do the thing that will get you what you want - your excuses be damned. Makes people feel invalidated.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Conformity / Tradition / Security vs. Self Direction / Freedom / Novelty / Challenge&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Benevolence / Universalism / Inclusiveness / Communal vs. Power / Achievement / Dominance / Systematicity&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Between sources of meaning&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Love &amp;amp; Family vs. Mission &amp;amp; Goals&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Agreeableness vs. Disagreeableness&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Introversion vs. Extroversion&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Openness vs. Conscientiousness&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Conscientiousness vs. Creativity&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Accountability vs. Creativity&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Measurability vs. Creativity&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Regimentedness vs. Creativity&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Consistency vs. Creativity&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Vulnerability vs. Conviction&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Wartime CEO vs. Peacetime CEO&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Freedom vs. Cohesion&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Yin (Zen, Alignment) vs Yang (Force, Effort)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Bias vs. Variance&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Exploration vs. Exploitation&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Simplicity vs. Complexity&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Loneliness vs Freedom&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Thinking vs. Doing&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Authenticity vs. Self-Awareness&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Big Picture vs. Detail Oriented&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Seriousness vs. Playfulness&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Literal vs. Emotional&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ego vs. Vulnerability&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Conviction vs. Vulnerability&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Action vs. Vulnerability&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Sphere of Control vs. Vulnerability&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Inadequacy sense vs. Understanding / Acclimation&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Attention vs. Awareness&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Compartmentalization vs. Integration&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Humbleness vs. Arrogance&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Groundedness vs. Expansive Vision&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Stability vs Growth&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Systemizing vs. Empathizing&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;(Thing orientedness vs. people orientedness)&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Fox vs Hedgehog&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;High vs low expectations&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Indoctrination vs. Ungroundedness, taking assumptions vs. questioning assumptions&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Power vs. Empathy&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Living in the Now vs. in the Past, Present and Future&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Open Mindedness vs. Assertiveness&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Judgement and Acceptance&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Tough Love as paradoxical&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><summary type="html">While it is possible to overcome many of these, the tradeoffs exist by default and can be seen over and over.</summary></entry><entry><title type="html">Compressing Decision Making</title><link href="http://localhost:4000/thinking/2019/02/08/compression-decision-making.html" rel="alternate" type="text/html" title="Compressing Decision Making" /><published>2019-02-08T17:42:46-08:00</published><updated>2019-02-08T17:42:46-08:00</updated><id>http://localhost:4000/thinking/2019/02/08/compression-decision-making</id><content type="html" xml:base="http://localhost:4000/thinking/2019/02/08/compression-decision-making.html">&lt;p&gt;Major Models&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Learning from Failure&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Facing Reality vs. Pretending / Ignoring Reality&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Determination / Courage&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Social Norms&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Opportunity Cost&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Triage / Prioritization (80/20 Pareto Principle)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Major Techniques&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Go to underlying reasons for the decision, and reason up. Goal Factor.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If a new person walked into your life, what would they do? Escape your mental frame.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;When possible, run a trial of important decision before committing to them.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Define and enshrine core priorities&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Premortem&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;What would the most determined, courageous version of me do?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Zero Based Thinking&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;If I was not already in this job / relationship / situation, would I enter it again?&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;If any variant of no, ask: How do I get out, and how quickly can I do it?&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Minor Models&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Confirmation Bias&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Short term emotions&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Prevention Focus vs. Promotion Focus&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Identify and don’t tolerate the problems that stand in the way of your goals&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Design plans that explicitly lay out the tasks that will get you over your problems and onto your goals&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Minor Techniques&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Find objective Information&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Distance yourself emotionally from the decision&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Worst case scenario&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Minimize the downside of your decision&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Set tripwires to check whether a decision needs to be made / changed&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Assume you can’t choose any of the existing options. What would you do?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Assume you’re forced into one decision. What would you do?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Have multiple good options in front of you simultaneously (Protects from premature commitment)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Seriously consider the opposite on important decisions. Find a belief driving your behavior and argue with all energy against it.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Look at your decision from the perspective of several time frames. 10 days / 10 months / 10 years, for example.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;When you have a difficult decision to make, flesh it out as a values conflict&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Honestly ask yourself what you want and what should be done about it.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;What am I likely to lie to myself about in this space?&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><summary type="html">Major Models</summary></entry><entry><title type="html">Relentless</title><link href="http://localhost:4000/books/2019/02/08/relentless.html" rel="alternate" type="text/html" title="Relentless" /><published>2019-02-08T17:39:46-08:00</published><updated>2019-02-08T17:39:46-08:00</updated><id>http://localhost:4000/books/2019/02/08/relentless</id><content type="html" xml:base="http://localhost:4000/books/2019/02/08/relentless.html">&lt;p&gt;There are major ideas that repeat here, that are the foundation.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Complete Focus on Outcome&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Willingness to do whatever it takes to achieve the outcome&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Disregard for norms / rules in the way of the outcome&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Obsessed with and insatiably addicted to success&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Make real sacrifices in pursuit of the goal&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Commitment and Persistence to the goal and outcome&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Self Reliant&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Belief in self&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Killer Instinct&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Confident that no matter what happens, you will figure it out&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Know exactly who you are&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Don’t need validation from other people to act on conviction&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sense of Responsibility&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Extremely High Expectation&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Being the best&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Transcending limitations&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Not Settling for good enough - pushing yourself harder than everyone else&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Never stooping to others’ low standards&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Dark Side&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Drive to control everything, especially the uncontrollable&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Attack, control, win.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Drive to conquer everything in your path&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Selfishness, egocentrism, ambition&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Zero fear of failing, excitement from risk + challenge&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Facing the Truth&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;No Tolerance for ‘nice’ lies&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The Zone&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Meditative&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Cool anger&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Courage&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Will take on a role they’re not comfortable with, confident they will figure it out&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Action Focus&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Decisive in Decision Making&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Taking action instead of talking about taking action&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Core concept is a complete focus on outcome. There’s a strong conflict here in my thinking generally, where there’s the tradeoff between process and outcome is real. Often they conflict at an emotional level. And Relentless was clear about which one it favored. It doesn’t care if what you’re doing is supposed to work (though this does imply extremely strong self confidence), it cares about reality and about optimizing for a particular outcome.&lt;/p&gt;

&lt;p&gt;That said, the willingness to do whatever it takes to achieve the outcome leads to real results. I realize now that my infatuation with Soares is mostly from the display of this quality - the idea that no matter the path taken, the outcome will be achieved. The only question is what it will cost, and how long it will take. “Don’t count the costs”, or something like that. And this is also the core of what people mean when they say ‘Relentless’.&lt;/p&gt;

&lt;p&gt;There’s a disregard for norms or rules in the way of an outcome that’s a natural result of relentlessness. It’s pretty beautiful, what stops being mattering as soon as you really care about something.&lt;/p&gt;

&lt;p&gt;Self reliance is extremely important to decisiveness and to problem solving. It’s necessary if you want to bite of any real challenges, not knowing exactly what that challenge will hold. The lack of need for other people to validate your ideas, as long as they make sense to you, makes you this unique source of powerful value. It also lets you avoid getting sucked into huge holes around norms in a society that torpedo most people’s chances at greatness.&lt;/p&gt;

&lt;p&gt;The strength of instinctual behavior comes out of decisiveness and conviction - it makes a slew of obviously valuable behaviors possible. Operating under uncertainty. Building up of huge advantage without explicit feedback. There’s this ambiguity to feedback in the absence of self reliance - often you can give yourself strong intuitive feedback if you’re willing to be honest with yourself. In the absence of feedback from your own intuition you’re lost in an uncertain haze of behavior, where you can’t direct yourself effectively.&lt;/p&gt;

&lt;p&gt;Knowing exactly who you are simplifies a huge number of decisions, and enables decisiveness. It’ll be immediately apparent to you whether particular behavior is in support of your goals or not. And so decisions can come quickly and easily.&lt;/p&gt;

&lt;p&gt;The sense of responsibility for things that you do transfers huge amounts of power to you from social perception or some other nonsense. Small sphere of control has people self-sabotage, not claiming resources or opportunities that would be available if they only allowed themselves to think that they have an impact on their own success. Ties closely in with confidence.&lt;/p&gt;

&lt;p&gt;Performance are a function of expectations, and these are set extremely high for the relentless. This is one domain where social norms have a huge impact on outcomes. Often, the mental block of expectations is more in the way of performance than anything real about the situation at hand. The 4 minute mile is a great example of this. There’s this mentality around never settling for good enough, and driving expectations higher than the surrounding people which leads to behavior that’s different in a way that differentiates the relentless. Being the best is a way of thinking of oneself that also ties in with darkside beliefs around egoism and selfishness, where you look to be better than anyone else. Grover disappoints me here - the goal is to push human limits, and be better than any human has ever been - not just being better than the existing crop. This redefines the ranges that are possible for intelligent creatures, as far as humans are concerned.&lt;/p&gt;

&lt;p&gt;Dark Side is a fascinating and particularly high variance part to this book. The embrace of the dark side is certainly something I’ve seen and felt. This embrace of the drive to control everything, drive to conquer. These goals are often self-centered (I want to win the callahan), though it’s good when it’s around team championships in basketball - that really makes the impact better for the teams of the players in question.&lt;/p&gt;

&lt;p&gt;There’s this wonderful truth seeking to someone who actually cares about being the best. That’s why they go to Tim Grover - he won’t sugar coat things or try to be their friend, he’ll just tell them what they actually need to sacrifice to get what they want.l The pervasive tacit lies in society around what’s necessary for achievement or where someone is creates a complete lack of feedback that is destructive to performance. The person has to be self reliant enough to generate those feedback signals themselves, if they care about growing in the ways that matter.&lt;/p&gt;

&lt;p&gt;Spending time in the zone is an amazing approach to performance. It intersects cleanly with Newport’s work on Deep Work and is clearly a mental space where spending time leads to great results. It’s the place to both practice and perform. My life needs more of it. I had it reading the deep learning textbook each morning, but have been strongly deprived of it since. The zone means blocking literally everything else out. And once inside, it’s a wonderful mental place to inhabit.&lt;/p&gt;

&lt;p&gt;Courage is a major determinant of success that’s overcome by the relentless through self reliance, truth and the dark side’s sense of attraction to difficulty and fear. It takes courage to believe in yourself and make decisions that look very valuable but feel contrarian on the inside.&lt;/p&gt;

&lt;p&gt;Action focus is a function of being decisive and caring about the end outcome. It does no good to get bogged down in side processes, and so the relentless person doesn’t get distracted by nonsense around signaling at the sacrifice of a level of ability. They recognize that often the most efficient path forward is to deeply understand the material and then simply communicate that to the people that matter.&lt;/p&gt;</content><author><name></name></author><summary type="html">There are major ideas that repeat here, that are the foundation.</summary></entry><entry><title type="html">OpenAI Research Frontier</title><link href="http://localhost:4000/thinking/2019/02/08/openai-research-overview.html" rel="alternate" type="text/html" title="OpenAI Research Frontier" /><published>2019-02-08T17:37:46-08:00</published><updated>2019-02-08T17:37:46-08:00</updated><id>http://localhost:4000/thinking/2019/02/08/openai-research-overview</id><content type="html" xml:base="http://localhost:4000/thinking/2019/02/08/openai-research-overview.html">&lt;p&gt;By Jeremy Nixon [&lt;a href=&quot;mailto:jnixon2@gmail.com&quot;&gt;jnixon2@gmail.com&lt;/a&gt;]. Nov 2017.&lt;/p&gt;

&lt;p&gt;Categories: Domain in which the paper’s innovation is novel.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Reinforcement Learning&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Multi-Agent&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Exploration&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Imitation Learning&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Deep Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Memory&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Program Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Representation Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Variational Inference&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Generative Models&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Evolution&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Applications&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Security / Safety&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Robotics&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Environments&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Papers:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Reinforcement Learning&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Multi-Agent&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;Learning with Opponent-Learning Awareness&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1709.04326&quot;&gt;https://arxiv.org/abs/1709.04326&lt;/a&gt;&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1706.02275&quot;&gt;https://arxiv.org/abs/1706.02275&lt;/a&gt;&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Emergence of Grounded Compositional Language in Multi-Agent Populations&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.04908&quot;&gt;https://arxiv.org/abs/1703.04908&lt;/a&gt;&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Exploration&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;Parameter Space Noise for Exploration&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1706.01905&quot;&gt;https://arxiv.org/abs/1706.01905&lt;/a&gt;&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;UCB and InfoGain Exploration via Q-Ensembles&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1706.01502&quot;&gt;https://arxiv.org/abs/1706.01502&lt;/a&gt;&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1611.04717&quot;&gt;https://arxiv.org/abs/1611.04717&lt;/a&gt;&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;VIME: Variational Information Maximizing Exploration&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;https://arxiv.org/abs/1605.09674&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Imitation Learning&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;Third-Person Imitation Learning&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.01703&quot;&gt;https://arxiv.org/abs/1703.01703&lt;/a&gt;&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;One-Shot Imitation Learning&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.07326&quot;&gt;https://arxiv.org/abs/1703.07326&lt;/a&gt;&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;RL2: Fast Reinforcement Learning via Slow Reinforcement Learning&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;https://arxiv.org/abs/1611.02779&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Teacher-Student Curriculum Learning&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1707.00183&quot;&gt;https://arxiv.org/abs/1707.00183&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Equivalence Between Policy Gradients and Soft Q-Learning&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1704.06440&quot;&gt;https://arxiv.org/abs/1704.06440&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Prediction and Control with Temporal Segment Models&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;https://arxiv.org/abs/1703.04070&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Deep Learning&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;https://arxiv.org/abs/1602.07868&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Memory&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Hindsight Experience Replay [Also, Reinforcement Learning]&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1707.01495.pdf&quot;&gt;https://arxiv.org/pdf/1707.01495.pdf&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Program Learning&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Extensions and Limitations of the Neural GPU&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;https://arxiv.org/abs/1611.00736&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Representation Learning&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Variational Lossy Autoencoder&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1611.02731&quot;&gt;https://arxiv.org/abs/1611.02731&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Variational Inference&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Improving Variational Inference with Inverse Autoregressive Flow&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;https://arxiv.org/abs/1606.04934&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Generative Models&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Generative Adversarial Networks&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;InfoGan: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets [Also, Representation Learning]&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1606.03657&quot;&gt;https://arxiv.org/abs/1606.03657&lt;/a&gt;&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Improved Techniques for Training GANs&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;https://arxiv.org/abs/1606.03498&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;On the Quantitative Analysis of Decoder-Based Generative Models&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1611.04273&quot;&gt;https://arxiv.org/abs/1611.04273&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;A Connection between Generative Adversarial Networks, Inverse Reinforcement Learning, and Energy Based Models [Also Reinforcement Learning]&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1611.03852.pdf&quot;&gt;https://arxiv.org/pdf/1611.03852.pdf&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;PixelCNN++: Improving the Pixel CNN with Discretized Logistic Mixture Likelihood and Other Modifications&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1701.05517&quot;&gt;https://arxiv.org/abs/1701.05517&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Learning to Generate Reviews and Discovering Sentiment&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1704.01444&quot;&gt;https://arxiv.org/abs/1704.01444&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Evolution&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Evolution Strategies as a Scalable Alternative to Reinforcement Learning&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;https://arxiv.org/abs/1703.03864&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Applications&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Security / Safety&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;Deep Reinforcement Learning from Human Preferences&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1706.03741&quot;&gt;https://arxiv.org/abs/1706.03741&lt;/a&gt;&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Concrete Problems in AI Safety&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;https://arxiv.org/abs/1606.06565&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Adversarial Attacks on Neural Network Policies&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1702.02284&quot;&gt;https://arxiv.org/abs/1702.02284&lt;/a&gt;&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Adversarial Training Methods for Semi-Supervised Text Classification&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1605.07725&quot;&gt;https://arxiv.org/abs/1605.07725&lt;/a&gt;&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Semi-Supervised Knowledge Transfer for Deep Learning from Private Training Data&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1610.05755&quot;&gt;https://arxiv.org/abs/1610.05755&lt;/a&gt;&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Debate Amplification&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;https://arxiv.org/pdf/1805.00899.pdf&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Robotics&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;Domain Randomization for Transferring Deep NEural Networks from Simulation to the Real World&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.06907&quot;&gt;https://arxiv.org/abs/1703.06907&lt;/a&gt;&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Transfer from Simulation to Real World through Learning Deep Inverse Dynamics Model&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1610.03518&quot;&gt;https://arxiv.org/abs/1610.03518&lt;/a&gt;&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Environments&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Infrastructure for Deep Learning&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;https://blog.openai.com/infrastructure-for-deep-learning/&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Universe&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://blog.openai.com/universe/&quot;&gt;https://blog.openai.com/universe/&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;OpenAI Gym&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1606.01540&quot;&gt;https://arxiv.org/abs/1606.01540&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;OpenAI Researchers (Every name on a published OpenAI Paper)&lt;/p&gt;

&lt;p&gt;Paul Christiano&lt;/p&gt;

&lt;p&gt;&lt;del&gt;Ryan Lowe&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;Jean Harb&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;Pieter Abbeel&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;Igor Mordatch&lt;/p&gt;

&lt;p&gt;Matthias Plappert&lt;/p&gt;

&lt;p&gt;Rein Houthooft&lt;/p&gt;

&lt;p&gt;Prafulla Dhariwal&lt;/p&gt;

&lt;p&gt;Szymon Sidor&lt;/p&gt;

&lt;p&gt;Richard Y. Chen&lt;/p&gt;

&lt;p&gt;&lt;del&gt;Xi Chen&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;Marcin Andrychowicz&lt;/p&gt;

&lt;p&gt;John Schulman&lt;/p&gt;

&lt;p&gt;Alec Radford&lt;/p&gt;

&lt;p&gt;&lt;del&gt;Rafal Jozefowicz&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;Yan Duan&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;Bradly C. Stadie&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;Jonathan Ho&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;Jonas Schneider&lt;/p&gt;

&lt;p&gt;Ilya Sutskever&lt;/p&gt;

&lt;p&gt;Wojciech Zaremba&lt;/p&gt;

&lt;p&gt;&lt;del&gt;Rachel Fong&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;Josh Tobin&lt;/p&gt;

&lt;p&gt;Alex Ray&lt;/p&gt;

&lt;p&gt;&lt;del&gt;Nikhil Mishra&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;Ian Goodfellow&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;Tim Salimans&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;Diederik P. Kingma&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;Andrej Karpathy&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;Yuri Burda&lt;/p&gt;

&lt;p&gt;&lt;del&gt;Zain Shah&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;Trevor Blackwell&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;Vicki Cheung&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://990s.foundationcenter.org/990_pdf_archive/810/810861541/810861541_201612_990.pdf&quot;&gt;Salaries of top employees&lt;/a&gt; [Pg. 28]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.guidestar.org/FinDocuments/2016/810/861/2016-810861541-0eb61629-9.pdf&quot;&gt;Hours &amp;amp; Salaries of top employees&lt;/a&gt; [Pg. 7]&lt;/p&gt;

&lt;p&gt;OpenAI spent 11 million in 2016, 7 million on salary. For comparison, Deepmind spend 138 million in 2016.&lt;/p&gt;</content><author><name></name></author><summary type="html">By Jeremy Nixon [jnixon2@gmail.com]. Nov 2017.</summary></entry><entry><title type="html">Deepmind’s Path to Neuro-inspired General Intelligence</title><link href="http://localhost:4000/thinking/2019/02/08/deepmind-path.html" rel="alternate" type="text/html" title="Deepmind's Path to Neuro-inspired General Intelligence" /><published>2019-02-08T17:29:46-08:00</published><updated>2019-02-08T17:29:46-08:00</updated><id>http://localhost:4000/thinking/2019/02/08/deepmind-path</id><content type="html" xml:base="http://localhost:4000/thinking/2019/02/08/deepmind-path.html">&lt;p&gt;By Jeremy Nixon [&lt;a href=&quot;mailto:jnixon2@gmail.com&quot;&gt;jnixon2@gmail.com&lt;/a&gt;]. Nov. 2017. Updated June 2018.&lt;/p&gt;

&lt;p&gt;Overview&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Deepmind Paper Framing&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Deepmind Papers through Framing&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Current Frontier&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Examples of Systems Neuroscience Inspiration&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Deepmind Papers&lt;/p&gt;

&lt;p&gt;Categories of the path to date:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Transfer Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Multi-task Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Tools, Environment &amp;amp; Datasets&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Intuitive Physics&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Reinforcement Learning&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Model-based RL&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Exploration in RL&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Applications&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Safety&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Deep Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;RNNs&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;CNNs&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Generative Models&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Variational Inference&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Unsupervised Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Representation Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Attention&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Memory&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Multi-Agent Systems&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Imitation Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Metalearning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Neural Programming&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Evolution&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Game Theory&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Natural Language Processing&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Multi-Modal Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;General Machine Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Theory&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Miscellaneous&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Neuroscience&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Papers:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Transfer Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;DARLA: Improving Zero-Shot Transfer In Reinforcement Learning&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1707.08475.pdf&quot;&gt;https://arxiv.org/pdf/1707.08475.pdf&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;PathNet: Evolution Channels Gradient Descent in Super Neural Networks&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1701.08734.pdf&quot;&gt;https://arxiv.org/pdf/1701.08734.pdf&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Matching Networks for One Shot Learning&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1606.04080&quot;&gt;https://arxiv.org/abs/1606.04080&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Progressive Neural Networks&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1606.04671.pdf&quot;&gt;https://arxiv.org/pdf/1606.04671.pdf&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Sim-to-Real Robot Learning from Pixels with Progressive Nets&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1610.04286.pdf&quot;&gt;https://arxiv.org/pdf/1610.04286.pdf&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Successor Features for Transfer in Reinforcement Learning&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1606.05312.pdf&quot;&gt;https://arxiv.org/pdf/1606.05312.pdf&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Multi-Task Learning&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Multi-task Self-Supervised Visual Learning&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1708.07860.pdf&quot;&gt;https://arxiv.org/pdf/1708.07860.pdf&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;The Intentional Unintentional Agent: Learning to Solve Many Continuous Control Tasks Simultaneously&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1707.03300.pdf&quot;&gt;https://arxiv.org/pdf/1707.03300.pdf&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Distral: Robust Multitask Reinforcement Learning&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1707.04175.pdf&quot;&gt;https://arxiv.org/pdf/1707.04175.pdf&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Emergence of Locomotion Behaviors in Rich Environments&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1707.02286.pdf&quot;&gt;https://arxiv.org/pdf/1707.02286.pdf&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Reinforcement Learning with Unsupervised Auxiliary Tasks&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1611.05397.pdf&quot;&gt;https://arxiv.org/pdf/1611.05397.pdf&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Learning to Navigate in Complex Environments&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1611.03673.pdf&quot;&gt;https://arxiv.org/pdf/1611.03673.pdf&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Learning and Transfer of Modulated Locomotor Controllers&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1610.05182.pdf&quot;&gt;https://arxiv.org/pdf/1610.05182.pdf&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Multi-Task Sequence to Sequence Learning&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1511.06114v3.pdf&quot;&gt;https://arxiv.org/pdf/1511.06114v3.pdf&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Learning by Playing - Solving Sparse Reward Tasks from Scratch&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1802.10567&quot;&gt;https://arxiv.org/abs/1802.10567&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Unicorn: Continual Learning with a Universal, Off-policy Agent&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1802.08294&quot;&gt;https://arxiv.org/abs/1802.08294&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Progress &amp;amp; Compress: A Scalable Framework for Continual Learning&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;https://arxiv.org/abs/1805.06370&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Tools, Environments, Evaluation &amp;amp; Datasets&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Starcraft II: A New Challenge for Reinforcement Learning&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1708.04782.pdf&quot;&gt;https://arxiv.org/pdf/1708.04782.pdf&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;DeepMind Lab&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1612.03801.pdf&quot;&gt;https://arxiv.org/pdf/1612.03801.pdf&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;The Kinetics Human Action Video Dataset&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1705.06950.pdf&quot;&gt;https://arxiv.org/pdf/1705.06950.pdf&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;An approximation of the Universal Intelligence Measure&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1109.5951v2.pdf&quot;&gt;https://arxiv.org/pdf/1109.5951v2.pdf&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Psychlab: A Psychology Laboratory for Deep Reinforcement Learning&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1801.08116&quot;&gt;https://arxiv.org/abs/1801.08116&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Deepmind Control Suite&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1801.00690v1.pdf&quot;&gt;https://arxiv.org/pdf/1801.00690v1.pdf&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1705.07750.pdf&quot;&gt;https://arxiv.org/pdf/1705.07750.pdf&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Intuitive Physics&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Position-Velocity Encoders for Unsupervised Learning of Structured State Representations&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1705.09805.pdf&quot;&gt;https://arxiv.org/pdf/1705.09805.pdf&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Learning to Perform Physics Experiments via Deep Reinforcement Learning&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1611.01843.pdf&quot;&gt;https://arxiv.org/pdf/1611.01843.pdf&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Continuous Control with Deep Reinforcement Learning&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1509.02971v2.pdf&quot;&gt;https://arxiv.org/pdf/1509.02971v2.pdf&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Reinforcement Learning (Papers with a pure RL focus)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Model-Based RL&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Learning Model-Based Planning from Scratch [Also, Planning]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1707.06170.pdf&quot;&gt;https://arxiv.org/pdf/1707.06170.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Recurrent Environment Simulators&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1704.02254.pdf&quot;&gt;https://arxiv.org/pdf/1704.02254.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Structure Learning in Motor Control: A Deep Reinforcement Learning Model [Also Transfer, Intuitive Physics]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1706.06827.pdf&quot;&gt;https://arxiv.org/pdf/1706.06827.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Imagination-Augmented Agents for Deep Reinforcement Learning [Also, Planning]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1707.06203&quot;&gt;https://arxiv.org/abs/1707.06203&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Continuous Deep Q-Learning with Model-based Acceleration&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1603.00748&quot;&gt;https://arxiv.org/abs/1603.00748&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Skip Context Tree Switching&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v32/bellemare14.pdf&quot;&gt;http://proceedings.mlr.press/v32/bellemare14.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Bayes-Adaptive Simulation-Based Search with Value Function Approximation&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www0.cs.ucl.ac.uk/staff/d.silver/web/Publications_files/bafa.pdf&quot;&gt;http://www0.cs.ucl.ac.uk/staff/d.silver/web/Publications_files/bafa.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Learning and Querying Fast Generative Models for Reinforcement Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1802.03006&quot;&gt;https://arxiv.org/abs/1802.03006&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Exploration in RL&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Count-Based Exploration with Neural Density Models&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1703.01310.pdf&quot;&gt;https://arxiv.org/pdf/1703.01310.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Unifying Count-Based Exploration and Intrinsic Motivation&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1606.01868&quot;&gt;https://arxiv.org/abs/1606.01868&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Deep Exploration via Bootstrapped DQN&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1602.04621&quot;&gt;https://arxiv.org/abs/1602.04621&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Variational Intrinsic Control&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1611.07507.pdf&quot;&gt;https://arxiv.org/pdf/1611.07507.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Learning to Search with MCTSnets&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1802.04697v1&quot;&gt;https://arxiv.org/abs/1802.04697v1&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Observe and Look Further: Achieving Consistent Performance on Atari&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https://arxiv.org/abs/1805.11593&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A Distributional Perspective on Reinforcement Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1707.06887.pdf&quot;&gt;https://arxiv.org/pdf/1707.06887.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;FeUdal Networks for Hierarchical Reinforcement Learning [Also, Planning]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1703.01161.pdf&quot;&gt;https://arxiv.org/pdf/1703.01161.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Combining Policy Gradient and Q-Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1611.01626.pdf&quot;&gt;https://arxiv.org/pdf/1611.01626.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Strategic Attentive Writer for Learning Macro-Actions&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1606.04695.pdf&quot;&gt;https://arxiv.org/pdf/1606.04695.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Safe and Efficient Off-Policy Reinforcement Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1606.02647&quot;&gt;https://arxiv.org/abs/1606.02647&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Deep Reinforcement Learning for Robotic Manipulation with Asynchronous Off-Policy Updates&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1610.00633.pdf&quot;&gt;https://arxiv.org/pdf/1610.00633.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Thompson Sampling is Asymptotically Optimal in General Environments&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1602.07905.pdf&quot;&gt;https://arxiv.org/pdf/1602.07905.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Asynchronous Methods for Deep Reinforcement Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1602.01783&quot;&gt;https://arxiv.org/abs/1602.01783&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Dueling Network Architectures for Deep Reinforcement Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1511.06581&quot;&gt;https://arxiv.org/abs/1511.06581&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Increasing the Action Gap: New Operators for Reinforcement Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1512.04860&quot;&gt;https://arxiv.org/abs/1512.04860&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Deep Reinforcement Learning with Double Q-Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https://arxiv.org/abs/1509.06461&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Policy Distillation&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1511.06295.pdf&quot;&gt;https://arxiv.org/pdf/1511.06295.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Universal Value Function Approximators&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v37/schaul15.pdf&quot;&gt;http://proceedings.mlr.press/v37/schaul15.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Human-level Control through Deep Reinforcement Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf&quot;&gt;https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Learning Continuous Control Policies by Stochastic Value Gradients&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1510.09142v1.pdf&quot;&gt;https://arxiv.org/pdf/1510.09142v1.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Fictitious Self-Play in Extensive Form Games&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v37/heinrich15.pdf&quot;&gt;http://proceedings.mlr.press/v37/heinrich15.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Toward Minimax Off-policy Value Estimation&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v38/li15b.html&quot;&gt;http://proceedings.mlr.press/v38/li15b.html&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Massively Parallel Methods for Deep Reinforcement Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1507.04296.pdf&quot;&gt;https://arxiv.org/pdf/1507.04296.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Compress and Control&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1411.5326v1.pdf&quot;&gt;https://arxiv.org/pdf/1411.5326v1.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Deterministic Policy Gradient Algorithms&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v32/silver14.pdf&quot;&gt;http://proceedings.mlr.press/v32/silver14.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Playing Atari with Deep Reinforcement Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1312.5602v1.pdf&quot;&gt;https://arxiv.org/pdf/1312.5602v1.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Reinforcement Learning, Efficient Coding, and the Statistics of Natural Tasks&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.sciencedirect.com/science/article/pii/S2352154615001151&quot;&gt;http://www.sciencedirect.com/science/article/pii/S2352154615001151&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Rainbow: Combining Improvements in Deep Reinforcement Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1710.02298&quot;&gt;https://arxiv.org/abs/1710.02298&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Path Consistency Learning in Tsallis Entropy Regularized MDPs&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1802.03501&quot;&gt;https://arxiv.org/abs/1802.03501&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;More Robust Doubly Robust Off-Policy Evaluation&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1802.03493&quot;&gt;https://arxiv.org/abs/1802.03493&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1802.01561&quot;&gt;https://arxiv.org/abs/1802.01561&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Mis&amp;amp;Match - Agent Curricula for Reinforcement Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1806.01780&quot;&gt;https://arxiv.org/abs/1806.01780&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Vector-based Navigation Using Grid-Like Representations in Artificial Agents&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.nature.com/articles/s41586-018-0102-6.epdf&quot;&gt;https://www.nature.com/articles/s41586-018-0102-6.epdf&lt;/a&gt;?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kickstarting Deep Reinforcement Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https://arxiv.org/abs/1803.03835&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Applications&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Go&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Mastering the Game of Go with Deep Neural Networks and Tree Search&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf&quot;&gt;https://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;More Evaluation in Go using Deep Convolutional Neural Networks [Also, Convolutional Neural Networks]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www0.cs.ucl.ac.uk/staff/d.silver/web/Publications_files/deepgo.pdf&quot;&gt;http://www0.cs.ucl.ac.uk/staff/d.silver/web/Publications_files/deepgo.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Mastering the Game of Go Without Human Knowledge&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.nature.com/articles/nature24270.epdf&quot;&gt;https://www.nature.com/articles/nature24270.epdf&lt;/a&gt;?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Poker&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Smooth UCT Search in Computer Poker&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www0.cs.ucl.ac.uk/staff/d.silver/web/Publications_files/smooth_uct.pdf&quot;&gt;http://www0.cs.ucl.ac.uk/staff/d.silver/web/Publications_files/smooth_uct.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Fairness&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Path-Specific Counterfactual Fairness&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1802.08139.pdf&quot;&gt;https://arxiv.org/pdf/1802.08139.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Safety / Security&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Reinforcement Learning with a Corrupted Reward Channel [Also, Safety]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1705.08417.pdf&quot;&gt;https://arxiv.org/pdf/1705.08417.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Safely Interruptible Agents [Also, Safety]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://intelligence.org/files/Interruptibility.pdf&quot;&gt;https://intelligence.org/files/Interruptibility.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;AI Safety Gridworlds&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1711.09883&quot;&gt;https://arxiv.org/abs/1711.09883&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Adversarial Risk and the Dangers of Evaluating Against Weak Attacks&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1802.05666&quot;&gt;https://arxiv.org/abs/1802.05666&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Safe Exploration in Continuous Action Spaces&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1801.08757&quot;&gt;https://arxiv.org/abs/1801.08757&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Measuring and Avoiding Side Effects Using Relative Reachability&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https://arxiv.org/abs/1806.01186&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Deep Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Recurrent Neural Networks&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sequential Neural Models with Stochastic Layers [Also, Planning]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1605.07571&quot;&gt;https://arxiv.org/abs/1605.07571&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Memory-Efficient Backpropagation Through Time&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1606.03401&quot;&gt;https://arxiv.org/abs/1606.03401&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Adaptive Computation Time for Recurrent Neural Networks&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1603.08983&quot;&gt;https://arxiv.org/abs/1603.08983&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Grid Long-Short Term Memory&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1507.01526v3.pdf&quot;&gt;https://arxiv.org/pdf/1507.01526v3.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Order Matters: Sequence to Sequence for Sets&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1511.06391v3.pdf&quot;&gt;https://arxiv.org/pdf/1511.06391v3.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Convolutional Neural Networks&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Exploiting Cyclic Symmetry in Convolutional Neural Networks&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1602.02660&quot;&gt;https://arxiv.org/abs/1602.02660&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Spatial Transformer Networks&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1506.02025.pdf&quot;&gt;https://arxiv.org/pdf/1506.02025.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Very Deep Convolutional Networks for Large Scale Image Recognition&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1409h.1556v6.pdf&quot;&gt;https://arxiv.org/pdf/1409h.1556v6.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Pooling is Neither Necessary Nor Sufficient for Appropriate Deformation Stability in CNNs&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https://arxiv.org/abs/1804.04438&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Noisy Networks for Exploration&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1706.10295.pdf&quot;&gt;https://arxiv.org/pdf/1706.10295.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sobolev Training for Neural Networks&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1706.04859&quot;&gt;https://arxiv.org/abs/1706.04859&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Decoupled Neural Interfaces using Synthetic Gradients&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https://arxiv.org/pdf/1608.05343.pdf&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Understanding Synthetic Gradients and Decoupled Neural Interfaces&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1703.00522.pdf&quot;&gt;https://arxiv.org/pdf/1703.00522.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1612.01474.pdf&quot;&gt;https://arxiv.org/pdf/1612.01474.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Overcoming Catastrophic Forgetting in Neural Networks&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1612.00796.pdf&quot;&gt;https://arxiv.org/pdf/1612.00796.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Local Minima in Training of Neural Networks&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1611.06310.pdf&quot;&gt;https://arxiv.org/pdf/1611.06310.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Learning Values Across Many Orders of Magnitude&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1602.07714&quot;&gt;https://arxiv.org/abs/1602.07714&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;MuProp: Unbiased Backpropagation for Stochastic Neural Networks&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1511.05176v2.pdf&quot;&gt;https://arxiv.org/pdf/1511.05176v2.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ACDC: A Structured Efficient Linear Layer&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1511.05946v3.pdf&quot;&gt;https://arxiv.org/pdf/1511.05946v3.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Natural Neural Networks&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1507.00210.pdf&quot;&gt;https://arxiv.org/pdf/1507.00210.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Gradient Estimation Using Stochastic Computation Graphs&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1506.05254v1.pdf&quot;&gt;https://arxiv.org/pdf/1506.05254v1.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Weight Uncertainty in Neural Networks&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v37/blundell15.pdf&quot;&gt;http://proceedings.mlr.press/v37/blundell15.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Stochastic Backpropagation and Approximate Inference in Deep Generative Models&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1401.4082&quot;&gt;https://arxiv.org/abs/1401.4082&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;On the Importance of Single Directions for Generalization&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https://arxiv.org/abs/1803.06959&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Variational Inference&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Filtering Variational Objectives&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1705.09279.pdf&quot;&gt;https://arxiv.org/pdf/1705.09279.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Variational Inference for Monte Carlo Objectives&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1602.06725&quot;&gt;https://arxiv.org/abs/1602.06725&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Variational Inference with Normalizing Flows&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1505.05770.pdf&quot;&gt;https://arxiv.org/pdf/1505.05770.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Variational Information Maximization for Intrinsically Motivated Reinforcement Learning [Also, Reinforcement Learning]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1509.08731v1.pdf&quot;&gt;https://arxiv.org/pdf/1509.08731v1.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Neural Variational Inference and Learning in Belief Networks&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1402.0030v2.pdf&quot;&gt;https://arxiv.org/pdf/1402.0030v2.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Distribution Matching in Variational Inference [Also, Generative, Unsupervised Learning]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https://arxiv.org/abs/1802.06847&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Generative Models&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The Cramer Distance as a Solution to Biased Wasserstein Gradients&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1705.10743.pdf&quot;&gt;https://arxiv.org/pdf/1705.10743.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Variational Approaches for Auto-Encoding Generative Adversarial Networks&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1706.04987.pdf&quot;&gt;https://arxiv.org/pdf/1706.04987.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Comparison of Maximum Likelihood and GAN-based training of Real NVPs&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1705.05263.pdf&quot;&gt;https://arxiv.org/pdf/1705.05263.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Parallel Multiscale Autoregressive Density Estimation&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1703.03664.pdf&quot;&gt;https://arxiv.org/pdf/1703.03664.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Conditional Image Generation with PixelCNN Decoders&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1606.05328.pdf&quot;&gt;https://arxiv.org/pdf/1606.05328.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;WaveNet: A Generative Model for Raw Audio&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1609.03499.pdf&quot;&gt;https://arxiv.org/pdf/1609.03499.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Video Pixel Networks&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1610.00527.pdf&quot;&gt;https://arxiv.org/pdf/1610.00527.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Learning in Implicit Generative Models&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1610.03483.pdf&quot;&gt;https://arxiv.org/pdf/1610.03483.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Connecting Generative Adversarial Networks and Actor-Critic Methods [Also, Reinforcement Learning]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1610.01945.pdf&quot;&gt;https://arxiv.org/pdf/1610.01945.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Pixel Recurrent Neural Networks&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1601.06759&quot;&gt;https://arxiv.org/abs/1601.06759&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;One-Shot Generalization in Deep Generative Models&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1603.05106&quot;&gt;https://arxiv.org/abs/1603.05106&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A Test of Relative Similarity for Model Selection in Generative Models&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1511.04581.pdf&quot;&gt;https://arxiv.org/pdf/1511.04581.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;DRAW: A Recurrent Neural Network for Image Generation [Also, Attention]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v37/gregor15.pdf&quot;&gt;http://proceedings.mlr.press/v37/gregor15.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Semi-Supervised Learning with Deep Generative Models&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1406.5298&quot;&gt;https://arxiv.org/abs/1406.5298&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Deep AutoRegressive Networks&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1310.8499&quot;&gt;https://arxiv.org/abs/1310.8499&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A Note on the Evaluation of Generative Models&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1511.01844v2.pdf&quot;&gt;https://arxiv.org/pdf/1511.01844v2.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Parallel WaveNet: Fast High-Fidelity Speech Synthesis (WaveRNN)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1711.10433&quot;&gt;https://arxiv.org/abs/1711.10433&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Efficient Neural Audio synthesis&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1802.08435&quot;&gt;https://arxiv.org/abs/1802.08435&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Learning and Querying Fast Generative Models for Reinforcement Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https://arxiv.org/abs/1802.03006&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Unsupervised Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Unsupervised Learning of 3D Structure from Images [Also, Computer Vision]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1607.00662.pdf&quot;&gt;https://arxiv.org/pdf/1607.00662.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Early Visual Concept Learning with Unsupervised Deep Learning (beta-VAE)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1606.05579.pdf&quot;&gt;https://arxiv.org/pdf/1606.05579.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Neural Scene Representation and Rendering&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://science.sciencemag.org/content/360/6394/1204&quot;&gt;http://science.sciencemag.org/content/360/6394/1204&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Spectral Inference Networks: Unifying Spectral Methods with Deep Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1806.02215&quot;&gt;https://arxiv.org/abs/1806.02215&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Representation Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;SCAN: Learning Abstract Hierarchical Compositional Visual Concepts&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1707.03389.pdf&quot;&gt;https://arxiv.org/pdf/1707.03389.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Towards Conceptual Compression&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1604.08772&quot;&gt;https://arxiv.org/abs/1604.08772&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Neural Discrete Representation Learning [Also, Unsupervised Learning]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1711.00937&quot;&gt;https://arxiv.org/abs/1711.00937&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Disentangling by Factorising&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1802.05983&quot;&gt;https://arxiv.org/abs/1802.05983&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Associative Compression Networks for Representation Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https://arxiv.org/abs/1804.02476&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Attention&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Attend, Infer, Repeat: Fast Scene Understanding with Generative Models&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1603.08575.pdf&quot;&gt;https://arxiv.org/pdf/1603.08575.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Reasoning about Entailment with Neural Attention [Also, Natural Language Processing]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1509.06664v2.pdf&quot;&gt;https://arxiv.org/pdf/1509.06664v2.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Multiple Object Recognition with Visual Attention&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1412.7755v2.pdf&quot;&gt;https://arxiv.org/pdf/1412.7755v2.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Recurrent Models of Visual Attention&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https://arxiv.org/abs/1406.6247&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Memory&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Neural Episodic Control&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1703.01988.pdf&quot;&gt;https://arxiv.org/pdf/1703.01988.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Generative Temporal Models With Memory&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1702.04649.pdf&quot;&gt;https://arxiv.org/pdf/1702.04649.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1610.09027.pdf&quot;&gt;https://arxiv.org/pdf/1610.09027.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Model-Free Episodic Control&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1606.04460&quot;&gt;https://arxiv.org/abs/1606.04460&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;One-Shot Learning with Memory-Augmented Neural Networks&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1605.06065&quot;&gt;https://arxiv.org/abs/1605.06065&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Associative Long Short-Term Memory&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1602.03032&quot;&gt;https://arxiv.org/abs/1602.03032&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Prioritized Experience Replay&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1511.05952v3.pdf&quot;&gt;https://arxiv.org/pdf/1511.05952v3.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sample Efficient Actor-Critic with Experience Replay&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1611.01224.pdf&quot;&gt;https://arxiv.org/pdf/1611.01224.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Learning Efficient Algorithms with Hierarchical Attentive Memory [Also, attention]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1602.03218&quot;&gt;https://arxiv.org/abs/1602.03218&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Count-Based Frequency Estimation with Bounded Memory [Also, Natural Language Processing]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.ijcai.org/Proceedings/15/Papers/470.pdf&quot;&gt;http://www.ijcai.org/Proceedings/15/Papers/470.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Memory-based Parameter Adaptation&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https://arxiv.org/abs/1802.10542&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Multi-Agent Systems&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Value Decomposition Networks For Cooperative Multi-Agent Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1706.05296.pdf&quot;&gt;https://arxiv.org/pdf/1706.05296.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Learning to Communicate with Deep Multi-Agent Reinforcement Learning [Also, Multi-Task RL]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1605.06676v2.pdf&quot;&gt;https://arxiv.org/pdf/1605.06676v2.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning [Also, Game Theory]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1711.00832&quot;&gt;https://arxiv.org/abs/1711.00832&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Machine Theory of Mind&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https://arxiv.org/abs/1802.07740&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Imitation Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Robust Imitation of Diverse Behaviors&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1707.02747.pdf&quot;&gt;https://arxiv.org/pdf/1707.02747.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Learning Human Behaviors from Motion Capture by Adversarial Imitation&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1707.02201&quot;&gt;https://arxiv.org/abs/1707.02201&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Leveraging Demonstrations for Deep Reinforcement Learning on Robotics Problems with Sparse Rewards&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1707.08817.pdf&quot;&gt;https://arxiv.org/pdf/1707.08817.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Reinforcement and Imitation Learning for Diverse Visuomotor Skills&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1802.09564&quot;&gt;https://arxiv.org/abs/1802.09564&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Playing Hard Exploration Games by Watching Youtube&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https://arxiv.org/abs/1805.11592&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Metalearning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Neural Programming&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Hybrid Computing Using a Neural Network with Dynamic External Memory&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.nature.com/articles/nature20101.epdf?author_access_token=ImTXBI8aWbYxYQ51Plys8NRgN0jAjWel9jnR3ZoTv0MggmpDmwljGswxVdeocYSurJ3hxupzWuRNeGvvXnoO8o4jTJcnAyhGuZzXJ1GEaD-Z7E6X_a9R-xqJ9TfJWBqz&quot;&gt;https://www.nature.com/articles/nature20101.epdf?author_access_token=ImTXBI8aWbYxYQ51Plys8NRgN0jAjWel9jnR3ZoTv0MggmpDmwljGswxVdeocYSurJ3hxupzWuRNeGvvXnoO8o4jTJcnAyhGuZzXJ1GEaD-Z7E6X_a9R-xqJ9TfJWBqz&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Programmable Agents [Also, Representation Learning]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1706.06383.pdf&quot;&gt;https://arxiv.org/pdf/1706.06383.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Neural Programmer-Interpreters&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1511.06279v3.pdf&quot;&gt;https://arxiv.org/pdf/1511.06279v3.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Neural Random-Access Machines&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1511.06392v3.pdf&quot;&gt;https://arxiv.org/pdf/1511.06392v3.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Neural Turing Machines&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1410.5401&quot;&gt;https://arxiv.org/abs/1410.5401&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Learning Explanatory Rules from Noisy Data&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1711.04574&quot;&gt;https://arxiv.org/abs/1711.04574&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Synthesizing Programs for Images using Reinforced Adversarial Learning (SPIRAL)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https://arxiv.org/abs/1804.01118&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Learning to learn by gradient descent by gradient descent&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1606.04474&quot;&gt;https://arxiv.org/abs/1606.04474&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Learning to Reinforcement Learn [Also, Reinforcement Learning]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1611.05763.pdf&quot;&gt;https://arxiv.org/pdf/1611.05763.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Hierarchical Representations for Efficient Architecture Search&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1711.00436.pdf&quot;&gt;https://arxiv.org/pdf/1711.00436.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Population Based Training of Neural Networks&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1711.09846&quot;&gt;https://arxiv.org/abs/1711.09846&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Meta-Gradient Reinforcement Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https://arxiv.org/abs/1805.09801&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Evolution&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Convolution by Evolution&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https://arxiv.org/pdf/1606.02580.pdf&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Game Theory&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Learning Nash Equilibrium for General-Sum Markov Games from Batch Data&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1606.08718.pdf&quot;&gt;https://arxiv.org/pdf/1606.08718.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The Mechanics of n-Player Differentiable Games [Also, Generative Models (GANs)]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1802.05642&quot;&gt;https://arxiv.org/abs/1802.05642&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Symmetric Decomposition of Asymmetric Games&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.nature.com/articles/s41598-018-19194-4&quot;&gt;https://www.nature.com/articles/s41598-018-19194-4&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A Generalised Method for Empirical Game Theoretic Analysis&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1803.06376&quot;&gt;https://arxiv.org/abs/1803.06376&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Inequity Aversion Resolves Intertemporal Social Dilemmas&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https://arxiv.org/abs/1803.08884&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Natural Language Processing&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Generative and Discriminative Text Classification with Recurrent Neural Networks&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1703.01898.pdf&quot;&gt;https://arxiv.org/pdf/1703.01898.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Learning to Compose Words Into Sentences with Reinforcement Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1611.09100.pdf&quot;&gt;https://arxiv.org/pdf/1611.09100.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Reference-Aware Language Models&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1611.01628.pdf&quot;&gt;https://arxiv.org/pdf/1611.01628.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The Neural Noisy Channel&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1611.02554.pdf&quot;&gt;https://arxiv.org/pdf/1611.02554.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Latent Predictor Networks for Code Generation&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1603.06744.pdf&quot;&gt;https://arxiv.org/pdf/1603.06744.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Learning the Curriculum with Bayesian Optimization for Task-Specific Word Representation Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1605.03852.pdf&quot;&gt;https://arxiv.org/pdf/1605.03852.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Semantic Parsing with Semi-Supervised Sequential Autoencoders&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1609.09315.pdf&quot;&gt;https://arxiv.org/pdf/1609.09315.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;On the State of the Art of Evaluation in Neural Language Models&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1707.05589&quot;&gt;https://arxiv.org/abs/1707.05589&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Teaching Machines to Read and Comprehend&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1506.03340v1.pdf&quot;&gt;https://arxiv.org/pdf/1506.03340v1.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Learning to Transduce with Unbounded Memory [Also, Memory, Neural Programming]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1506.02516v1.pdf&quot;&gt;https://arxiv.org/pdf/1506.02516v1.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Dependency Recurrent Neural Language Models for Sentence Completion&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://cs.nyu.edu/~mirowski/pub/MirowskiVlachos_ACL2015_DependencyTreeRNN.pdf&quot;&gt;http://cs.nyu.edu/~mirowski/pub/MirowskiVlachos_ACL2015_DependencyTreeRNN.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Towards End-to-End Speech Recognition with Recurrent Neural Networks&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v32/graves14.pdf&quot;&gt;http://proceedings.mlr.press/v32/graves14.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Learning Word Embeddings Efficiently with Noise-Contrastive Estimation&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://papers.nips.cc/paper/5165-learning-word-embeddings-efficiently-with-noise-contrastive-estimation.pdf&quot;&gt;http://papers.nips.cc/paper/5165-learning-word-embeddings-efficiently-with-noise-contrastive-estimation.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The NarrativeQA Reading Comprehension Challenge&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1712.07040v1&quot;&gt;https://arxiv.org/abs/1712.07040v1&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Learning to Follow Language Instructions with Adversarial Reward Induction [Also, Loss Function Learning]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https://arxiv.org/abs/1806.01946&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Multi-Modal&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Look, Listen and Learn&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1705.08168.pdf&quot;&gt;https://arxiv.org/pdf/1705.08168.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;End-to-end Optimization of Goal-Driven and Visually Grounded Dialogue Systems&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1703.05423.pdf&quot;&gt;https://arxiv.org/pdf/1703.05423.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;GuessWhat?! Visual Object Discovery through Multi-Modal Dialogue&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1611.08481.pdf&quot;&gt;https://arxiv.org/pdf/1611.08481.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Grounded Language Learning in a Simulated 3D World&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1706.06551.pdf&quot;&gt;https://arxiv.org/pdf/1706.06551.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Understanding Grounded Language Learning Agents [Also, Natural Language Processing]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1710.09867&quot;&gt;https://arxiv.org/abs/1710.09867&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Objects that Sound&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1712.06651&quot;&gt;https://arxiv.org/abs/1712.06651&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;General Machine Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1611.00712.pdf&quot;&gt;https://arxiv.org/pdf/1611.00712.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Learning Deep Nearest Neighbor Representations Using Differentiable Boundary Trees&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1702.08833.pdf&quot;&gt;https://arxiv.org/pdf/1702.08833.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Unit Tests for Stochastic Optimization&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1312.6055v3.pdf&quot;&gt;https://arxiv.org/pdf/1312.6055v3.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Bayesian Hierarchical Community Discovery&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://papers.nips.cc/paper/5048-bayesian-hierarchical-community-discovery.pdf&quot;&gt;http://papers.nips.cc/paper/5048-bayesian-hierarchical-community-discovery.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Implicit Reparameterization Gradients&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1805.08498&quot;&gt;https://arxiv.org/abs/1805.08498&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Cleaning up the Neighborhood: A Full Classification for Adversarial Partial Monitoring&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https://arxiv.org/abs/1805.09247&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Theory&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Online Learning with Gated Linear Networks&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https://arxiv.org/abs/1712.01897v1&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Miscellaneous&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Generalized Probability Smoothing&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1712.02151&quot;&gt;https://arxiv.org/abs/1712.02151&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Agents and Devices: A Relative Definition of Agency&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1805.12387&quot;&gt;https://arxiv.org/abs/1805.12387&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Neuroscience&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The Successor representation in human reinforcement learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.biorxiv.org/content/biorxiv/early/2017/07/04/083824.full.pdf&quot;&gt;http://www.biorxiv.org/content/biorxiv/early/2017/07/04/083824.full.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Dorsal Hippocampus Contributes to Model-Based Planning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.nature.com/articles/nn.4613.epdf?author_access_token=OfuqRzRgBmFKQdGE1Qw7FdRgN0jAjWel9jnR3ZoTv0N3IprbEH8EVdPgVTpPLVjgaMNMGW_KprBhEEIm7f1drNjI5FB2fds3h58n3XEtMJPC3kLK1Pp3J2_Qb45cy7uk&quot;&gt;https://www.nature.com/articles/nn.4613.epdf?author_access_token=OfuqRzRgBmFKQdGE1Qw7FdRgN0jAjWel9jnR3ZoTv0N3IprbEH8EVdPgVTpPLVjgaMNMGW_KprBhEEIm7f1drNjI5FB2fds3h58n3XEtMJPC3kLK1Pp3J2_Qb45cy7uk&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Neuroscience-Inspired Artificial Intelligence&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.cell.com/neuron/fulltext/S0896-6273(17)30509-3&quot;&gt;http://www.cell.com/neuron/fulltext/S0896-6273(17)30509-3&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Computations Underlying Social Hierarchy Learning: Distinct Neural Mechanism for Updating and Representing Self-Relevant Information&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.cell.com/neuron/pdf/S0896-6273(16)30802-9.pdf&quot;&gt;http://www.cell.com/neuron/pdf/S0896-6273(16)30802-9.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Dorsal Anterior Cingulate Cortex and the Value of Control&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.nature.com/articles/nn.4384.epdf?author_access_token=dq-w7RyWLn3z-0m4nbyTW9RgN0jAjWel9jnR3ZoTv0N7RVyemANPvboWSepiJaSAsTFiGqyORVbog9B6IjN113kC9aqMAEoNVCCfdRA4gLVJXcy4e1klhW0KiKS5F1gp&quot;&gt;https://www.nature.com/articles/nn.4384.epdf?author_access_token=dq-w7RyWLn3z-0m4nbyTW9RgN0jAjWel9jnR3ZoTv0N7RVyemANPvboWSepiJaSAsTFiGqyORVbog9B6IjN113kC9aqMAEoNVCCfdRA4gLVJXcy4e1klhW0KiKS5F1gp&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Semantic Representations in the Temporal Pole Predict False Memories&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.pnas.org/content/113/36/10180.abstract&quot;&gt;http://www.pnas.org/content/113/36/10180.abstract&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Towards an Integration of Deep Learning and Neuroscience&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.biorxiv.org/content/early/2016/06/13/058545&quot;&gt;http://www.biorxiv.org/content/early/2016/06/13/058545&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;What Learning Systems do Intelligent Agents Need? Complementary Learning systems Theory Updated&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(16)30043-2&quot;&gt;http://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(16)30043-2&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Neural Mechanisms of Hierarchical Planning in a Virtual Subway Network [Also, Planning]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.cell.com/neuron/abstract/S0896-6273(16)30057-5&quot;&gt;http://www.cell.com/neuron/abstract/S0896-6273(16)30057-5&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Predictive Representations can Link Model-Based Reinforcement Learning to Model-Free Mechanisms&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.biorxiv.org/content/early/2016/10/27/083857&quot;&gt;https://www.biorxiv.org/content/early/2016/10/27/083857&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Hippocampal place cells construct reward related sequences through unexplored space&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://elifesciences.org/articles/06063&quot;&gt;https://elifesciences.org/articles/06063&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A Probabilistic Approach to Demixing Odors&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.nature.com/neuro/journal/v20/n1/full/nn.4444.html&quot;&gt;http://www.nature.com/neuro/journal/v20/n1/full/nn.4444.html&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Approximate Hubel-Wiesel Modules and the Data Structures of Neural Computation&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1512.08457v1.pdf&quot;&gt;https://arxiv.org/pdf/1512.08457v1.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The Future of Memory: Remembering, Imagining, and the Brain&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://static1.1.sqspcdn.com/static/f/1096238/22043246/1361990370157/FutureMemory--Neuron12.pdf?token=b5gB3ycz3e%2BmKnQQCW3%2FvwZyHwE%3D&quot;&gt;http://static1.1.sqspcdn.com/static/f/1096238/22043246/1361990370157/FutureMemory–Neuron12.pdf?token=b5gB3ycz3e%2BmKnQQCW3%2FvwZyHwE%3D&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Is the Brain a Good Model for Machine Intelligence?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.gatsby.ucl.ac.uk/~demis/TuringSpecialIssue(Nature2012).pdf&quot;&gt;http://www.gatsby.ucl.ac.uk/~demis/TuringSpecialIssue(Nature2012).pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Evidence Integration in Model-Based Tree Search&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.pnas.org/content/112/37/11708.full.pdf&quot;&gt;http://www.pnas.org/content/112/37/11708.full.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;(Commentary on0 Building Machines that Learn and Think for Themselves&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/building-machines-that-learn-and-think-for-themselves/E28DBFEC380D4189FB7754B50066A96F&quot;&gt;https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/building-machines-that-learn-and-think-for-themselves/E28DBFEC380D4189FB7754B50066A96F&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Prefrontal Cortex as a Meta-Reinforcement Learning System&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https://www.nature.com/articles/s41593-018-0147-8&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Current Frontier:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Hierarchical planning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Imagination-based planning with generative models&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Unsupervised Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Memory and one-shot learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Abstract Concepts&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Continual and Transfer Learning&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Emphasis on systems neuroscience - using the brain as inspiration for the structure and function of algorithms.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://sci-hub.cc/10.1016/j.neuron.2017.06.011&quot;&gt;Neuroscience Inspired Artificial Intelligence&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Examples of previous success of neuro-inspiration:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Reinforcement Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Inspired by animal learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;TD Learning came out of animal behavior research.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Second-order conditioning (Conditional Stimulus) (Sutton and Barto, 1981)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Deep Learning.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Convolutional Neural Networks. Visual Cortex (V1)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Uses hierarchical structure (successive processing layers)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Neurons in the early visual systems responds strongly to specific patterns of light (say, precisely oriented bars) but hardly responds to many other patterns.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Gabor functions describe the weights in V1 cells.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Nonlinear Transduction&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Divisive Normalization&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Word / Sentence Vectors - Distributed Embeddings&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Parallel Distributed Processing in the brain for representation and computation&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Dropout&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Stochasticity in neurons that fire with` Poisson-like statistics (Hinton 2012)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Attention&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Applying attention to memory&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Thought - it doesn’t make much sense to train an attention model over a static image, rather than over a time series. With a time series, bringing attention to changing aspects of the input makes sense.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Multiple Memory Systems&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Episodic Memory&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Experience Replay&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Especially for one shot experiences&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Working Memory&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;LSTM - gating allows for conditioning on current state&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Long-term Memory&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;External Memory&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Gating in LSTM&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Continual Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Elastic weight consolidation for slowing down learning on weights that are important for previous tasks.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Examples of future success:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Intuitive Understanding of Physics&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Need to understand space, number, objectness&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Need to disentangle representations for transfer. (Dude, I feel so stolen from)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Efficient Learning (Learning from few examples)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Transfer Learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Transferring generalized knowledge gained in one context to novel domains&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Concept representations for transfer&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;No direct evidence of concept representations in brains&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Imagination and Planning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Toward model-based RL&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Internal model of the environment&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Model needs to include compositional / disentangled representations for flexibility&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Implementing a forecasted-based method of action selection&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Monte-carlo Tree Search as simulation based planning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In rat brains, we observe ‘preplay’ where rats imagine the likely future experience - measured by comparing neural activations at preplay to activations during the activity&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Generalization + Transfer in human planning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Hierarchical Planning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Virtual Brain Analytics&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;2.&lt;/p&gt;</content><author><name></name></author><summary type="html">By Jeremy Nixon [jnixon2@gmail.com]. Nov. 2017. Updated June 2018.</summary></entry><entry><title type="html">Memetics</title><link href="http://localhost:4000/thinking/2019/02/08/memetics.html" rel="alternate" type="text/html" title="Memetics" /><published>2019-02-08T17:27:46-08:00</published><updated>2019-02-08T17:27:46-08:00</updated><id>http://localhost:4000/thinking/2019/02/08/memetics</id><content type="html" xml:base="http://localhost:4000/thinking/2019/02/08/memetics.html">&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Tools exist to create computational memetics through machine learning / NLP&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Transmission is a function of emotion / simplicity, not truth&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The only ideas you see are the ones that can propagate&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Memes are antifragile (grow stronger from attack, generally through increased exposure)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Replicators&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Transmission by moving from one mind to another&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Differential Selection based on longevity, fecundity / virality, copying-fidelity&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;There are many truths that can not or fail to propagate that are lying around to be collected&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Competing memes buttress one another&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Opposed memes generate controversy, leading to arguments that ensure that many are exposed to the meta-meme&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;http://slatestarcodex.com/2014/12/17/the-toxoplasma-of-rage/&quot;&gt;Ex. Toxoplasma of rage&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Memes are replicators that ideologies cooperate to spread&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Memetic drift&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Due to negative connotation&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Colored -&amp;gt; Negro -&amp;gt; African American / Black&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Artificial Intelligence -&amp;gt; Machine Intelligence&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Memetics as organismic analogy for ideas&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sources on “memes” within an evolutionary framework&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Dawkins, The Selfish Gene, Chapter 11 Memes: The New Replicators&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Vaccination / Immunization to ideas&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Meme design&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Meme components&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Emotional / Attentional&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Value Add&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Genealogy of ideas&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Computational Memetics&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Cascade prediction&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Predicting the spread of memes across a social graph&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;a href=&quot;https://www.cs.cornell.edu/home/kleinber/www14-cascades.pdf&quot;&gt;Ex. Can cascades be predicted?&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Predicting strength of inculcation of meme&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;Ex., number of times meme repeated by a person&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Intensity / Density of engagement with meme&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Understanding Properties of Memes&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Affect / Sentiment / Emotionality&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Longevity&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Fecundity (Propensity to spread)&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Understanding people - which memes they’re vulnerable to&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Understanding the memetic environment&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Learn the structure of the genealogy of memes&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Networks over which to conduct research&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Top Tier&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;Twitter&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Facebook&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Reddit&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Second Tier&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;Instagram&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Youtube&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;LinkedIn&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Pinterest&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Tumblr&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Third Tier&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;Quora&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Google Trends&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Google / Bing / Yahoo Search Results&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Google +&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The Selfish Gene Meme Idea List:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Memetic evolution is much faster than genetic evolution&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Memes can be seen as alive, if life evolves by the differential survival of replicators.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Memes are parasites, in that they use their host to survive and reproduce.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The emergence of the meme as a new replicator is akin to the emergence of alien life on our planet.&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;We make a distinction between cellular life and memetic life.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Life = Replicator + Differential Selection. Not cellular life - memetic life. That’s why it’s alien.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Memes are alien because they’re separate from us - they’re parasites / mutualists / commensalists. We are hardware for the memes. People identify with memes - that’s a property of memes that give it strength. There is definitely coevolution between memes and people. People conflate memes (ideas, beliefs, memories) and cells (platform, hardware) when thinking about “their life”.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The name meme comes out of ‘mime’ - from the imitation that memes use to spread.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Standards for memes:&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Longevity&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Virality / Fecundity&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Creation of Desire to Spread&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;Value Added&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Psychological Appeal&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Ease of Spread&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;Simplicity&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Attachment to other memes in cultural environment&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Creation of Need to Spread&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;Ex., Hell&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Copying Fidelity?&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Empirically, memes are constantly modified and blended, certainly at a low level of abstraction&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Memes often have Hierarchical Structure&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Memes exist at multiple levels of abstraction&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Memes have higher fidelity at more abstract levels&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Memes can be thought of as active agents, working for their own survival. Memes defend themselves, invade others, etc.&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;They are just like biological life; they have a fitness function.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Memes compete over limited resources.&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Attention&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Memory&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Time (Ex. Radio / TV Time)&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Space (Ex. Billboard Space, Newspaper Column-Inches, Library Shelf Space)&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Interaction with Cultural Environment&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Many memes are closely linked and share their selection outcome&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Ex. Organized Church, with architecture, rituals, laws, music, art, writings.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Memes can hijack other memes to propagate themselves.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Explanation for behavior that doesn’t have a grounding in evolution&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;A gene for celibacy is unlikely to survive, but a meme for celibacy can.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Memes can oppose evolutionary success of the human carrying the meme&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Ex. Celibacy, Life after Death, Honor in war&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;There is stability in the meme pool, which new memes have to invade. Pool goes to evolutionarily stable solution.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Genetic longevity through children as weaker than memetic longevity.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;We don’t need to look for biological survival value of traits like religion, music, dancing, etc. - we just need to show that the memes have properties that advantage their own survival.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Examples of Memes:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Tunes&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Song - ‘Auld Lang Syne’&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Symphony&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ideas&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;God / Religion&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Jewish Religion Laws&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Life After Death&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Threat of Hell&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Faith - Belief without evidence&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Celibacy&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Catch-phrases&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Fashon&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Engineering&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Ways of making pots (aesthetic)&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Ways of creating arches (aesthetic)&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Language&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Songs of Songbirds&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Diet&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ceremonies&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Customs&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Art&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Architecture&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><summary type="html">Tools exist to create computational memetics through machine learning / NLP Transmission is a function of emotion / simplicity, not truth The only ideas you see are the ones that can propagate Memes are antifragile (grow stronger from attack, generally through increased exposure) Replicators</summary></entry><entry><title type="html">Canonical Success</title><link href="http://localhost:4000/thinking/2019/02/08/canonical-success.html" rel="alternate" type="text/html" title="Canonical Success" /><published>2019-02-08T17:25:46-08:00</published><updated>2019-02-08T17:25:46-08:00</updated><id>http://localhost:4000/thinking/2019/02/08/canonical-success</id><content type="html" xml:base="http://localhost:4000/thinking/2019/02/08/canonical-success.html">&lt;p&gt;The mission is to assemble the traits that act as a strong filter for success, or that are strongly predictive of a canonical understanding of success. Success means different things to different people, ‘canonical success’ here points to the common understanding between people (accomplishment, status, performance, wealth) .&lt;/p&gt;

&lt;p&gt;Importance ordering:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Conviction / Self-Belief / Confidence&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Conscientiousness / Work Ethic / Discipline&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sphere of Control / Responsibility&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Persistence / Determination&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Fearlessness&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Focus&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Vision&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Obsession&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Independence&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Antifragility&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Expectations&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Influence&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Interactions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Conviction / Self-Belief / Confidence gives you:&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sphere of Control / Responsibility (Agency narrative)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Independence (You don’t need others validation to believe)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Vision (What you think a worthy outcome needs no validation)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Obsession gives you:&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Work Ethic / Discipline&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Vision needs to have:&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;High Expectations of Outcome&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;How to fit in? / Borderline traits&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Growth orientation?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Creativity?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Intelligence? (there’s a necessary threshold, but too much is dangerous)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Belief in ability to be flexible / learn what’s necessary?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Action Bias?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Resourcefulness? (Independence + Creativity + Action Bias)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Self-awareness&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Self-critical (basic, not excessive)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Grounded Arrogance (Real success backing up ego) for self-efficacy&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Embraces Reality / Groundedness&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Agency (combination of independence / conviction / sphere of control?)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Concepts&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Know What You Want / Have a Vision&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Believe In Yourself&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Overcome Your Fear&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Be Persistent&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Focus&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Take Responsibility / Control&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Follow Your Own Way&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Failure or Problems as Opportunities for Growth&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Life is About Growth and Progress&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;You Have Potential / Greatness in You&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Work Hard / Create Habits&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ignore Those Who Sabotage You&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Set High Expectations / Shoot High&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Care about Results, Not Excuses or Reasons.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Do Whatever it Takes&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Be Obsessed&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Narrative Frame&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Victim Narrative or Agency Narrative?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Corresponds to Sphere of Control / Responsibility&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Chosen One Narrative or not?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Corresponds to Independence&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Corresponds to Conviction / Self Belief&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Corresponds to Expectations&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Corresponds to Sphere of Control / Responsibility&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Construction of this framework&lt;/p&gt;

&lt;p&gt;Intersection of:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://docs.google.com/document/d/1bBeCdCIRx7wmMNdS3t5M55DUKTZQ_fXsrklDTTyStCk/edit?usp=sharing&quot;&gt;Relentless&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://docs.google.com/document/d/1hUQDqax5rWHIWp4_y30KDKzxZOETnaUTNr0FtDH3C5U/edit?usp=sharing&quot;&gt;Motivation Idea Space&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://docs.google.com/document/d/1l0vZ-tqtAZtcKC70QiujwPNVEysBqDBVOmjBkaax6Ow/edit?usp=sharing&quot;&gt;Ashlee Vance Bio&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=7TEc_qyKQ0c&quot;&gt;Schwarzenegger Talk&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Jeremy’s Real Life Experience&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">The mission is to assemble the traits that act as a strong filter for success, or that are strongly predictive of a canonical understanding of success. Success means different things to different people, ‘canonical success’ here points to the common understanding between people (accomplishment, status, performance, wealth) .</summary></entry><entry><title type="html">Naive Rationality</title><link href="http://localhost:4000/thinking/2018/12/24/naive-rationality.html" rel="alternate" type="text/html" title="Naive Rationality" /><published>2018-12-24T04:02:46-08:00</published><updated>2018-12-24T04:02:46-08:00</updated><id>http://localhost:4000/thinking/2018/12/24/naive-rationality</id><content type="html" xml:base="http://localhost:4000/thinking/2018/12/24/naive-rationality.html">&lt;p&gt;Naive Rationality has classic failure modes.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Failing to take into account 2nd and 3rd effects
  This often happens when those 2nd and 3rd effects are unknown to rationality but known to intuition&lt;/li&gt;
  &lt;li&gt;Long Term Thinking
  Naive rationality leads to undervaluing poorly understood activity, (ex. Play / exploration) for maximizing expected value greedily in each moment&lt;/li&gt;
  &lt;li&gt;Lack of Complex Consequentialism
  ‘Consistency’ demands that we choose either Deontology or Consequentialism, or some other framework for evaluating actions. But these systems all have value in particular contexts, and so should subsume one another. For example, effective rules often have to be clear (discrete) for psychological reasons, which leads to Deontology. The consequentialist should realize when that optimizes the outcome.&lt;/li&gt;
  &lt;li&gt;Disrespect for Intuition / Cultural Knowledge
  What people mean when they say ‘wisdom’ is knowledge whose source is unknown, unknowable or forgotten. Passed from generations of Elders. Intuited through a distributed, parallel process in a mind that can’t be understood linearly.&lt;/li&gt;
  &lt;li&gt;Rational People Defect and Free Ride
  There are many game-theoretic situations where cooperation is only enforced by social norms. In that context, a person relying on rationality instead of social imitation will defect (assuming that the long term ramifications for reputation, etc. are low)&lt;/li&gt;
  &lt;li&gt;Assuming Normal Distributions in Extremistan&lt;/li&gt;
  &lt;li&gt;What you see is all there is (relevant to Chesterton’s fence)&lt;/li&gt;
  &lt;li&gt;Believing that you’re rational leads to being overconfident in your understanding of the situation&lt;/li&gt;
  &lt;li&gt;Ignore the emotional side of thought / experience
  Damning when emotions are the generators of action, rationalized&lt;/li&gt;
  &lt;li&gt;Appearances don’t matter, Environment doesn’t matter
  This sense of invulnerability to emotional / cultural impact due to a belief in one’s own rationality&lt;/li&gt;
  &lt;li&gt;Chesterton’s Fence
  The absence of understanding something is conflated with the misunderstood object being useless. An important instance of the overconfidence that comes out of naive rationality. 
  Two reformers find a fence in their way. The first doesn’t see the fence’s purpose, so he goes to knock it down. The second says that until the first reformer can see the purpose of the fence, he won’t allow him to knock it down.&lt;/li&gt;
  &lt;li&gt;Goodhart’s Law
  Naive Rationality overfits to metrics that are available to a quantitative, empirical mind. But there’s much that science can’t touch and that is difficult to measure, and so when rationality is combined with something intuitive (say, ‘goodness’) it leads to EA / Singerism. In that case, lives saved is measurable.&lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><summary type="html">Naive Rationality has classic failure modes.</summary></entry><entry><title type="html">How to Learn</title><link href="http://localhost:4000/thinking/2018/12/22/how-to-learn.html" rel="alternate" type="text/html" title="How to Learn" /><published>2018-12-22T04:02:46-08:00</published><updated>2018-12-22T04:02:46-08:00</updated><id>http://localhost:4000/thinking/2018/12/22/how-to-learn</id><content type="html" xml:base="http://localhost:4000/thinking/2018/12/22/how-to-learn.html">&lt;p&gt;There are two major categories of relevant information.&lt;/p&gt;

&lt;p&gt;One is models - a set of relationships between variables, a sense for how the system works.
The other is objects - particular techniques or behaviors that interact with models to produce learning.&lt;/p&gt;

&lt;p&gt;For example, Focused and Diffuse thinking are models. Spaced repetition is an object/technique. Reinforcement (reward / punish) learned behavior is a model. Creating a reward is a technique.&lt;/p&gt;

&lt;p&gt;I’m going to start this by just listing out important models and techniques, as well as unimportant models and techniques (if there’s content I think isn’t worth focusing on - a continuous list with weights on importance would be perfect, but I’ll settle for a two-tiered system for now).&lt;/p&gt;

&lt;p&gt;Major Models:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Levels of abstraction - high level / low level representation of information (context vs content, bottom up learning vs. top down learning, Holistic vs. Sequential reasoning)&lt;/li&gt;
  &lt;li&gt;Long-term memory and working memory systems&lt;/li&gt;
  &lt;li&gt;Working memory limited in scope&lt;/li&gt;
  &lt;li&gt;Long term memory requires revisits to get content established&lt;/li&gt;
  &lt;li&gt;Habits as the source of most behavior&lt;/li&gt;
  &lt;li&gt;Cue + routine + reward + belief&lt;/li&gt;
  &lt;li&gt;Learning by doing as more effective than learning in abstract - 8/ learning as active or passive&lt;/li&gt;
  &lt;li&gt;Able to Recreate vs. Recall ability vs. Illusion of Competence&lt;/li&gt;
  &lt;li&gt;Outcome oriented vs. Process oriented&lt;/li&gt;
  &lt;li&gt;System 1 / System 2&lt;/li&gt;
  &lt;li&gt;Focused vs. Default Mode Thinking&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Major Techniques:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Spaced Repetition&lt;/li&gt;
  &lt;li&gt;Memorable items must be repeated over several days&lt;/li&gt;
  &lt;li&gt;Alternate the level of abstraction you process information at, from high level context to low level details and back&lt;/li&gt;
  &lt;li&gt;Material as important as method. Ensure that the content being processed is sufficiently incremental and has the best 80/20 cut of the important information.&lt;/li&gt;
  &lt;li&gt;Modify environment&lt;/li&gt;
  &lt;li&gt;Eliminate distractions in the environment&lt;/li&gt;
  &lt;li&gt;After reading material, look away from the material and recall it. Repeat for great effect.&lt;/li&gt;
  &lt;li&gt;Deliberate Practice&lt;/li&gt;
  &lt;li&gt;Focus on the parts of content that are difficult&lt;/li&gt;
  &lt;li&gt;Increase intensity of practice / focus&lt;/li&gt;
  &lt;li&gt;Structure behavior, at least on a weekly and daily basis&lt;/li&gt;
  &lt;li&gt;Tutoring&lt;/li&gt;
  &lt;li&gt;Get into a space with experts in what you’re looking to learn&lt;/li&gt;
  &lt;li&gt;Pomodoro - small step towards goal, process oriented&lt;/li&gt;
  &lt;li&gt;Set timer to 25 minutes, cut interruptions, focus hard for 25m, give reward&lt;/li&gt;
  &lt;li&gt;Create abstractions / chunks by combining sets of ideas or concepts for working memory&lt;/li&gt;
  &lt;li&gt;Test yourself regularly on content you’re looking to learn&lt;/li&gt;
  &lt;li&gt;Metaphor / Analogy, Transferring mental models between fields&lt;/li&gt;
  &lt;li&gt;Teach someone else the content, forcing you to frame information from different perspective&lt;/li&gt;
  &lt;li&gt;If procrastination, focus on process instead of outcome&lt;/li&gt;
  &lt;li&gt;Get into a social environment that reinforces the right beliefs and values&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Minor Models:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Understanding each step in a process vs. understanding the connection between steps&lt;/li&gt;
  &lt;li&gt;Learning occurs during Sleep&lt;/li&gt;
  &lt;li&gt;When you think of something you’d rather not do, your brain experiences pain that subsides once you actually start working on it. 4. This leads to procrastination.&lt;/li&gt;
  &lt;li&gt;Practice makes permanent&lt;/li&gt;
  &lt;li&gt;While mind is relaxing in the background, progress is made on problems&lt;/li&gt;
  &lt;li&gt;Attention Switching Costs / Impact of multitasking&lt;/li&gt;
  &lt;li&gt;Hyperbolic Discounting, default focus on short term&lt;/li&gt;
  &lt;li&gt;Memory has a visual / auditory component&lt;/li&gt;
  &lt;li&gt;Memories are not fixed, but reconsolidated every time they’re recalled&lt;/li&gt;
  &lt;li&gt;Memory techniques as skills in themselves requiring practice&lt;/li&gt;
  &lt;li&gt;Energy level / Energy management&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Minor Techniques:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Let yourself fall into the diffuse mode while thinking about a problem (falling asleep, for example). Then wake up with an alarm or falling object and apply focused to the diffuse content.&lt;/li&gt;
  &lt;li&gt;Alternate the way you process information, going from focused thinking to diffuse and back to focused&lt;/li&gt;
  &lt;li&gt;Establish the smallest step towards working on a problem (pomodoro in general)&lt;/li&gt;
  &lt;li&gt;Intentionally look to dream about what you’re studying&lt;/li&gt;
  &lt;li&gt;Exercise regularly&lt;/li&gt;
  &lt;li&gt;Concept Mapping&lt;/li&gt;
  &lt;li&gt;Learn in different environments to avoid overfitting learning to environment&lt;/li&gt;
  &lt;li&gt;Promise a reward after a work session&lt;/li&gt;
  &lt;li&gt;Create a library of chunks / latticework of mental models&lt;/li&gt;
  &lt;li&gt;Overlearning (Putting in a ton of work in batch)&lt;/li&gt;
  &lt;li&gt;Interleaving content together to increase flexibility of understanding&lt;/li&gt;
  &lt;li&gt;Analyze the cue of damaging habits and avoid / change them.&lt;/li&gt;
  &lt;li&gt;Have a trigger-action plan when you catch yourself in the routine of a habit&lt;/li&gt;
  &lt;li&gt;Create an emotional reward for new habitual behavior&lt;/li&gt;
  &lt;li&gt;Plan quitting time on daily goals.&lt;/li&gt;
  &lt;li&gt;Strongly isolate work from leisure&lt;/li&gt;
  &lt;li&gt;Work on hard / disliked tasks as soon as you wake up, when you have willpower&lt;/li&gt;
  &lt;li&gt;Mnemonics / Neumonics&lt;/li&gt;
  &lt;li&gt;Memory Palace Technique (Link visual / spatial thinking with concepts)&lt;/li&gt;
  &lt;li&gt;Metaphor / analogize the concepts being learned&lt;/li&gt;
  &lt;li&gt;Meditation / Deep Breathing&lt;/li&gt;
  &lt;li&gt;Thoroughly understand the basics of content, the building blocks&lt;/li&gt;
  &lt;li&gt;Breaks to avoid drop in attention span over time&lt;/li&gt;
  &lt;li&gt;Visualization&lt;/li&gt;
  &lt;li&gt;Focus Tracking&lt;/li&gt;
  &lt;li&gt;Urge Propagation&lt;/li&gt;
  &lt;li&gt;80/20 / Triage&lt;/li&gt;
  &lt;li&gt;Growth Mindset&lt;/li&gt;
  &lt;li&gt;Nutrition&lt;/li&gt;
  &lt;li&gt;Define study schedule&lt;/li&gt;
  &lt;li&gt;Goal Factor learning&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Carl Shan’s Notes on Tim Ferriss’ Metalearning Podcast
These notes describe a process for learning at a fairly high level. 
The DISSS framework (Deconstruction, Selection, Sequencing, Stakes)
The CaFE framework (Compression (80/20), Frequency, Encoding)&lt;/p&gt;

&lt;p&gt;Samford Video Series:
https://www.samford.edu/departments/academic-success-center/how-to-study&lt;/p&gt;</content><author><name></name></author><summary type="html">There are two major categories of relevant information.</summary></entry><entry><title type="html">Idea Lists</title><link href="http://localhost:4000/creativity/2018/06/18/idea-lists.html" rel="alternate" type="text/html" title="Idea Lists" /><published>2018-06-18T05:02:46-07:00</published><updated>2018-06-18T05:02:46-07:00</updated><id>http://localhost:4000/creativity/2018/06/18/idea-lists</id><content type="html" xml:base="http://localhost:4000/creativity/2018/06/18/idea-lists.html">&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;Revel in the moment of creation.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Idea Listing:&lt;br /&gt;
-Choose a topic to generate 10 ideas over.
-10m Time Constraint. Start timer.&lt;br /&gt;
-Fill to 10 ideas. Let quality fall if time becomes a limiting factor.&lt;br /&gt;
-Optimize for both expected value of the idea and for its novelty
-Novelty - Novelty is great but not necessary. Feel free to dial this down as time goes on.
&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Mechanics:
The time constraint accomplishes a number of important things.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Creates the freedom to let all other thoughts, worries and mental activity be released temporarily. The time being explicitly set aside for one task is permission to let go of open loops, freeing those slots in working memory for the task.&lt;/li&gt;
  &lt;li&gt;Activates an action-oriented mode, a creation rather than consumption mode.&lt;/li&gt;
  &lt;li&gt;Is a step of momentum towards taking productive action&lt;/li&gt;
  &lt;li&gt;Creates freedom from other people - they either see it, or you feel comfortable letting them know that you’re busy (but only temporarily, making it feel acceptable).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Examples:&lt;br /&gt;
Demonstrate list of idea lists&lt;br /&gt;
For Research: &lt;a href=&quot;https://docs.google.com/document/d/1zK8KwdWM5DtxFdD_NOHmAhUclLzh_ohkbRWR_CRmp8E/edit?usp=sharing&quot;&gt;Types of Temporal Structure&lt;/a&gt;&lt;br /&gt;
For Conversation: &lt;a href=&quot;https://docs.google.com/document/d/1H9o89AP_9oqzVuYPzUWo4zNB-xVxRf05EL6GOA8AamA/edit?usp=sharing&quot;&gt;Interesting Facts in Machine Learning (Linear Regression)&lt;/a&gt;&lt;br /&gt;
For an Idea: &lt;a href=&quot;https://docs.google.com/document/d/1kT5WG2DfAIZKntcEw3-OHvEDulG_lyPNDfsOSMxPsw8/edit?usp=sharing&quot;&gt;Memetics&lt;/a&gt;&lt;br /&gt;
For Emotion: &lt;a href=&quot;https://docs.google.com/document/d/13sV_25TjB5376ErdwAIfJ7imHdGH6J7IQ-niqTdjkjk/edit?usp=sharing&quot;&gt;Ways to Induce Anger&lt;/a&gt;&lt;br /&gt;
For ML: &lt;a href=&quot;https://docs.google.com/document/d/1cpiNNO9WOGyzQ1M_tK-cZv4dH35EBV-CU_ZTv58zxls/edit?usp=sharing&quot;&gt;Machine Intelligence Contrarian&lt;/a&gt;&lt;br /&gt;
For Creativity: &lt;a href=&quot;https://docs.google.com/document/d/1Dw6FZ_Kx2SRXO8O4aygmH0XxItZrLNjMAabozZ0xhXo/edit?usp=sharing&quot;&gt;17-04-08 Systematizing Creativity&lt;/a&gt;&lt;br /&gt;
For Learning: &lt;a href=&quot;https://docs.google.com/document/d/1JRhjtXJyhO9tXfjcEVRFE7ZMGD2UFHqPb8VRsPXAyFs/edit?usp=sharing&quot;&gt;Ideas for Learning ML/AI (2015)&lt;/a&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Part of a series on &lt;a href=&quot;https://jeremynixon.github.io/creativity/2018/06/09/systematizing-creativity-models-and-techniques.html&quot;&gt;Systematizing Creativity&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/JeremyNixon/JeremyNixon.github.io/blob/master/_site/assets/images/Creative-Hand.jpg&quot;&gt;&lt;img src=&quot;https://github.com/JeremyNixon/JeremyNixon.github.io/raw/master/_site/assets/images/Creative-Hand.jpg&quot; alt=&quot;Moment of Creation&quot; style=&quot;max-width:100%;&quot; /&gt;&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Revel in the moment of creation.</summary></entry></feed>