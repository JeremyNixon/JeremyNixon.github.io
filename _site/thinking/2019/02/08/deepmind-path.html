<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.4.0 -->
<title>Deepmind’s Path to Neuro-inspired General Intelligence | Grounded Abstraction</title>
<meta name="generator" content="Jekyll v3.8.0" />
<meta property="og:title" content="Deepmind’s Path to Neuro-inspired General Intelligence" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="By Jeremy Nixon [jnixon2@gmail.com]. Nov. 2017. Updated June 2018." />
<meta property="og:description" content="By Jeremy Nixon [jnixon2@gmail.com]. Nov. 2017. Updated June 2018." />
<link rel="canonical" href="http://localhost:4000/thinking/2019/02/08/deepmind-path.html" />
<meta property="og:url" content="http://localhost:4000/thinking/2019/02/08/deepmind-path.html" />
<meta property="og:site_name" content="Grounded Abstraction" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-02-08T17:29:46-08:00" />
<script type="application/ld+json">
{"description":"By Jeremy Nixon [jnixon2@gmail.com]. Nov. 2017. Updated June 2018.","@type":"BlogPosting","url":"http://localhost:4000/thinking/2019/02/08/deepmind-path.html","headline":"Deepmind’s Path to Neuro-inspired General Intelligence","dateModified":"2019-02-08T17:29:46-08:00","datePublished":"2019-02-08T17:29:46-08:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/thinking/2019/02/08/deepmind-path.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Grounded Abstraction" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Grounded Abstraction</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">Identity.</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Deepmind&#39;s Path to Neuro-inspired General Intelligence</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2019-02-08T17:29:46-08:00" itemprop="datePublished">Feb 8, 2019
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>By Jeremy Nixon [<a href="mailto:jnixon2@gmail.com">jnixon2@gmail.com</a>]. Nov. 2017. Updated June 2018.</p>

<p>Overview</p>

<ol>
  <li>
    <p>Deepmind Paper Framing</p>
  </li>
  <li>
    <p>Deepmind Papers through Framing</p>
  </li>
  <li>
    <p>Current Frontier</p>
  </li>
  <li>
    <p>Examples of Systems Neuroscience Inspiration</p>
  </li>
</ol>

<p>Deepmind Papers</p>

<p>Categories of the path to date:</p>

<ol>
  <li>
    <p>Transfer Learning</p>
  </li>
  <li>
    <p>Multi-task Learning</p>
  </li>
  <li>
    <p>Tools, Environment &amp; Datasets</p>
  </li>
  <li>
    <p>Intuitive Physics</p>
  </li>
  <li>
    <p>Reinforcement Learning</p>

    <ol>
      <li>
        <p>Model-based RL</p>
      </li>
      <li>
        <p>Exploration in RL</p>
      </li>
    </ol>
  </li>
  <li>
    <p>Applications</p>
  </li>
  <li>
    <p>Safety</p>
  </li>
  <li>
    <p>Deep Learning</p>
  </li>
  <li>
    <p>RNNs</p>
  </li>
  <li>
    <p>CNNs</p>
  </li>
  <li>
    <p>Generative Models</p>
  </li>
  <li>
    <p>Variational Inference</p>
  </li>
  <li>
    <p>Unsupervised Learning</p>
  </li>
  <li>
    <p>Representation Learning</p>
  </li>
  <li>
    <p>Attention</p>
  </li>
  <li>
    <p>Memory</p>
  </li>
  <li>
    <p>Multi-Agent Systems</p>
  </li>
  <li>
    <p>Imitation Learning</p>
  </li>
  <li>
    <p>Metalearning</p>
  </li>
  <li>
    <p>Neural Programming</p>
  </li>
  <li>
    <p>Evolution</p>
  </li>
  <li>
    <p>Game Theory</p>
  </li>
  <li>
    <p>Natural Language Processing</p>
  </li>
  <li>
    <p>Multi-Modal Learning</p>
  </li>
  <li>
    <p>General Machine Learning</p>
  </li>
  <li>
    <p>Theory</p>
  </li>
  <li>
    <p>Miscellaneous</p>
  </li>
  <li>
    <p>Neuroscience</p>
  </li>
</ol>

<p>Papers:</p>

<ol>
  <li>
    <p>Transfer Learning</p>
  </li>
  <li>
    <p>DARLA: Improving Zero-Shot Transfer In Reinforcement Learning</p>

    <ol>
      <li>
        <p><a href="https://arxiv.org/pdf/1707.08475.pdf">https://arxiv.org/pdf/1707.08475.pdf</a></p>
      </li>
      <li>
        <p>PathNet: Evolution Channels Gradient Descent in Super Neural Networks</p>
      </li>
      <li>
        <p><a href="https://arxiv.org/pdf/1701.08734.pdf">https://arxiv.org/pdf/1701.08734.pdf</a></p>
      </li>
      <li>
        <p>Matching Networks for One Shot Learning</p>
      </li>
      <li>
        <p><a href="https://arxiv.org/abs/1606.04080">https://arxiv.org/abs/1606.04080</a></p>
      </li>
      <li>
        <p>Progressive Neural Networks</p>
      </li>
      <li>
        <p><a href="https://arxiv.org/pdf/1606.04671.pdf">https://arxiv.org/pdf/1606.04671.pdf</a></p>
      </li>
      <li>
        <p>Sim-to-Real Robot Learning from Pixels with Progressive Nets</p>
      </li>
      <li>
        <p><a href="https://arxiv.org/pdf/1610.04286.pdf">https://arxiv.org/pdf/1610.04286.pdf</a></p>
      </li>
      <li>
        <p>Successor Features for Transfer in Reinforcement Learning</p>
      </li>
      <li>
        <p><a href="https://arxiv.org/pdf/1606.05312.pdf">https://arxiv.org/pdf/1606.05312.pdf</a></p>
      </li>
    </ol>
  </li>
  <li>
    <p>Multi-Task Learning</p>

    <ol>
      <li>
        <p>Multi-task Self-Supervised Visual Learning</p>
      </li>
      <li>
        <p><a href="https://arxiv.org/pdf/1708.07860.pdf">https://arxiv.org/pdf/1708.07860.pdf</a></p>
      </li>
      <li>
        <p>The Intentional Unintentional Agent: Learning to Solve Many Continuous Control Tasks Simultaneously</p>
      </li>
      <li>
        <p><a href="https://arxiv.org/pdf/1707.03300.pdf">https://arxiv.org/pdf/1707.03300.pdf</a></p>
      </li>
      <li>
        <p>Distral: Robust Multitask Reinforcement Learning</p>
      </li>
      <li>
        <p><a href="https://arxiv.org/pdf/1707.04175.pdf">https://arxiv.org/pdf/1707.04175.pdf</a></p>
      </li>
      <li>
        <p>Emergence of Locomotion Behaviors in Rich Environments</p>
      </li>
      <li>
        <p><a href="https://arxiv.org/pdf/1707.02286.pdf">https://arxiv.org/pdf/1707.02286.pdf</a></p>
      </li>
      <li>
        <p>Reinforcement Learning with Unsupervised Auxiliary Tasks</p>
      </li>
      <li>
        <p><a href="https://arxiv.org/pdf/1611.05397.pdf">https://arxiv.org/pdf/1611.05397.pdf</a></p>
      </li>
      <li>
        <p>Learning to Navigate in Complex Environments</p>
      </li>
      <li>
        <p><a href="https://arxiv.org/pdf/1611.03673.pdf">https://arxiv.org/pdf/1611.03673.pdf</a></p>
      </li>
      <li>
        <p>Learning and Transfer of Modulated Locomotor Controllers</p>
      </li>
      <li>
        <p><a href="https://arxiv.org/pdf/1610.05182.pdf">https://arxiv.org/pdf/1610.05182.pdf</a></p>
      </li>
      <li>
        <p>Multi-Task Sequence to Sequence Learning</p>
      </li>
      <li>
        <p><a href="https://arxiv.org/pdf/1511.06114v3.pdf">https://arxiv.org/pdf/1511.06114v3.pdf</a></p>
      </li>
      <li>
        <p>Learning by Playing - Solving Sparse Reward Tasks from Scratch</p>
      </li>
      <li>
        <p><a href="https://arxiv.org/abs/1802.10567">https://arxiv.org/abs/1802.10567</a></p>
      </li>
      <li>
        <p>Unicorn: Continual Learning with a Universal, Off-policy Agent</p>
      </li>
      <li>
        <p><a href="https://arxiv.org/abs/1802.08294">https://arxiv.org/abs/1802.08294</a></p>
      </li>
      <li>
        <p>Progress &amp; Compress: A Scalable Framework for Continual Learning</p>
      </li>
      <li>
        <p>https://arxiv.org/abs/1805.06370</p>
      </li>
    </ol>
  </li>
  <li>
    <p>Tools, Environments, Evaluation &amp; Datasets</p>

    <ol>
      <li>
        <p>Starcraft II: A New Challenge for Reinforcement Learning</p>
      </li>
      <li>
        <p><a href="https://arxiv.org/pdf/1708.04782.pdf">https://arxiv.org/pdf/1708.04782.pdf</a></p>
      </li>
      <li>
        <p>DeepMind Lab</p>
      </li>
      <li>
        <p><a href="https://arxiv.org/pdf/1612.03801.pdf">https://arxiv.org/pdf/1612.03801.pdf</a></p>
      </li>
      <li>
        <p>The Kinetics Human Action Video Dataset</p>
      </li>
      <li>
        <p><a href="https://arxiv.org/pdf/1705.06950.pdf">https://arxiv.org/pdf/1705.06950.pdf</a></p>
      </li>
      <li>
        <p>An approximation of the Universal Intelligence Measure</p>
      </li>
      <li>
        <p><a href="https://arxiv.org/pdf/1109.5951v2.pdf">https://arxiv.org/pdf/1109.5951v2.pdf</a></p>
      </li>
      <li>
        <p>Psychlab: A Psychology Laboratory for Deep Reinforcement Learning</p>
      </li>
      <li>
        <p><a href="https://arxiv.org/abs/1801.08116">https://arxiv.org/abs/1801.08116</a></p>
      </li>
      <li>
        <p>Deepmind Control Suite</p>
      </li>
      <li>
        <p><a href="https://arxiv.org/pdf/1801.00690v1.pdf">https://arxiv.org/pdf/1801.00690v1.pdf</a></p>
      </li>
      <li>
        <p>Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset</p>
      </li>
      <li>
        <p><a href="https://arxiv.org/pdf/1705.07750.pdf">https://arxiv.org/pdf/1705.07750.pdf</a></p>
      </li>
    </ol>
  </li>
  <li>
    <p>Intuitive Physics</p>

    <ol>
      <li>
        <p>Position-Velocity Encoders for Unsupervised Learning of Structured State Representations</p>
      </li>
      <li>
        <p><a href="https://arxiv.org/pdf/1705.09805.pdf">https://arxiv.org/pdf/1705.09805.pdf</a></p>
      </li>
      <li>
        <p>Learning to Perform Physics Experiments via Deep Reinforcement Learning</p>
      </li>
      <li>
        <p><a href="https://arxiv.org/pdf/1611.01843.pdf">https://arxiv.org/pdf/1611.01843.pdf</a></p>
      </li>
      <li>
        <p>Continuous Control with Deep Reinforcement Learning</p>
      </li>
      <li>
        <p><a href="https://arxiv.org/pdf/1509.02971v2.pdf">https://arxiv.org/pdf/1509.02971v2.pdf</a></p>
      </li>
    </ol>
  </li>
  <li>
    <p>Reinforcement Learning (Papers with a pure RL focus)</p>
  </li>
  <li>
    <p>Model-Based RL</p>
  </li>
  <li>
    <p>Learning Model-Based Planning from Scratch [Also, Planning]</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1707.06170.pdf">https://arxiv.org/pdf/1707.06170.pdf</a></p>
  </li>
  <li>
    <p>Recurrent Environment Simulators</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1704.02254.pdf">https://arxiv.org/pdf/1704.02254.pdf</a></p>
  </li>
  <li>
    <p>Structure Learning in Motor Control: A Deep Reinforcement Learning Model [Also Transfer, Intuitive Physics]</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1706.06827.pdf">https://arxiv.org/pdf/1706.06827.pdf</a></p>
  </li>
  <li>
    <p>Imagination-Augmented Agents for Deep Reinforcement Learning [Also, Planning]</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1707.06203">https://arxiv.org/abs/1707.06203</a></p>
  </li>
  <li>
    <p>Continuous Deep Q-Learning with Model-based Acceleration</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1603.00748">https://arxiv.org/abs/1603.00748</a></p>
  </li>
  <li>
    <p>Skip Context Tree Switching</p>
  </li>
  <li>
    <p><a href="http://proceedings.mlr.press/v32/bellemare14.pdf">http://proceedings.mlr.press/v32/bellemare14.pdf</a></p>
  </li>
  <li>
    <p>Bayes-Adaptive Simulation-Based Search with Value Function Approximation</p>
  </li>
  <li>
    <p><a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Publications_files/bafa.pdf">http://www0.cs.ucl.ac.uk/staff/d.silver/web/Publications_files/bafa.pdf</a></p>
  </li>
  <li>
    <p>Learning and Querying Fast Generative Models for Reinforcement Learning</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1802.03006">https://arxiv.org/abs/1802.03006</a></p>
  </li>
  <li>
    <p>Exploration in RL</p>
  </li>
  <li>
    <p>Count-Based Exploration with Neural Density Models</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1703.01310.pdf">https://arxiv.org/pdf/1703.01310.pdf</a></p>
  </li>
  <li>
    <p>Unifying Count-Based Exploration and Intrinsic Motivation</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1606.01868">https://arxiv.org/abs/1606.01868</a></p>
  </li>
  <li>
    <p>Deep Exploration via Bootstrapped DQN</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1602.04621">https://arxiv.org/abs/1602.04621</a></p>
  </li>
  <li>
    <p>Variational Intrinsic Control</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1611.07507.pdf">https://arxiv.org/pdf/1611.07507.pdf</a></p>
  </li>
  <li>
    <p>Learning to Search with MCTSnets</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1802.04697v1">https://arxiv.org/abs/1802.04697v1</a></p>
  </li>
  <li>
    <p>Observe and Look Further: Achieving Consistent Performance on Atari</p>
  </li>
  <li>
    <p>https://arxiv.org/abs/1805.11593</p>
  </li>
  <li>
    <p>A Distributional Perspective on Reinforcement Learning</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1707.06887.pdf">https://arxiv.org/pdf/1707.06887.pdf</a></p>
  </li>
  <li>
    <p>FeUdal Networks for Hierarchical Reinforcement Learning [Also, Planning]</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1703.01161.pdf">https://arxiv.org/pdf/1703.01161.pdf</a></p>
  </li>
  <li>
    <p>Combining Policy Gradient and Q-Learning</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1611.01626.pdf">https://arxiv.org/pdf/1611.01626.pdf</a></p>
  </li>
  <li>
    <p>Strategic Attentive Writer for Learning Macro-Actions</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1606.04695.pdf">https://arxiv.org/pdf/1606.04695.pdf</a></p>
  </li>
  <li>
    <p>Safe and Efficient Off-Policy Reinforcement Learning</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1606.02647">https://arxiv.org/abs/1606.02647</a></p>
  </li>
  <li>
    <p>Deep Reinforcement Learning for Robotic Manipulation with Asynchronous Off-Policy Updates</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1610.00633.pdf">https://arxiv.org/pdf/1610.00633.pdf</a></p>
  </li>
  <li>
    <p>Thompson Sampling is Asymptotically Optimal in General Environments</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1602.07905.pdf">https://arxiv.org/pdf/1602.07905.pdf</a></p>
  </li>
  <li>
    <p>Asynchronous Methods for Deep Reinforcement Learning</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1602.01783">https://arxiv.org/abs/1602.01783</a></p>
  </li>
  <li>
    <p>Dueling Network Architectures for Deep Reinforcement Learning</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1511.06581">https://arxiv.org/abs/1511.06581</a></p>
  </li>
  <li>
    <p>Increasing the Action Gap: New Operators for Reinforcement Learning</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1512.04860">https://arxiv.org/abs/1512.04860</a></p>
  </li>
  <li>
    <p>Deep Reinforcement Learning with Double Q-Learning</p>
  </li>
  <li>
    <p>https://arxiv.org/abs/1509.06461</p>
  </li>
  <li>
    <p>Policy Distillation</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1511.06295.pdf">https://arxiv.org/pdf/1511.06295.pdf</a></p>
  </li>
  <li>
    <p>Universal Value Function Approximators</p>
  </li>
  <li>
    <p><a href="http://proceedings.mlr.press/v37/schaul15.pdf">http://proceedings.mlr.press/v37/schaul15.pdf</a></p>
  </li>
  <li>
    <p>Human-level Control through Deep Reinforcement Learning</p>
  </li>
  <li>
    <p><a href="https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf">https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf</a></p>
  </li>
  <li>
    <p>Learning Continuous Control Policies by Stochastic Value Gradients</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1510.09142v1.pdf">https://arxiv.org/pdf/1510.09142v1.pdf</a></p>
  </li>
  <li>
    <p>Fictitious Self-Play in Extensive Form Games</p>
  </li>
  <li>
    <p><a href="http://proceedings.mlr.press/v37/heinrich15.pdf">http://proceedings.mlr.press/v37/heinrich15.pdf</a></p>
  </li>
  <li>
    <p>Toward Minimax Off-policy Value Estimation</p>
  </li>
  <li>
    <p><a href="http://proceedings.mlr.press/v38/li15b.html">http://proceedings.mlr.press/v38/li15b.html</a></p>
  </li>
  <li>
    <p>Massively Parallel Methods for Deep Reinforcement Learning</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1507.04296.pdf">https://arxiv.org/pdf/1507.04296.pdf</a></p>
  </li>
  <li>
    <p>Compress and Control</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1411.5326v1.pdf">https://arxiv.org/pdf/1411.5326v1.pdf</a></p>
  </li>
  <li>
    <p>Deterministic Policy Gradient Algorithms</p>
  </li>
  <li>
    <p><a href="http://proceedings.mlr.press/v32/silver14.pdf">http://proceedings.mlr.press/v32/silver14.pdf</a></p>
  </li>
  <li>
    <p>Playing Atari with Deep Reinforcement Learning</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1312.5602v1.pdf">https://arxiv.org/pdf/1312.5602v1.pdf</a></p>
  </li>
  <li>
    <p>Reinforcement Learning, Efficient Coding, and the Statistics of Natural Tasks</p>
  </li>
  <li>
    <p><a href="http://www.sciencedirect.com/science/article/pii/S2352154615001151">http://www.sciencedirect.com/science/article/pii/S2352154615001151</a></p>
  </li>
  <li>
    <p>Rainbow: Combining Improvements in Deep Reinforcement Learning</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1710.02298">https://arxiv.org/abs/1710.02298</a></p>
  </li>
  <li>
    <p>Path Consistency Learning in Tsallis Entropy Regularized MDPs</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1802.03501">https://arxiv.org/abs/1802.03501</a></p>
  </li>
  <li>
    <p>More Robust Doubly Robust Off-Policy Evaluation</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1802.03493">https://arxiv.org/abs/1802.03493</a></p>
  </li>
  <li>
    <p>IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1802.01561">https://arxiv.org/abs/1802.01561</a></p>
  </li>
  <li>
    <p>Mis&amp;Match - Agent Curricula for Reinforcement Learning</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1806.01780">https://arxiv.org/abs/1806.01780</a></p>
  </li>
  <li>
    <p>Vector-based Navigation Using Grid-Like Representations in Artificial Agents</p>
  </li>
  <li>
    <p><a href="https://www.nature.com/articles/s41586-018-0102-6.epdf">https://www.nature.com/articles/s41586-018-0102-6.epdf</a>?</p>
  </li>
  <li>
    <p>Kickstarting Deep Reinforcement Learning</p>
  </li>
  <li>
    <p>https://arxiv.org/abs/1803.03835</p>
  </li>
  <li>
    <p>Applications</p>
  </li>
  <li>
    <p>Go</p>
  </li>
  <li>
    <p>Mastering the Game of Go with Deep Neural Networks and Tree Search</p>
  </li>
  <li>
    <p><a href="https://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf">https://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf</a></p>
  </li>
  <li>
    <p>More Evaluation in Go using Deep Convolutional Neural Networks [Also, Convolutional Neural Networks]</p>
  </li>
  <li>
    <p><a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Publications_files/deepgo.pdf">http://www0.cs.ucl.ac.uk/staff/d.silver/web/Publications_files/deepgo.pdf</a></p>
  </li>
  <li>
    <p>Mastering the Game of Go Without Human Knowledge</p>
  </li>
  <li>
    <p><a href="https://www.nature.com/articles/nature24270.epdf">https://www.nature.com/articles/nature24270.epdf</a>?</p>
  </li>
  <li>
    <p>Poker</p>
  </li>
  <li>
    <p>Smooth UCT Search in Computer Poker</p>
  </li>
  <li>
    <p><a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Publications_files/smooth_uct.pdf">http://www0.cs.ucl.ac.uk/staff/d.silver/web/Publications_files/smooth_uct.pdf</a></p>
  </li>
  <li>
    <p>Fairness</p>
  </li>
  <li>
    <p>Path-Specific Counterfactual Fairness</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1802.08139.pdf">https://arxiv.org/pdf/1802.08139.pdf</a></p>
  </li>
  <li>
    <p>Safety / Security</p>
  </li>
  <li>
    <p>Reinforcement Learning with a Corrupted Reward Channel [Also, Safety]</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1705.08417.pdf">https://arxiv.org/pdf/1705.08417.pdf</a></p>
  </li>
  <li>
    <p>Safely Interruptible Agents [Also, Safety]</p>
  </li>
  <li>
    <p><a href="https://intelligence.org/files/Interruptibility.pdf">https://intelligence.org/files/Interruptibility.pdf</a></p>
  </li>
  <li>
    <p>AI Safety Gridworlds</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1711.09883">https://arxiv.org/abs/1711.09883</a></p>
  </li>
  <li>
    <p>Adversarial Risk and the Dangers of Evaluating Against Weak Attacks</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1802.05666">https://arxiv.org/abs/1802.05666</a></p>
  </li>
  <li>
    <p>Safe Exploration in Continuous Action Spaces</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1801.08757">https://arxiv.org/abs/1801.08757</a></p>
  </li>
  <li>
    <p>Measuring and Avoiding Side Effects Using Relative Reachability</p>
  </li>
  <li>
    <p>https://arxiv.org/abs/1806.01186</p>
  </li>
  <li>
    <p>Deep Learning</p>
  </li>
  <li>
    <p>Recurrent Neural Networks</p>
  </li>
  <li>
    <p>Sequential Neural Models with Stochastic Layers [Also, Planning]</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1605.07571">https://arxiv.org/abs/1605.07571</a></p>
  </li>
  <li>
    <p>Memory-Efficient Backpropagation Through Time</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1606.03401">https://arxiv.org/abs/1606.03401</a></p>
  </li>
  <li>
    <p>Adaptive Computation Time for Recurrent Neural Networks</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1603.08983">https://arxiv.org/abs/1603.08983</a></p>
  </li>
  <li>
    <p>Grid Long-Short Term Memory</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1507.01526v3.pdf">https://arxiv.org/pdf/1507.01526v3.pdf</a></p>
  </li>
  <li>
    <p>Order Matters: Sequence to Sequence for Sets</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1511.06391v3.pdf">https://arxiv.org/pdf/1511.06391v3.pdf</a></p>
  </li>
  <li>
    <p>Convolutional Neural Networks</p>
  </li>
  <li>
    <p>Exploiting Cyclic Symmetry in Convolutional Neural Networks</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1602.02660">https://arxiv.org/abs/1602.02660</a></p>
  </li>
  <li>
    <p>Spatial Transformer Networks</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1506.02025.pdf">https://arxiv.org/pdf/1506.02025.pdf</a></p>
  </li>
  <li>
    <p>Very Deep Convolutional Networks for Large Scale Image Recognition</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1409h.1556v6.pdf">https://arxiv.org/pdf/1409h.1556v6.pdf</a></p>
  </li>
  <li>
    <p>Pooling is Neither Necessary Nor Sufficient for Appropriate Deformation Stability in CNNs</p>
  </li>
  <li>
    <p>https://arxiv.org/abs/1804.04438</p>
  </li>
  <li>
    <p>Noisy Networks for Exploration</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1706.10295.pdf">https://arxiv.org/pdf/1706.10295.pdf</a></p>
  </li>
  <li>
    <p>Sobolev Training for Neural Networks</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1706.04859">https://arxiv.org/abs/1706.04859</a></p>
  </li>
  <li>
    <p>Decoupled Neural Interfaces using Synthetic Gradients</p>
  </li>
  <li>
    <p>https://arxiv.org/pdf/1608.05343.pdf</p>
  </li>
  <li>
    <p>Understanding Synthetic Gradients and Decoupled Neural Interfaces</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1703.00522.pdf">https://arxiv.org/pdf/1703.00522.pdf</a></p>
  </li>
  <li>
    <p>Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1612.01474.pdf">https://arxiv.org/pdf/1612.01474.pdf</a></p>
  </li>
  <li>
    <p>Overcoming Catastrophic Forgetting in Neural Networks</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1612.00796.pdf">https://arxiv.org/pdf/1612.00796.pdf</a></p>
  </li>
  <li>
    <p>Local Minima in Training of Neural Networks</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1611.06310.pdf">https://arxiv.org/pdf/1611.06310.pdf</a></p>
  </li>
  <li>
    <p>Learning Values Across Many Orders of Magnitude</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1602.07714">https://arxiv.org/abs/1602.07714</a></p>
  </li>
  <li>
    <p>MuProp: Unbiased Backpropagation for Stochastic Neural Networks</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1511.05176v2.pdf">https://arxiv.org/pdf/1511.05176v2.pdf</a></p>
  </li>
  <li>
    <p>ACDC: A Structured Efficient Linear Layer</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1511.05946v3.pdf">https://arxiv.org/pdf/1511.05946v3.pdf</a></p>
  </li>
  <li>
    <p>Natural Neural Networks</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1507.00210.pdf">https://arxiv.org/pdf/1507.00210.pdf</a></p>
  </li>
  <li>
    <p>Gradient Estimation Using Stochastic Computation Graphs</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1506.05254v1.pdf">https://arxiv.org/pdf/1506.05254v1.pdf</a></p>
  </li>
  <li>
    <p>Weight Uncertainty in Neural Networks</p>
  </li>
  <li>
    <p><a href="http://proceedings.mlr.press/v37/blundell15.pdf">http://proceedings.mlr.press/v37/blundell15.pdf</a></p>
  </li>
  <li>
    <p>Stochastic Backpropagation and Approximate Inference in Deep Generative Models</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1401.4082">https://arxiv.org/abs/1401.4082</a></p>
  </li>
  <li>
    <p>On the Importance of Single Directions for Generalization</p>
  </li>
  <li>
    <p>https://arxiv.org/abs/1803.06959</p>
  </li>
  <li>
    <p>Variational Inference</p>
  </li>
  <li>
    <p>Filtering Variational Objectives</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1705.09279.pdf">https://arxiv.org/pdf/1705.09279.pdf</a></p>
  </li>
  <li>
    <p>Variational Inference for Monte Carlo Objectives</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1602.06725">https://arxiv.org/abs/1602.06725</a></p>
  </li>
  <li>
    <p>Variational Inference with Normalizing Flows</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1505.05770.pdf">https://arxiv.org/pdf/1505.05770.pdf</a></p>
  </li>
  <li>
    <p>Variational Information Maximization for Intrinsically Motivated Reinforcement Learning [Also, Reinforcement Learning]</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1509.08731v1.pdf">https://arxiv.org/pdf/1509.08731v1.pdf</a></p>
  </li>
  <li>
    <p>Neural Variational Inference and Learning in Belief Networks</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1402.0030v2.pdf">https://arxiv.org/pdf/1402.0030v2.pdf</a></p>
  </li>
  <li>
    <p>Distribution Matching in Variational Inference [Also, Generative, Unsupervised Learning]</p>
  </li>
  <li>
    <p>https://arxiv.org/abs/1802.06847</p>
  </li>
  <li>
    <p>Generative Models</p>
  </li>
  <li>
    <p>The Cramer Distance as a Solution to Biased Wasserstein Gradients</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1705.10743.pdf">https://arxiv.org/pdf/1705.10743.pdf</a></p>
  </li>
  <li>
    <p>Variational Approaches for Auto-Encoding Generative Adversarial Networks</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1706.04987.pdf">https://arxiv.org/pdf/1706.04987.pdf</a></p>
  </li>
  <li>
    <p>Comparison of Maximum Likelihood and GAN-based training of Real NVPs</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1705.05263.pdf">https://arxiv.org/pdf/1705.05263.pdf</a></p>
  </li>
  <li>
    <p>Parallel Multiscale Autoregressive Density Estimation</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1703.03664.pdf">https://arxiv.org/pdf/1703.03664.pdf</a></p>
  </li>
  <li>
    <p>Conditional Image Generation with PixelCNN Decoders</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1606.05328.pdf">https://arxiv.org/pdf/1606.05328.pdf</a></p>
  </li>
  <li>
    <p>WaveNet: A Generative Model for Raw Audio</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1609.03499.pdf">https://arxiv.org/pdf/1609.03499.pdf</a></p>
  </li>
  <li>
    <p>Video Pixel Networks</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1610.00527.pdf">https://arxiv.org/pdf/1610.00527.pdf</a></p>
  </li>
  <li>
    <p>Learning in Implicit Generative Models</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1610.03483.pdf">https://arxiv.org/pdf/1610.03483.pdf</a></p>
  </li>
  <li>
    <p>Connecting Generative Adversarial Networks and Actor-Critic Methods [Also, Reinforcement Learning]</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1610.01945.pdf">https://arxiv.org/pdf/1610.01945.pdf</a></p>
  </li>
  <li>
    <p>Pixel Recurrent Neural Networks</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1601.06759">https://arxiv.org/abs/1601.06759</a></p>
  </li>
  <li>
    <p>One-Shot Generalization in Deep Generative Models</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1603.05106">https://arxiv.org/abs/1603.05106</a></p>
  </li>
  <li>
    <p>A Test of Relative Similarity for Model Selection in Generative Models</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1511.04581.pdf">https://arxiv.org/pdf/1511.04581.pdf</a></p>
  </li>
  <li>
    <p>DRAW: A Recurrent Neural Network for Image Generation [Also, Attention]</p>
  </li>
  <li>
    <p><a href="http://proceedings.mlr.press/v37/gregor15.pdf">http://proceedings.mlr.press/v37/gregor15.pdf</a></p>
  </li>
  <li>
    <p>Semi-Supervised Learning with Deep Generative Models</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1406.5298">https://arxiv.org/abs/1406.5298</a></p>
  </li>
  <li>
    <p>Deep AutoRegressive Networks</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1310.8499">https://arxiv.org/abs/1310.8499</a></p>
  </li>
  <li>
    <p>A Note on the Evaluation of Generative Models</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1511.01844v2.pdf">https://arxiv.org/pdf/1511.01844v2.pdf</a></p>
  </li>
  <li>
    <p>Parallel WaveNet: Fast High-Fidelity Speech Synthesis (WaveRNN)</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1711.10433">https://arxiv.org/abs/1711.10433</a></p>
  </li>
  <li>
    <p>Efficient Neural Audio synthesis</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1802.08435">https://arxiv.org/abs/1802.08435</a></p>
  </li>
  <li>
    <p>Learning and Querying Fast Generative Models for Reinforcement Learning</p>
  </li>
  <li>
    <p>https://arxiv.org/abs/1802.03006</p>
  </li>
  <li>
    <p>Unsupervised Learning</p>
  </li>
  <li>
    <p>Unsupervised Learning of 3D Structure from Images [Also, Computer Vision]</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1607.00662.pdf">https://arxiv.org/pdf/1607.00662.pdf</a></p>
  </li>
  <li>
    <p>Early Visual Concept Learning with Unsupervised Deep Learning (beta-VAE)</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1606.05579.pdf">https://arxiv.org/pdf/1606.05579.pdf</a></p>
  </li>
  <li>
    <p>Neural Scene Representation and Rendering</p>
  </li>
  <li>
    <p><a href="http://science.sciencemag.org/content/360/6394/1204">http://science.sciencemag.org/content/360/6394/1204</a></p>
  </li>
  <li>
    <p>Spectral Inference Networks: Unifying Spectral Methods with Deep Learning</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1806.02215">https://arxiv.org/abs/1806.02215</a></p>
  </li>
  <li>
    <p>Representation Learning</p>
  </li>
  <li>
    <p>SCAN: Learning Abstract Hierarchical Compositional Visual Concepts</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1707.03389.pdf">https://arxiv.org/pdf/1707.03389.pdf</a></p>
  </li>
  <li>
    <p>Towards Conceptual Compression</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1604.08772">https://arxiv.org/abs/1604.08772</a></p>
  </li>
  <li>
    <p>Neural Discrete Representation Learning [Also, Unsupervised Learning]</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1711.00937">https://arxiv.org/abs/1711.00937</a></p>
  </li>
  <li>
    <p>Disentangling by Factorising</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1802.05983">https://arxiv.org/abs/1802.05983</a></p>
  </li>
  <li>
    <p>Associative Compression Networks for Representation Learning</p>
  </li>
  <li>
    <p>https://arxiv.org/abs/1804.02476</p>
  </li>
  <li>
    <p>Attention</p>
  </li>
  <li>
    <p>Attend, Infer, Repeat: Fast Scene Understanding with Generative Models</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1603.08575.pdf">https://arxiv.org/pdf/1603.08575.pdf</a></p>
  </li>
  <li>
    <p>Reasoning about Entailment with Neural Attention [Also, Natural Language Processing]</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1509.06664v2.pdf">https://arxiv.org/pdf/1509.06664v2.pdf</a></p>
  </li>
  <li>
    <p>Multiple Object Recognition with Visual Attention</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1412.7755v2.pdf">https://arxiv.org/pdf/1412.7755v2.pdf</a></p>
  </li>
  <li>
    <p>Recurrent Models of Visual Attention</p>
  </li>
  <li>
    <p>https://arxiv.org/abs/1406.6247</p>
  </li>
  <li>
    <p>Memory</p>
  </li>
  <li>
    <p>Neural Episodic Control</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1703.01988.pdf">https://arxiv.org/pdf/1703.01988.pdf</a></p>
  </li>
  <li>
    <p>Generative Temporal Models With Memory</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1702.04649.pdf">https://arxiv.org/pdf/1702.04649.pdf</a></p>
  </li>
  <li>
    <p>Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1610.09027.pdf">https://arxiv.org/pdf/1610.09027.pdf</a></p>
  </li>
  <li>
    <p>Model-Free Episodic Control</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1606.04460">https://arxiv.org/abs/1606.04460</a></p>
  </li>
  <li>
    <p>One-Shot Learning with Memory-Augmented Neural Networks</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1605.06065">https://arxiv.org/abs/1605.06065</a></p>
  </li>
  <li>
    <p>Associative Long Short-Term Memory</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1602.03032">https://arxiv.org/abs/1602.03032</a></p>
  </li>
  <li>
    <p>Prioritized Experience Replay</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1511.05952v3.pdf">https://arxiv.org/pdf/1511.05952v3.pdf</a></p>
  </li>
  <li>
    <p>Sample Efficient Actor-Critic with Experience Replay</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1611.01224.pdf">https://arxiv.org/pdf/1611.01224.pdf</a></p>
  </li>
  <li>
    <p>Learning Efficient Algorithms with Hierarchical Attentive Memory [Also, attention]</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1602.03218">https://arxiv.org/abs/1602.03218</a></p>
  </li>
  <li>
    <p>Count-Based Frequency Estimation with Bounded Memory [Also, Natural Language Processing]</p>
  </li>
  <li>
    <p><a href="http://www.ijcai.org/Proceedings/15/Papers/470.pdf">http://www.ijcai.org/Proceedings/15/Papers/470.pdf</a></p>
  </li>
  <li>
    <p>Memory-based Parameter Adaptation</p>
  </li>
  <li>
    <p>https://arxiv.org/abs/1802.10542</p>
  </li>
  <li>
    <p>Multi-Agent Systems</p>
  </li>
  <li>
    <p>Value Decomposition Networks For Cooperative Multi-Agent Learning</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1706.05296.pdf">https://arxiv.org/pdf/1706.05296.pdf</a></p>
  </li>
  <li>
    <p>Learning to Communicate with Deep Multi-Agent Reinforcement Learning [Also, Multi-Task RL]</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1605.06676v2.pdf">https://arxiv.org/pdf/1605.06676v2.pdf</a></p>
  </li>
  <li>
    <p>A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning [Also, Game Theory]</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1711.00832">https://arxiv.org/abs/1711.00832</a></p>
  </li>
  <li>
    <p>Machine Theory of Mind</p>
  </li>
  <li>
    <p>https://arxiv.org/abs/1802.07740</p>
  </li>
  <li>
    <p>Imitation Learning</p>
  </li>
  <li>
    <p>Robust Imitation of Diverse Behaviors</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1707.02747.pdf">https://arxiv.org/pdf/1707.02747.pdf</a></p>
  </li>
  <li>
    <p>Learning Human Behaviors from Motion Capture by Adversarial Imitation</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1707.02201">https://arxiv.org/abs/1707.02201</a></p>
  </li>
  <li>
    <p>Leveraging Demonstrations for Deep Reinforcement Learning on Robotics Problems with Sparse Rewards</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1707.08817.pdf">https://arxiv.org/pdf/1707.08817.pdf</a></p>
  </li>
  <li>
    <p>Reinforcement and Imitation Learning for Diverse Visuomotor Skills</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1802.09564">https://arxiv.org/abs/1802.09564</a></p>
  </li>
  <li>
    <p>Playing Hard Exploration Games by Watching Youtube</p>
  </li>
  <li>
    <p>https://arxiv.org/abs/1805.11592</p>
  </li>
  <li>
    <p>Metalearning</p>
  </li>
  <li>
    <p>Neural Programming</p>
  </li>
  <li>
    <p>Hybrid Computing Using a Neural Network with Dynamic External Memory</p>
  </li>
  <li>
    <p><a href="https://www.nature.com/articles/nature20101.epdf?author_access_token=ImTXBI8aWbYxYQ51Plys8NRgN0jAjWel9jnR3ZoTv0MggmpDmwljGswxVdeocYSurJ3hxupzWuRNeGvvXnoO8o4jTJcnAyhGuZzXJ1GEaD-Z7E6X_a9R-xqJ9TfJWBqz">https://www.nature.com/articles/nature20101.epdf?author_access_token=ImTXBI8aWbYxYQ51Plys8NRgN0jAjWel9jnR3ZoTv0MggmpDmwljGswxVdeocYSurJ3hxupzWuRNeGvvXnoO8o4jTJcnAyhGuZzXJ1GEaD-Z7E6X_a9R-xqJ9TfJWBqz</a></p>
  </li>
  <li>
    <p>Programmable Agents [Also, Representation Learning]</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1706.06383.pdf">https://arxiv.org/pdf/1706.06383.pdf</a></p>
  </li>
  <li>
    <p>Neural Programmer-Interpreters</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1511.06279v3.pdf">https://arxiv.org/pdf/1511.06279v3.pdf</a></p>
  </li>
  <li>
    <p>Neural Random-Access Machines</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1511.06392v3.pdf">https://arxiv.org/pdf/1511.06392v3.pdf</a></p>
  </li>
  <li>
    <p>Neural Turing Machines</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1410.5401">https://arxiv.org/abs/1410.5401</a></p>
  </li>
  <li>
    <p>Learning Explanatory Rules from Noisy Data</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1711.04574">https://arxiv.org/abs/1711.04574</a></p>
  </li>
  <li>
    <p>Synthesizing Programs for Images using Reinforced Adversarial Learning (SPIRAL)</p>
  </li>
  <li>
    <p>https://arxiv.org/abs/1804.01118</p>
  </li>
  <li>
    <p>Learning to learn by gradient descent by gradient descent</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1606.04474">https://arxiv.org/abs/1606.04474</a></p>
  </li>
  <li>
    <p>Learning to Reinforcement Learn [Also, Reinforcement Learning]</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1611.05763.pdf">https://arxiv.org/pdf/1611.05763.pdf</a></p>
  </li>
  <li>
    <p>Hierarchical Representations for Efficient Architecture Search</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1711.00436.pdf">https://arxiv.org/pdf/1711.00436.pdf</a></p>
  </li>
  <li>
    <p>Population Based Training of Neural Networks</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1711.09846">https://arxiv.org/abs/1711.09846</a></p>
  </li>
  <li>
    <p>Meta-Gradient Reinforcement Learning</p>
  </li>
  <li>
    <p>https://arxiv.org/abs/1805.09801</p>
  </li>
  <li>
    <p>Evolution</p>
  </li>
  <li>
    <p>Convolution by Evolution</p>
  </li>
  <li>
    <p>https://arxiv.org/pdf/1606.02580.pdf</p>
  </li>
  <li>
    <p>Game Theory</p>
  </li>
  <li>
    <p>Learning Nash Equilibrium for General-Sum Markov Games from Batch Data</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1606.08718.pdf">https://arxiv.org/pdf/1606.08718.pdf</a></p>
  </li>
  <li>
    <p>The Mechanics of n-Player Differentiable Games [Also, Generative Models (GANs)]</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1802.05642">https://arxiv.org/abs/1802.05642</a></p>
  </li>
  <li>
    <p>Symmetric Decomposition of Asymmetric Games</p>
  </li>
  <li>
    <p><a href="https://www.nature.com/articles/s41598-018-19194-4">https://www.nature.com/articles/s41598-018-19194-4</a></p>
  </li>
  <li>
    <p>A Generalised Method for Empirical Game Theoretic Analysis</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1803.06376">https://arxiv.org/abs/1803.06376</a></p>
  </li>
  <li>
    <p>Inequity Aversion Resolves Intertemporal Social Dilemmas</p>
  </li>
  <li>
    <p>https://arxiv.org/abs/1803.08884</p>
  </li>
  <li>
    <p>Natural Language Processing</p>
  </li>
  <li>
    <p>Generative and Discriminative Text Classification with Recurrent Neural Networks</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1703.01898.pdf">https://arxiv.org/pdf/1703.01898.pdf</a></p>
  </li>
  <li>
    <p>Learning to Compose Words Into Sentences with Reinforcement Learning</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1611.09100.pdf">https://arxiv.org/pdf/1611.09100.pdf</a></p>
  </li>
  <li>
    <p>Reference-Aware Language Models</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1611.01628.pdf">https://arxiv.org/pdf/1611.01628.pdf</a></p>
  </li>
  <li>
    <p>The Neural Noisy Channel</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1611.02554.pdf">https://arxiv.org/pdf/1611.02554.pdf</a></p>
  </li>
  <li>
    <p>Latent Predictor Networks for Code Generation</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1603.06744.pdf">https://arxiv.org/pdf/1603.06744.pdf</a></p>
  </li>
  <li>
    <p>Learning the Curriculum with Bayesian Optimization for Task-Specific Word Representation Learning</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1605.03852.pdf">https://arxiv.org/pdf/1605.03852.pdf</a></p>
  </li>
  <li>
    <p>Semantic Parsing with Semi-Supervised Sequential Autoencoders</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1609.09315.pdf">https://arxiv.org/pdf/1609.09315.pdf</a></p>
  </li>
  <li>
    <p>On the State of the Art of Evaluation in Neural Language Models</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1707.05589">https://arxiv.org/abs/1707.05589</a></p>
  </li>
  <li>
    <p>Teaching Machines to Read and Comprehend</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1506.03340v1.pdf">https://arxiv.org/pdf/1506.03340v1.pdf</a></p>
  </li>
  <li>
    <p>Learning to Transduce with Unbounded Memory [Also, Memory, Neural Programming]</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1506.02516v1.pdf">https://arxiv.org/pdf/1506.02516v1.pdf</a></p>
  </li>
  <li>
    <p>Dependency Recurrent Neural Language Models for Sentence Completion</p>
  </li>
  <li>
    <p><a href="http://cs.nyu.edu/~mirowski/pub/MirowskiVlachos_ACL2015_DependencyTreeRNN.pdf">http://cs.nyu.edu/~mirowski/pub/MirowskiVlachos_ACL2015_DependencyTreeRNN.pdf</a></p>
  </li>
  <li>
    <p>Towards End-to-End Speech Recognition with Recurrent Neural Networks</p>
  </li>
  <li>
    <p><a href="http://proceedings.mlr.press/v32/graves14.pdf">http://proceedings.mlr.press/v32/graves14.pdf</a></p>
  </li>
  <li>
    <p>Learning Word Embeddings Efficiently with Noise-Contrastive Estimation</p>
  </li>
  <li>
    <p><a href="http://papers.nips.cc/paper/5165-learning-word-embeddings-efficiently-with-noise-contrastive-estimation.pdf">http://papers.nips.cc/paper/5165-learning-word-embeddings-efficiently-with-noise-contrastive-estimation.pdf</a></p>
  </li>
  <li>
    <p>The NarrativeQA Reading Comprehension Challenge</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1712.07040v1">https://arxiv.org/abs/1712.07040v1</a></p>
  </li>
  <li>
    <p>Learning to Follow Language Instructions with Adversarial Reward Induction [Also, Loss Function Learning]</p>
  </li>
  <li>
    <p>https://arxiv.org/abs/1806.01946</p>
  </li>
  <li>
    <p>Multi-Modal</p>
  </li>
  <li>
    <p>Look, Listen and Learn</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1705.08168.pdf">https://arxiv.org/pdf/1705.08168.pdf</a></p>
  </li>
  <li>
    <p>End-to-end Optimization of Goal-Driven and Visually Grounded Dialogue Systems</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1703.05423.pdf">https://arxiv.org/pdf/1703.05423.pdf</a></p>
  </li>
  <li>
    <p>GuessWhat?! Visual Object Discovery through Multi-Modal Dialogue</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1611.08481.pdf">https://arxiv.org/pdf/1611.08481.pdf</a></p>
  </li>
  <li>
    <p>Grounded Language Learning in a Simulated 3D World</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1706.06551.pdf">https://arxiv.org/pdf/1706.06551.pdf</a></p>
  </li>
  <li>
    <p>Understanding Grounded Language Learning Agents [Also, Natural Language Processing]</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1710.09867">https://arxiv.org/abs/1710.09867</a></p>
  </li>
  <li>
    <p>Objects that Sound</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1712.06651">https://arxiv.org/abs/1712.06651</a></p>
  </li>
  <li>
    <p>General Machine Learning</p>
  </li>
  <li>
    <p>The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1611.00712.pdf">https://arxiv.org/pdf/1611.00712.pdf</a></p>
  </li>
  <li>
    <p>Learning Deep Nearest Neighbor Representations Using Differentiable Boundary Trees</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1702.08833.pdf">https://arxiv.org/pdf/1702.08833.pdf</a></p>
  </li>
  <li>
    <p>Unit Tests for Stochastic Optimization</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1312.6055v3.pdf">https://arxiv.org/pdf/1312.6055v3.pdf</a></p>
  </li>
  <li>
    <p>Bayesian Hierarchical Community Discovery</p>
  </li>
  <li>
    <p><a href="http://papers.nips.cc/paper/5048-bayesian-hierarchical-community-discovery.pdf">http://papers.nips.cc/paper/5048-bayesian-hierarchical-community-discovery.pdf</a></p>
  </li>
  <li>
    <p>Implicit Reparameterization Gradients</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1805.08498">https://arxiv.org/abs/1805.08498</a></p>
  </li>
  <li>
    <p>Cleaning up the Neighborhood: A Full Classification for Adversarial Partial Monitoring</p>
  </li>
  <li>
    <p>https://arxiv.org/abs/1805.09247</p>
  </li>
  <li>
    <p>Theory</p>
  </li>
  <li>
    <p>Online Learning with Gated Linear Networks</p>
  </li>
  <li>
    <p>https://arxiv.org/abs/1712.01897v1</p>
  </li>
  <li>
    <p>Miscellaneous</p>
  </li>
  <li>
    <p>Generalized Probability Smoothing</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1712.02151">https://arxiv.org/abs/1712.02151</a></p>
  </li>
  <li>
    <p>Agents and Devices: A Relative Definition of Agency</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1805.12387">https://arxiv.org/abs/1805.12387</a></p>
  </li>
  <li>
    <p>Neuroscience</p>
  </li>
  <li>
    <p>The Successor representation in human reinforcement learning</p>
  </li>
  <li>
    <p><a href="http://www.biorxiv.org/content/biorxiv/early/2017/07/04/083824.full.pdf">http://www.biorxiv.org/content/biorxiv/early/2017/07/04/083824.full.pdf</a></p>
  </li>
  <li>
    <p>Dorsal Hippocampus Contributes to Model-Based Planning</p>
  </li>
  <li>
    <p><a href="https://www.nature.com/articles/nn.4613.epdf?author_access_token=OfuqRzRgBmFKQdGE1Qw7FdRgN0jAjWel9jnR3ZoTv0N3IprbEH8EVdPgVTpPLVjgaMNMGW_KprBhEEIm7f1drNjI5FB2fds3h58n3XEtMJPC3kLK1Pp3J2_Qb45cy7uk">https://www.nature.com/articles/nn.4613.epdf?author_access_token=OfuqRzRgBmFKQdGE1Qw7FdRgN0jAjWel9jnR3ZoTv0N3IprbEH8EVdPgVTpPLVjgaMNMGW_KprBhEEIm7f1drNjI5FB2fds3h58n3XEtMJPC3kLK1Pp3J2_Qb45cy7uk</a></p>
  </li>
  <li>
    <p>Neuroscience-Inspired Artificial Intelligence</p>
  </li>
  <li>
    <p><a href="http://www.cell.com/neuron/fulltext/S0896-6273(17)30509-3">http://www.cell.com/neuron/fulltext/S0896-6273(17)30509-3</a></p>
  </li>
  <li>
    <p>Computations Underlying Social Hierarchy Learning: Distinct Neural Mechanism for Updating and Representing Self-Relevant Information</p>
  </li>
  <li>
    <p><a href="http://www.cell.com/neuron/pdf/S0896-6273(16)30802-9.pdf">http://www.cell.com/neuron/pdf/S0896-6273(16)30802-9.pdf</a></p>
  </li>
  <li>
    <p>Dorsal Anterior Cingulate Cortex and the Value of Control</p>
  </li>
  <li>
    <p><a href="https://www.nature.com/articles/nn.4384.epdf?author_access_token=dq-w7RyWLn3z-0m4nbyTW9RgN0jAjWel9jnR3ZoTv0N7RVyemANPvboWSepiJaSAsTFiGqyORVbog9B6IjN113kC9aqMAEoNVCCfdRA4gLVJXcy4e1klhW0KiKS5F1gp">https://www.nature.com/articles/nn.4384.epdf?author_access_token=dq-w7RyWLn3z-0m4nbyTW9RgN0jAjWel9jnR3ZoTv0N7RVyemANPvboWSepiJaSAsTFiGqyORVbog9B6IjN113kC9aqMAEoNVCCfdRA4gLVJXcy4e1klhW0KiKS5F1gp</a></p>
  </li>
  <li>
    <p>Semantic Representations in the Temporal Pole Predict False Memories</p>
  </li>
  <li>
    <p><a href="http://www.pnas.org/content/113/36/10180.abstract">http://www.pnas.org/content/113/36/10180.abstract</a></p>
  </li>
  <li>
    <p>Towards an Integration of Deep Learning and Neuroscience</p>
  </li>
  <li>
    <p><a href="http://www.biorxiv.org/content/early/2016/06/13/058545">http://www.biorxiv.org/content/early/2016/06/13/058545</a></p>
  </li>
  <li>
    <p>What Learning Systems do Intelligent Agents Need? Complementary Learning systems Theory Updated</p>
  </li>
  <li>
    <p><a href="http://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(16)30043-2">http://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(16)30043-2</a></p>
  </li>
  <li>
    <p>Neural Mechanisms of Hierarchical Planning in a Virtual Subway Network [Also, Planning]</p>
  </li>
  <li>
    <p><a href="http://www.cell.com/neuron/abstract/S0896-6273(16)30057-5">http://www.cell.com/neuron/abstract/S0896-6273(16)30057-5</a></p>
  </li>
  <li>
    <p>Predictive Representations can Link Model-Based Reinforcement Learning to Model-Free Mechanisms</p>
  </li>
  <li>
    <p><a href="https://www.biorxiv.org/content/early/2016/10/27/083857">https://www.biorxiv.org/content/early/2016/10/27/083857</a></p>
  </li>
  <li>
    <p>Hippocampal place cells construct reward related sequences through unexplored space</p>
  </li>
  <li>
    <p><a href="https://elifesciences.org/articles/06063">https://elifesciences.org/articles/06063</a></p>
  </li>
  <li>
    <p>A Probabilistic Approach to Demixing Odors</p>
  </li>
  <li>
    <p><a href="http://www.nature.com/neuro/journal/v20/n1/full/nn.4444.html">http://www.nature.com/neuro/journal/v20/n1/full/nn.4444.html</a></p>
  </li>
  <li>
    <p>Approximate Hubel-Wiesel Modules and the Data Structures of Neural Computation</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1512.08457v1.pdf">https://arxiv.org/pdf/1512.08457v1.pdf</a></p>
  </li>
  <li>
    <p>The Future of Memory: Remembering, Imagining, and the Brain</p>
  </li>
  <li>
    <p><a href="http://static1.1.sqspcdn.com/static/f/1096238/22043246/1361990370157/FutureMemory--Neuron12.pdf?token=b5gB3ycz3e%2BmKnQQCW3%2FvwZyHwE%3D">http://static1.1.sqspcdn.com/static/f/1096238/22043246/1361990370157/FutureMemory–Neuron12.pdf?token=b5gB3ycz3e%2BmKnQQCW3%2FvwZyHwE%3D</a></p>
  </li>
  <li>
    <p>Is the Brain a Good Model for Machine Intelligence?</p>
  </li>
  <li>
    <p><a href="http://www.gatsby.ucl.ac.uk/~demis/TuringSpecialIssue(Nature2012).pdf">http://www.gatsby.ucl.ac.uk/~demis/TuringSpecialIssue(Nature2012).pdf</a></p>
  </li>
  <li>
    <p>Evidence Integration in Model-Based Tree Search</p>
  </li>
  <li>
    <p><a href="http://www.pnas.org/content/112/37/11708.full.pdf">http://www.pnas.org/content/112/37/11708.full.pdf</a></p>
  </li>
  <li>
    <p>(Commentary on0 Building Machines that Learn and Think for Themselves</p>
  </li>
  <li>
    <p><a href="https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/building-machines-that-learn-and-think-for-themselves/E28DBFEC380D4189FB7754B50066A96F">https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/building-machines-that-learn-and-think-for-themselves/E28DBFEC380D4189FB7754B50066A96F</a></p>
  </li>
  <li>
    <p>Prefrontal Cortex as a Meta-Reinforcement Learning System</p>
  </li>
  <li>
    <p>https://www.nature.com/articles/s41593-018-0147-8</p>
  </li>
</ol>

<p>Current Frontier:</p>

<ol>
  <li>
    <p>Hierarchical planning</p>
  </li>
  <li>
    <p>Imagination-based planning with generative models</p>
  </li>
  <li>
    <p>Unsupervised Learning</p>
  </li>
  <li>
    <p>Memory and one-shot learning</p>
  </li>
  <li>
    <p>Abstract Concepts</p>
  </li>
  <li>
    <p>Continual and Transfer Learning</p>
  </li>
</ol>

<p>Emphasis on systems neuroscience - using the brain as inspiration for the structure and function of algorithms.</p>

<p><a href="http://sci-hub.cc/10.1016/j.neuron.2017.06.011">Neuroscience Inspired Artificial Intelligence</a></p>

<p>Examples of previous success of neuro-inspiration:</p>

<ul>
  <li>
    <p>Reinforcement Learning</p>
  </li>
  <li>
    <p>Inspired by animal learning</p>
  </li>
  <li>
    <p>TD Learning came out of animal behavior research.</p>
  </li>
  <li>
    <p>Second-order conditioning (Conditional Stimulus) (Sutton and Barto, 1981)</p>
  </li>
  <li>
    <p>Deep Learning.</p>
  </li>
  <li>
    <p>Convolutional Neural Networks. Visual Cortex (V1)</p>
  </li>
  <li>
    <p>Uses hierarchical structure (successive processing layers)</p>
  </li>
  <li>
    <p>Neurons in the early visual systems responds strongly to specific patterns of light (say, precisely oriented bars) but hardly responds to many other patterns.</p>
  </li>
  <li>
    <p>Gabor functions describe the weights in V1 cells.</p>
  </li>
  <li>
    <p>Nonlinear Transduction</p>
  </li>
  <li>
    <p>Divisive Normalization</p>
  </li>
  <li>
    <p>Word / Sentence Vectors - Distributed Embeddings</p>
  </li>
  <li>
    <p>Parallel Distributed Processing in the brain for representation and computation</p>
  </li>
  <li>
    <p>Dropout</p>
  </li>
  <li>
    <p>Stochasticity in neurons that fire with` Poisson-like statistics (Hinton 2012)</p>
  </li>
  <li>
    <p>Attention</p>
  </li>
  <li>
    <p>Applying attention to memory</p>
  </li>
  <li>
    <p>Thought - it doesn’t make much sense to train an attention model over a static image, rather than over a time series. With a time series, bringing attention to changing aspects of the input makes sense.</p>
  </li>
  <li>
    <p>Multiple Memory Systems</p>
  </li>
  <li>
    <p>Episodic Memory</p>
  </li>
  <li>
    <p>Experience Replay</p>
  </li>
  <li>
    <p>Especially for one shot experiences</p>
  </li>
  <li>
    <p>Working Memory</p>
  </li>
  <li>
    <p>LSTM - gating allows for conditioning on current state</p>
  </li>
  <li>
    <p>Long-term Memory</p>
  </li>
  <li>
    <p>External Memory</p>
  </li>
  <li>
    <p>Gating in LSTM</p>
  </li>
  <li>
    <p>Continual Learning</p>
  </li>
  <li>
    <p>Elastic weight consolidation for slowing down learning on weights that are important for previous tasks.</p>
  </li>
</ul>

<p>Examples of future success:</p>

<ul>
  <li>
    <p>Intuitive Understanding of Physics</p>
  </li>
  <li>
    <p>Need to understand space, number, objectness</p>
  </li>
  <li>
    <p>Need to disentangle representations for transfer. (Dude, I feel so stolen from)</p>
  </li>
  <li>
    <p>Efficient Learning (Learning from few examples)</p>
  </li>
  <li>
    <p>Transfer Learning</p>
  </li>
  <li>
    <p>Transferring generalized knowledge gained in one context to novel domains</p>
  </li>
  <li>
    <p>Concept representations for transfer</p>
  </li>
  <li>
    <p>No direct evidence of concept representations in brains</p>
  </li>
  <li>
    <p>Imagination and Planning</p>
  </li>
  <li>
    <p>Toward model-based RL</p>
  </li>
  <li>
    <p>Internal model of the environment</p>
  </li>
  <li>
    <p>Model needs to include compositional / disentangled representations for flexibility</p>
  </li>
  <li>
    <p>Implementing a forecasted-based method of action selection</p>
  </li>
  <li>
    <p>Monte-carlo Tree Search as simulation based planning</p>
  </li>
  <li>
    <p>In rat brains, we observe ‘preplay’ where rats imagine the likely future experience - measured by comparing neural activations at preplay to activations during the activity</p>
  </li>
  <li>
    <p>Generalization + Transfer in human planning</p>
  </li>
  <li>
    <p>Hierarchical Planning</p>
  </li>
  <li>
    <p>Virtual Brain Analytics</p>
  </li>
</ul>

<p>2.</p>

  </div><a class="u-url" href="/thinking/2019/02/08/deepmind-path.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Grounded Abstraction</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Grounded Abstraction</li><li><a class="u-email" href="mailto:jnixon2@gmail.com">jnixon2@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/jeremynixon"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">jeremynixon</span></a></li><li><a href="https://www.twitter.com/JvNixon"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">JvNixon</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Reach to the sky from the bottom.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
