---
layout: post
title:  "OpenAI Research Frontier"
date:   2019-02-08 18:37:46 -0700
categories: thinking
---
By Jeremy Nixon [[jnixon2@gmail.com](mailto:jnixon2@gmail.com)]. Nov 2017.

  
  

Categories: Domain in which the paperâ€™s innovation is novel.

  

1.  Reinforcement Learning
    

	1.  Multi-Agent
	    
	2.  Exploration
	    
	3.  Imitation Learning
	    

3.  Deep Learning
    
4.  Memory
    
5.  Program Learning
    
6.  Representation Learning
    
7.  Variational Inference
    
8.  Generative Models
    
9.  Evolution
    
10.  Applications
    
	
		1.  Security / Safety
		    
		2.  Robotics
		    

12.  Environments
    

  
  
  Papers:
  

1.  Reinforcement Learning
    
	
	1.  Multi-Agent
	    
	
		1.  Learning with Opponent-Learning Awareness
		    

		1.  [https://arxiv.org/abs/1709.04326](https://arxiv.org/abs/1709.04326)
		    

		3.  Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments
		    

		1.  [https://arxiv.org/abs/1706.02275](https://arxiv.org/abs/1706.02275)
		    

		5.  Emergence of Grounded Compositional Language in Multi-Agent Populations
		    

		1.  [https://arxiv.org/abs/1703.04908](https://arxiv.org/abs/1703.04908)
		    

	3.  Exploration
	    

		1.  Parameter Space Noise for Exploration
		    

		1.  [https://arxiv.org/abs/1706.01905](https://arxiv.org/abs/1706.01905)
		    

		3.  UCB and InfoGain Exploration via Q-Ensembles
		    

		1.  [https://arxiv.org/abs/1706.01502](https://arxiv.org/abs/1706.01502)
		    

		5.  Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning
		    

		1.  [https://arxiv.org/abs/1611.04717](https://arxiv.org/abs/1611.04717)
		    

		7.  VIME: Variational Information Maximizing Exploration
		    

		1.  https://arxiv.org/abs/1605.09674
		    

	5.  Imitation Learning
	    
	
		1.  Third-Person Imitation Learning
		    

		1.  [https://arxiv.org/abs/1703.01703](https://arxiv.org/abs/1703.01703)
		    

		3.  One-Shot Imitation Learning
		    

		1.  [https://arxiv.org/abs/1703.07326](https://arxiv.org/abs/1703.07326)
		    

	7.  RL2: Fast Reinforcement Learning via Slow Reinforcement Learning
	    

	1.  https://arxiv.org/abs/1611.02779
	    

	9.  Teacher-Student Curriculum Learning
	    

	1.  [https://arxiv.org/abs/1707.00183](https://arxiv.org/abs/1707.00183)
	    

	11.  Equivalence Between Policy Gradients and Soft Q-Learning
	    

	1.  [https://arxiv.org/abs/1704.06440](https://arxiv.org/abs/1704.06440)
	    

	13.  Prediction and Control with Temporal Segment Models
	    

	1.  https://arxiv.org/abs/1703.04070
	    

3.  Deep Learning
    

	1.  Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks
	    

	1.  https://arxiv.org/abs/1602.07868
	    

5.  Memory
    

	1.  Hindsight Experience Replay [Also, Reinforcement Learning]
	    

	1.  [https://arxiv.org/pdf/1707.01495.pdf](https://arxiv.org/pdf/1707.01495.pdf)
	    

7.  Program Learning
    

	1.  Extensions and Limitations of the Neural GPU
	    

	1.  https://arxiv.org/abs/1611.00736
	    

9.  Representation Learning
    

	1.  Variational Lossy Autoencoder
	    

	1.  [https://arxiv.org/abs/1611.02731](https://arxiv.org/abs/1611.02731)
	    

11.  Variational Inference
    

		1.  Improving Variational Inference with Inverse Autoregressive Flow
		    

		1.  https://arxiv.org/abs/1606.04934
		    

13.  Generative Models
    

		1.  Generative Adversarial Networks
		    

			1.  InfoGan: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets [Also, Representation Learning]
			    

			1.  [https://arxiv.org/abs/1606.03657](https://arxiv.org/abs/1606.03657)
			    

			3.  Improved Techniques for Training GANs
			    

			1.  https://arxiv.org/abs/1606.03498
		    

		3.  On the Quantitative Analysis of Decoder-Based Generative Models
		    

		1.  [https://arxiv.org/abs/1611.04273](https://arxiv.org/abs/1611.04273)
		    

		5.  A Connection between Generative Adversarial Networks, Inverse Reinforcement Learning, and Energy Based Models [Also Reinforcement Learning]
		    

		1.  [https://arxiv.org/pdf/1611.03852.pdf](https://arxiv.org/pdf/1611.03852.pdf)
		    

		7.  PixelCNN++: Improving the Pixel CNN with Discretized Logistic Mixture Likelihood and Other Modifications
		    

		1.  [https://arxiv.org/abs/1701.05517](https://arxiv.org/abs/1701.05517)
		    

		9.  Learning to Generate Reviews and Discovering Sentiment
		    

		1.  [https://arxiv.org/abs/1704.01444](https://arxiv.org/abs/1704.01444)
	    

15.  Evolution
    

		1.  Evolution Strategies as a Scalable Alternative to Reinforcement Learning
		    

		1.  https://arxiv.org/abs/1703.03864
	    

17.  Applications
    

		1.  Security / Safety
		    

			1.  Deep Reinforcement Learning from Human Preferences
			    

			1.  [https://arxiv.org/abs/1706.03741](https://arxiv.org/abs/1706.03741)
			    

			3.  Concrete Problems in AI Safety
			    

			1.  https://arxiv.org/abs/1606.06565
			    

			5.  Adversarial Attacks on Neural Network Policies
			    

			1.  [https://arxiv.org/abs/1702.02284](https://arxiv.org/abs/1702.02284)
			    

			7.  Adversarial Training Methods for Semi-Supervised Text Classification
			    

			1.  [https://arxiv.org/abs/1605.07725](https://arxiv.org/abs/1605.07725)
			    

			9.  Semi-Supervised Knowledge Transfer for Deep Learning from Private Training Data
			    

			1.  [https://arxiv.org/abs/1610.05755](https://arxiv.org/abs/1610.05755)
			    

			11.  Debate Amplification
			    

			1.  https://arxiv.org/pdf/1805.00899.pdf
			    

		3.  Robotics
		    

			1.  Domain Randomization for Transferring Deep NEural Networks from Simulation to the Real World
			    

			1.  [https://arxiv.org/abs/1703.06907](https://arxiv.org/abs/1703.06907)
			    

			3.  Transfer from Simulation to Real World through Learning Deep Inverse Dynamics Model
			    

			1.  [https://arxiv.org/abs/1610.03518](https://arxiv.org/abs/1610.03518)
			    

19.  Environments
    
	
		1.  Infrastructure for Deep Learning
		    

		1.  https://blog.openai.com/infrastructure-for-deep-learning/
		    

		3.  Universe
		    

		1.  [https://blog.openai.com/universe/](https://blog.openai.com/universe/)
		    

		5.  OpenAI Gym
		    

		1.  [https://arxiv.org/abs/1606.01540](https://arxiv.org/abs/1606.01540)
	    

	  
  

OpenAI Researchers (Every name on a published OpenAI Paper)

  

Paul Christiano
    
~~Ryan Lowe~~
    
~~Jean Harb~~
    
~~Pieter Abbeel~~  
    
Igor Mordatch
    
Matthias Plappert
    
Rein Houthooft
    
Prafulla Dhariwal
    
Szymon Sidor
    
Richard Y. Chen
    
~~Xi Chen~~
    
Marcin Andrychowicz
    
John Schulman
    
Alec Radford
    
~~Rafal Jozefowicz~~
    
~~Yan Duan~~
    
~~Bradly C. Stadie~~
    
~~Jonathan Ho~~
    
Jonas Schneider
    
Ilya Sutskever
    
Wojciech Zaremba
    
~~Rachel Fong~~
    
Josh Tobin
    
Alex Ray
    
~~Nikhil Mishra~~
    
~~Ian Goodfellow~~
    
~~Tim Salimans~~
    
~~Diederik P. Kingma~~
    
~~Andrej Karpathy~~
    
Yuri Burda
    
~~Zain Shah~~
    
~~Trevor Blackwell~~
    
~~Vicki Cheung~~
    

  

[Salaries of top employees](http://990s.foundationcenter.org/990_pdf_archive/810/810861541/810861541_201612_990.pdf) [Pg. 28]

[Hours & Salaries of top employees](http://www.guidestar.org/FinDocuments/2016/810/861/2016-810861541-0eb61629-9.pdf) [Pg. 7]

OpenAI spent 11 million in 2016, 7 million on salary. For comparison, Deepmind spend 138 million in 2016.