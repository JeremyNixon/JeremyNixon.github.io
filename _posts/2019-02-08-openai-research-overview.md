---
layout: post
title: "Open AI Research Overview"
date:   2019-02-08
categories: intelligence
---

By Jeremy Nixon [[jnixon2@gmail.com](mailto:jnixon2@gmail.com)]. Nov. 2017.
Categories: Domain in which the paperâ€™s innovation is novel.
1. Reinforcement Learning
   * Multi-Agent
   * Exploration
   * Imitation Learning
2. Deep Learning
3. Memory
4. Program Learning
5. Representation Learning
6. Variational Inference
7. Generative Models
8. Evolution
9. Applications
   * Security / Safety
   * Robotics
10. Environments


1. Reinforcement Learning
   * Multi-Agent
      * [Learning with Opponent-Learning Awareness](https://arxiv.org/abs/1709.04326)
      * [Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments](https://arxiv.org/abs/1706.02275)
      * [Emergence of Grounded Compositional Language in Multi-Agent Populations](https://arxiv.org/abs/1703.04908)
   * Exploration
      * [Parameter Space Noise for Exploration](https://arxiv.org/abs/1706.01905)
      * [UCB and InfoGain Exploration via Q-Ensembles](https://arxiv.org/abs/1706.01502)
      * [Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning](https://arxiv.org/abs/1611.04717)
      * [VIME: Variational Information Maximizing Exploration](https://arxiv.org/abs/1605.09674)
   * Imitation Learning
      * [Third-Person Imitation Learning](https://arxiv.org/abs/1703.01703)
      * [One-Shot Imitation Learning](https://arxiv.org/abs/1703.07326)
   * [RL2: Fast Reinforcement Learning via Slow Reinforcement Learning](https://arxiv.org/abs/1611.02779)
   * [Teacher-Student Curriculum Learning](https://arxiv.org/abs/1707.00183)
   * [Equivalence Between Policy Gradients and Soft Q-Learning](https://arxiv.org/abs/1704.06440)
   * [Prediction and Control with Temporal Segment Models](https://arxiv.org/abs/1703.04070)
2. Deep Learning
   * [Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks](https://arxiv.org/abs/1602.07868)
3. Memory
   * [Hindsight Experience Replay [Also, Reinforcement Learning]](https://arxiv.org/pdf/1707.01495.pdf)
4. Program Learning
   * [Extensions and Limitations of the Neural GPU](https://arxiv.org/abs/1611.00736)
5. Representation Learning
   * [Variational Lossy Autoencoder](https://arxiv.org/abs/1611.02731)
6. Variational Inference
   * [Improving Variational Inference with Inverse Autoregressive Flow](https://arxiv.org/abs/1606.04934)
7. Generative Models
   * Generative Adversarial Networks
      * [InfoGan: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets [Also, Representation Learning]](https://arxiv.org/abs/1606.03657)
      * [Improved Techniques for Training GANs](https://arxiv.org/abs/1606.03498)
   * [On the Quantitative Analysis of Decoder-Based Generative Models](https://arxiv.org/abs/1611.04273)
   * [A Connection between Generative Adversarial Networks, Inverse Reinforcement Learning, and Energy Based Models [Also Reinforcement Learning]](https://arxiv.org/pdf/1611.03852.pdf)
   * [PixelCNN++: Improving the Pixel CNN with Discretized Logistic Mixture Likelihood and Other Modifications](https://arxiv.org/abs/1701.05517)
   * [Learning to Generate Reviews and Discovering Sentiment](https://arxiv.org/abs/1704.01444)
8. Evolution
   * [Evolution Strategies as a Scalable Alternative to Reinforcement Learning](https://arxiv.org/abs/1703.03864)
9. Applications
   * Security / Safety
      * [Deep Reinforcement Learning from Human Preferences](https://arxiv.org/abs/1706.03741)
      * [Concrete Problems in AI Safety](https://arxiv.org/abs/1606.06565)
      * [Adversarial Attacks on Neural Network Policies](https://arxiv.org/abs/1702.02284)
      * [Adversarial Training Methods for Semi-Supervised Text Classification](https://arxiv.org/abs/1605.07725)
      * [Semi-Supervised Knowledge Transfer for Deep Learning from Private Training Data](https://arxiv.org/abs/1610.05755)
      * [Debate Amplification](https://arxiv.org/pdf/1805.00899.pdf)
   * Robotics
      * [Domain Randomization for Transferring Deep NEural Networks from Simulation to the Real World](https://arxiv.org/abs/1703.06907)
      * [Transfer from Simulation to Real World through Learning Deep Inverse Dynamics Model](https://arxiv.org/abs/1610.03518)
10. Environments
    * [Infrastructure for Deep Learning](https://blog.openai.com/infrastructure-for-deep-learning/)
    * [Universe](https://blog.openai.com/universe/)
    * [OpenAI Gym](https://arxiv.org/abs/1606.01540)

OpenAI Researchers
1. Paul Christiano
2. ~~Ryan Lowe~~
3. ~~Jean Harb~~
4. ~~Pieter Abbeel~~
5. ~~Igor Mordatch~~
6. Matthias Plappert
7. ~~Rein Houthooft~~
8. Prafulla Dhariwal
9. Szymon Sidor
10. Richard Y. Chen
11. ~~Xi Chen~~
12. ~~Marcin Andrychowicz~~
13. John Schulman
14. Alec Radford
15. ~~Rafal Jozefowicz~~
16. ~~Yan Duan~~
17. ~~Bradly C. Stadie~~
18. ~~Jonathan Ho~~
19. Jonas Schneider
20. Ilya Sutskever
21. Wojciech Zaremba
22. ~~Rachel Fong~~
23. Josh Tobin
24. Alex Ray
25. ~~Nikhil Mishra~~
26. ~~Ian Goodfellow~~
27. ~~Tim Salimans~~
28. ~~Diederik P. Kingma~~
29. ~~Andrej Karpathy~~
30. ~~Yuri Burda~~
31. ~~Zain Shah~~
32. ~~Trevor Blackwell~~
33. ~~Vicki Cheung~~

[Salaries of top employees](http://990s.foundationcenter.org/990_pdf_archive/810/810861541/810861541_201612_990.pdf) [Pg. 28]
[Hours & Salaries of top employees](http://www.guidestar.org/FinDocuments/2016/810/861/2016-810861541-0eb61629-9.pdf) [Pg. 7]
OpenAI spent 11 million in 2016, 7 million on salary. For comparison, Deepmind spend 138 million in 2016.




 
