<p>By Jeremy Nixon [<a href="mailto:jnixon2@gmail.com">jnixon2@gmail.com</a>]. Nov. 2017. Updated June 2018.</p>

<p>Overview</p>
<ol>
  <li>Categorization of Breakthroughs / Contents</li>
  <li>Major / Minor Researchers List (All appearing on papers)</li>
  <li>Genealogy</li>
  <li>
    <p>Sorted Researchers by Paper Count</p>
  </li>
  <li>Deep Learning
    <ul>
      <li>Scalability and Speed</li>
      <li>Convolutional Neural Networks</li>
      <li>Recurrent Neural Networks</li>
      <li>Privacy</li>
      <li>Understanding / Theory</li>
      <li>Regularization</li>
    </ul>
  </li>
  <li>Applications
    <ul>
      <li>Speech Recognition</li>
      <li>Image Categorization</li>
      <li>Image Captioning</li>
      <li>Machine Translation</li>
      <li>Natural Language Understanding</li>
      <li>Multi-Modal</li>
      <li>Pedestrian Detection</li>
      <li>Grasp Detection</li>
      <li>Go</li>
      <li>Video</li>
      <li>Dialogue</li>
      <li>3D Object Reconstruction</li>
      <li>Speaker Verification</li>
      <li>Health Care</li>
      <li>Theorem Proving</li>
      <li>Music</li>
      <li>Pose Estimation</li>
      <li>Speech Generation</li>
      <li>Super Resolution</li>
      <li>Chemistry</li>
      <li>Robotics
        <ul>
          <li>Autonomous Vehicles</li>
        </ul>
      </li>
      <li>Physics</li>
      <li>Device Placement</li>
      <li>Games</li>
      <li>Art</li>
    </ul>
  </li>
  <li>Unsupervised Learning</li>
  <li>Attention</li>
  <li>Memory</li>
  <li>Transfer Learning</li>
  <li>Representation Learning</li>
  <li>Reinforcemnet Learning
    <ul>
      <li>Model-Based Reinforcement Learning</li>
      <li>Multi-Task Learning</li>
    </ul>
  </li>
  <li>Metalearning
    <ul>
      <li>Neural Programming</li>
      <li>Hyperparameter Optimization</li>
    </ul>
  </li>
  <li>Generative
    <ul>
      <li>GANs</li>
    </ul>
  </li>
  <li>Intrepretability</li>
  <li>Tools, Environments &amp; Datasets</li>
  <li>Adversarial Examples</li>
  <li>Multi-Agent Systems</li>
  <li>Variational Inference</li>
  <li>Kernel Machines</li>
  <li>Collaborative Filtering</li>
  <li>Graphical / Relational Learning</li>
  <li>
    <p>Miscellaneous</p>
  </li>
  <li>Deep Learning
    <ul>
      <li>Scalability and Speed
        <ul>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40565.pdf">Large Scale Distributed Deep Networks</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40810.pdf">Multiframe Deep Neural Networks for Acoustic Modeling</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42248.pdf">Asynchronous Stochastic Optimization for Sequence Training of Deep Neural Networks</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45166.pdf">Tensorflow: Large-Scale Machine Learning on Heterogeneous Distributed Systems</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44873.pdf">Distilling the Knowledge in a Neural Network</a></li>
          <li><a href="https://arxiv.org/pdf/1412.7479.pdf">Deep Networks with Large Output Spaces</a></li>
          <li><a href="https://www.usenix.org/system/files/conference/osdi16/osdi16-abadi.pdf">TensorFlow: A System for Large-Scale Machine Learning</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45187.pdf">Revisiting Distributed Synchronous SGD</a></li>
          <li><a href="https://arxiv.org/abs/1706.03059">Depthwise Separable Convolutions for Neural Machine Translation</a></li>
          <li><a href="https://openreview.net/pdf?id=rkr1UDeC-">Large Scale Distributed Neural Network Training Through Online Distillation</a></li>
          <li><a href="https://openreview.net/pdf?id=SkhQHMW0W">Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training</a></li>
        </ul>
      </li>
      <li>Convolutional Neural Networks
        <ul>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43022.pdf">Going Deeper with Convolutions [Inception]</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44903.pdf">Rethinking the Inception Architecture for Computer Vision</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45169.pdf">Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning</a></li>
          <li><a href="https://arxiv.org/pdf/1705.08664.pdf">Towards Understanding the Invertibility of Convolutional Neural Networks</a></li>
        </ul>
      </li>
      <li>Recurrent Neural Networks
        <ul>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43155.pdf">Sequence to Sequence Learning with Neural Networks</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42547.pdf">Sequence Discriminative Distributed Training of Long Short-Term Memory Recurrent Neural Networks</a></li>
          <li><a href="https://arxiv.org/abs/1409.2329">Recurrent Neural Network Regularization [Also, Language Modeling]</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44267.pdf">Semi-supervised Sequence Learning</a></li>
          <li><a href="https://research.google.com/pubs/pub45474.html">Learning to Execute</a></li>
          <li><a href="https://research.google.com/pubs/pub45473.html">An Empirical Exploration of Recurrent Network Architectures</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44961.pdf">A Simple Way to Initialize Recurrent Networks of Rectified Linear Units</a></li>
          <li><a href="https://arxiv.org/pdf/1610.06258.pdf">Using Fast Weights to Attend to the Recent Past</a></li>
          <li><a href="https://arxiv.org/pdf/1611.02683.pdf">Unsupervised Pre-training for Sequence to Sequence Learning</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44871.pdf">Order Matters: Sequence to Sequence for Sets</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44928.pdf">Multi-Task Sequence to Sequence Learning</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45404.pdf">Generating Sentences from a Continuous Space</a></li>
          <li><a href="https://arxiv.org/pdf/1606.05340.pdf">Exponential expressivity in deep neural networks through transient chaos</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45167.pdf">An Online Sequence-to-Sequence Model Using Partial Conditioning</a></li>
          <li><a href="https://arxiv.org/pdf/1511.04868.pdf">A Neural Transducer</a></li>
          <li><a href="https://openreview.net/pdf?id=Syyv2e-Kx">Tuning Recurrent Neural Networks with Reinforcement Learning</a></li>
          <li><a href="https://arxiv.org/pdf/1611.02796.pdf">Sequence Tutor: Conservative Fine-Tuning of Sequence Generation Models with KL-control</a></li>
          <li><a href="https://arxiv.org/pdf/1702.08503.pdf">SGD Learns the Conjugate Kernel Class of the Network</a></li>
          <li><a href="https://arxiv.org/pdf/1706.05744.pdf">Learning Hierarchical Information Flow with Recurrent Neural Modules</a></li>
          <li><a href="https://arxiv.org/pdf/1610.03035.pdf">Latent Sequence Decompositions</a></li>
          <li><a href="https://openreview.net/pdf?id=BydARw9ex">Capacity and Trainability in Recurrent Neural Networks</a></li>
          <li><a href="https://openreview.net/pdf?id=HJJ23bW0b">Initialization Matters: Orthogonal Predictive State Recurrent Neural Networks</a></li>
        </ul>
      </li>
      <li>Privacy
        <ul>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45428.pdf">Deep Learning with Differential Privacy</a></li>
          <li><a href="https://arxiv.org/pdf/1610.05755.pdf">Semi-Supervised Knowledge Transfer for Deep Learning from Private Training Data</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46128.pdf">Glimmers: Resolving the Privacy / Trust Quagmire</a></li>
          <li><a href="https://arxiv.org/pdf/1802.08908.pdf">Scalable Private Learning with PATE</a></li>
          <li><a href="https://openreview.net/pdf?id=BJ0hF1Z0b">Learning Differentially Private Recurrent Language Models [Also, Language Modeling]</a></li>
        </ul>
      </li>
      <li>Understanding / Theory
        <ul>
          <li><a href="https://arxiv.org/pdf/1412.6544.pdf">Qualitatively Characterizing Neural Network Optimization Problems</a></li>
          <li><a href="https://arxiv.org/pdf/1602.05897.pdf">Toward Deeper Understanding of Neural Networks: The Power of Initialization and a Dual View on Expressivity</a></li>
          <li><a href="https://arxiv.org/pdf/1611.03530.pdf">Understanding Deep Learning Requires Re-Thinking Generalization</a></li>
          <li><a href="https://arxiv.org/pdf/1703.04933.pdf">Sharp Minima Can Generalize for Deep Nets</a></li>
          <li><a href="https://arxiv.org/pdf/1606.05336.pdf">On the Expressive Power of Deep Neural Networks</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46342.pdf">Nonlinear Random Matrix Theory for Deep Learning</a></li>
          <li><a href="http://papers.nips.cc/paper/6879-mean-field-residual-networks-on-the-edge-of-chaos.pdf">Mean Field Residual Networks: On the Edge of Chaos</a></li>
          <li><a href="https://arxiv.org/pdf/1611.04231.pdf">Identity Matters in Deep Learning</a></li>
          <li><a href="http://proceedings.mlr.press/v70/pennington17a/pennington17a.pdf">Geometry of Neural Network Loss Surfaces via Random Matrix Theory</a></li>
          <li><a href="https://openreview.net/pdf?id=HkXKUTVFl">Explaining the Learning Dynamics of Direct Feedback Alignment</a></li>
          <li><a href="https://openreview.net/pdf?id=H1W1UN9gg">Deep Information Propagation</a></li>
          <li><a href="https://arxiv.org/pdf/1802.09979.pdf">The Emergence of Spectral Universality in Deep Networks</a></li>
          <li><a href="https://arxiv.org/pdf/1802.08760.pdf">Sensitivity and Generalization in Neural Networks: An Empirical Study</a></li>
          <li><a href="https://arxiv.org/pdf/1802.06093.pdf">Gradient Descent with identity initialization efficiently learns positive definite linear transformations by deep residual networks</a></li>
          <li><a href="https://openreview.net/pdf?id=B1EA-M-0Z">Deep Neural Networks as Gaussian Processes</a></li>
          <li><a href="https://openreview.net/pdf?id=BJij4yg0Z">A Bayesian Perspective on Generalization and Stochastic Gradient Descent</a></li>
        </ul>
      </li>
      <li>Regularization
        <ul>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45137.pdf">Adding Gradient Noise Improves Learning for Very Deep Networks</a></li>
          <li><a href="http://www.phillong.info/publications/HL17_deep_dropout.pdf">Surprising Properties of Dropout in Deep Networks</a></li>
          <li><a href="https://arxiv.org/pdf/1701.06548.pdf">Regularizing Neural Networks by Penalizing Confident Output Distributions</a></li>
          <li><a href="https://arxiv.org/pdf/1706.06569.pdf">A Unified Approach to Adaptive Regularization in Online and Stochastic Optimization</a></li>
        </ul>
      </li>
      <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41872.pdf">Training Highly Multiclass Classifiers</a></li>
      <li><a href="https://arxiv.org/pdf/1412.6558.pdf">Random Walk Initialization for Training Very Deep Feedforward Networks</a></li>
      <li><a href="https://arxiv.org/pdf/1312.4314.pdf">Learning Factored Representations in a Deep Mixture of Experts</a></li>
      <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43273.pdf">Training Deep Neural Networks on Noisy Labels with Bootstrapping</a></li>
      <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43455.pdf">Convolutional, Long Short-Term Memory, Fully Connected Deep Neural Networks</a></li>
      <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45580.pdf">Reward Augmented Maximum Likelihood for Neural Structured Prediction</a></li>
      <li><a href="https://arxiv.org/pdf/1511.05176v3.pdf">MuProp: Unbiased Backpropagation for Stochastic Neural Networks</a></li>
      <li><a href="https://research.google.com/pubs/pub45945.html">Chained predictions using convolutional neural networks</a></li>
      <li><a href="https://openreview.net/pdf?id=BJBkkaNYe">Training a Subsampling Mechanism in Expectation</a></li>
      <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46341.pdf">Resurrecting the Sigmoid in deep learning through dynamical isometry: theory and practice</a></li>
      <li><a href="https://openreview.net/pdf?id=B1ckMDqlg">Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer</a></li>
      <li><a href="https://research.google.com/pubs/pub46347.html">On Blackbox Backpropagation and Jacobian Sensing</a></li>
      <li><a href="https://arxiv.org/pdf/1703.04363.pdf">Deep Value Networks Learn to Evaluate and Iteratively Refine Structured Outputs</a></li>
      <li><a href="https://arxiv.org/pdf/1706.03200.pdf">Critical Hyper-Parameters: No Random, No Cry</a></li>
      <li><a href="https://arxiv.org/pdf/1711.09784.pdf">Distilling a Neural Network into a Soft Decision Tree</a></li>
      <li><a href="https://arxiv.org/pdf/1611.01144.pdf">Categorical Reparameterization with Gumbel-Softmax</a></li>
      <li><a href="https://openreview.net/pdf?id=ryiAv2xAZ">Training Confidence-Calibrated Classifiers For Detecting Out-of-Distribution Samples</a></li>
      <li><a href="https://openreview.net/pdf?id=B1X0mzZCW">Fidelity-Weighted Learning</a></li>
      <li><a href="https://openreview.net/pdf?id=B1Yy1BxCZ">Don’t Decay the Learning Rate, Increase the Batch Size</a></li>
    </ul>
  </li>
  <li>Applications
    <ul>
      <li>Speech Recognition
        <ul>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/38131.pdf">Deep Neural Networks for Acoustic Modeling in Speech Recognition</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/38130.pdf">Application of Pre-trained Deep Neural Networks to Large Vocabulary Speech Recognition</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40811.pdf">On Rectified Linear Units for Speech Processing</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40807.pdf">Multilingual Acoustic Models Using Distributed Deep Neural Networks</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40808.pdf">An Empirical Study of Learning Rates in DNNs for Speech Recognition</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42543.pdf">Word Embeddings for Speech Recognition</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42947.pdf">Autoregressive product of multi-frame predictions can improve the accuracy of hybrid models</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43960.pdf">Learning the Speech Front-end with Raw Waveform CLDNNs</a></li>
          <li><a href="http://www.cs.cmu.edu/~chanwook/MyPapers/b_li_interspeech_2017.pdf">Acoustic Modeling for Google Home</a></li>
          <li><a href="https://arxiv.org/pdf/1711.01694.pdf">Multilingual Speech Recognition With a Single End-to-End Model</a></li>
          <li><a href="https://arxiv.org/pdf/1712.01996.pdf">An Analysis of Incorporating an External Language Model into a Sequence-to-Sequence Model</a></li>
        </ul>
      </li>
      <li>Image Classification
        <ul>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42244.pdf">Using Web Co-occurrence Statistics for Improving Image Categorization</a></li>
          <li><a href="https://arxiv.org/pdf/1511.06789.pdf">The Unreasonable Effectiveness of Noisy Data for Fine-Grained Recognition</a></li>
        </ul>
      </li>
      <li>Image Captioning
        <ul>
          <li><a href="https://nlp.stanford.edu/~socherr/SocherKarpathyLeManningNg_TACL2013.pdf">Grounded Compositional Semantics for Finding and Describing Images with Sentences</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43274.pdf">Show and Tell: A Neural Image Caption Generator</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43443.pdf">Learning Semantic Relationships for Better Action Retrieval in Images</a></li>
        </ul>
      </li>
      <li>Machine Translation
        <ul>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44931.pdf">Exploiting Similarities among Languages for Machine Translation</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44929.pdf">Addressing the Rare Word Problem in Neural Machine Translation</a></li>
          <li><a href="https://arxiv.org/abs/1609.08144">Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation</a></li>
          <li><a href="https://arxiv.org/pdf/1703.08581.pdf">Sequence-to-Sequence Models Can Directly Translate Foreign Speech</a></li>
          <li><a href="https://arxiv.org/pdf/1703.03906.pdf">Massive Exploration of Neural Machine Translation Architectures</a></li>
        </ul>
      </li>
      <li>Natural Language Understanding
        <ul>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41224.pdf">Efficient Estimation of Word Representations in Vector Space</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44876.pdf">Distributed Representations of Words and Their Compositionality</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42371.pdf">Zero-Shot Learning by Convex Combination of Semantic Embeddings</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44930.pdf">Distributed Representations of Sentences and Documents</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43852.pdf">Sentence Compression by Deletion with LSTMs</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43799.pdf">Grammar as a Foreign Language</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45190.pdf">BilBOWA: Fast Bilingual Distributed Representations without Word Alignments</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45170.pdf">Multilingual Language Processing From Bytes</a></li>
          <li><a href="https://arxiv.org/pdf/1602.02410.pdf">Exploring the Limits of Language Modeling</a></li>
          <li><a href="https://arxiv.org/pdf/1612.02695.pdf">Towards better decoding and language model integration in sequence to sequence models</a></li>
          <li><a href="https://arxiv.org/pdf/1704.06877.pdf">Learning to Skim Text</a></li>
          <li><a href="https://arxiv.org/pdf/1704.04368.pdf">Get To The Point: Summarization with Pointer-Generator Networks</a></li>
          <li><a href="https://openreview.net/pdf?id=Hyg0vbWC-">Generating Wikipedia by Summarizing Long Sequences</a></li>
          <li><a href="https://openreview.net/pdf?id=rJvJXZb0W">An Efficient Framework for Learning Sentence Representations</a></li>
        </ul>
      </li>
      <li>Multi-Modal
        <ul>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41869.pdf">DeViSE: A Deep Visual-Semantic Embedding Model</a></li>
          <li><a href="https://arxiv.org/pdf/1707.00683.pdf">Modulating Early Visual Processing by Language</a></li>
          <li><a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Vedantam_Context-Aware_Captions_From_CVPR_2017_paper.pdf">Context-aware Captions from Context-agnostic Supervision</a></li>
          <li><a href="https://arxiv.org/pdf/1705.08386.pdf">Better Text Understanding Through Image-To-Text Transfer</a></li>
        </ul>
      </li>
      <li>Pedestrian Detection
        <ul>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43850.pdf">Real Time Pedestrian Detection with Deep Network Cascades</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43849.pdf">Pedestrian Detection with a Large Field-Of-View Deep Network</a></li>
        </ul>
      </li>
      <li>Grasp Detection
        <ul>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43875.pdf">Real-Time Grasp Detection Using Convolutional Neural Networks</a></li>
        </ul>
      </li>
      <li>Go
        <ul>
          <li><a href="https://arxiv.org/pdf/1412.6564.pdf">Move Evaluation in Go Using Deep Convolutional Neural Networks</a></li>
          <li><a href="https://www.nature.com/articles/nature16961">Mastering the game of Go with deep neural networks and tree search</a></li>
        </ul>
      </li>
      <li>Video
        <ul>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43793.pdf">Beyond Short Snippets: Deep Networks for Video Classification</a></li>
        </ul>
      </li>
      <li>Dialogue
        <ul>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44925.pdf">A Neural Conversational Model</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45189.pdf">Smart Reply: Automated Response Suggestion for Email</a></li>
          <li><a href="https://arxiv.org/pdf/1701.08198.pdf">Adversarial Evaluation of Dialogue Models</a></li>
          <li><a href="https://arxiv.org/pdf/1701.03185.pdf">Generating High-Quality and Informative Conversation Responses with Sequence-to-Sequence Models</a></li>
        </ul>
      </li>
      <li>3D Object Reconstruction
        <ul>
          <li><a href="https://arxiv.org/pdf/1612.00814.pdf">Perspective Transformer Nets: Learning Single-View 3D Object Reconstruction without 3D Supervision</a></li>
        </ul>
      </li>
      <li>Speaker Verification
        <ul>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44681.pdf">End-to-End Text-Dependent Speaker Verification</a></li>
        </ul>
      </li>
      <li>Health Care
        <ul>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45732.pdf">Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs</a></li>
        </ul>
      </li>
      <li>Theorem Proving
        <ul>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45402.pdf">DeepMath - Deep Sequence Models for Premise Selection</a></li>
          <li><a href="https://arxiv.org/pdf/1701.06972.pdf">Deep Network Guided Proof Search</a></li>
        </ul>
      </li>
      <li>Music
        <ul>
          <li><a href="https://18798-presscdn-pagely.netdna-ssl.com/ismir2016/wp-content/uploads/sites/2294/2016/08/ardila-audio.pdf">Audio Deepdream: Optimizing Raw Audio with Convolutional Networks</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45871.pdf">Generating Music by Fine-Tuning Recurrent Neural Networks with Reinforcement Learning</a></li>
          <li><a href="https://arxiv.org/pdf/1704.01279.pdf">Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders</a></li>
        </ul>
      </li>
      <li>Pose Estimation
        <ul>
          <li><a href="https://arxiv.org/pdf/1701.01779.pdf">Towards Accurate Multi-person Pose Estimation in the Wild</a></li>
        </ul>
      </li>
      <li>Speech Generation
        <ul>
          <li><a href="https://arxiv.org/pdf/1703.10135.pdf">Tacotron: Towards End-to-End Speech Synthesis</a></li>
          <li><a href="https://arxiv.org/pdf/1611.00068.pdf">RNN Approaches to Text Normalization: A Challenge</a></li>
          <li><a href="https://arxiv.org/pdf/1712.08363.pdf">On Using Backpropagation for Speech texture Generation and Voice Cnversion</a></li>
          <li><a href="https://arxiv.org/pdf/1712.05884.pdf">Natural TTS Synthesis by Conditioning Wavenet on Mel Spectrogram Prediction [Tacotron 2]</a></li>
        </ul>
      </li>
      <li>Super Resolution
        <ul>
          <li><a href="https://arxiv.org/pdf/1702.00783.pdf">Pixel Recursive Super Resolution</a></li>
        </ul>
      </li>
      <li>Chemistry
        <ul>
          <li><a href="https://arxiv.org/pdf/1704.01212.pdf">Neural Message Passing for Quantum Chemistry</a></li>
        </ul>
      </li>
      <li>Robotics
        <ul>
          <li>Autonomous Vehicles
            <ul>
              <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45985.pdf">Learning with Proxy Supervision for End-To-End Visual Learning</a></li>
              <li><a href="https://arxiv.org/pdf/1709.02833.pdf">Learning Robotic Manipulation of Granular Media</a></li>
              <li><a href="https://drive.google.com/file/d/0B0mFoBMu8f8BaHYzOXZMdzVOalU/view">Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection</a></li>
              <li><a href="https://arxiv.org/pdf/1707.01932.pdf">End-to-End Learning of Semantic Grasping</a></li>
              <li><a href="https://arxiv.org/pdf/1702.03920.pdf">Cognitive Mapping and Planning for Visual Navigation</a></li>
              <li><a href="https://arxiv.org/pdf/1709.07857.pdf">Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Physics
        <ul>
          <li><a href="https://arxiv.org/pdf/1607.03597.pdf">Accelerating Eulerian Fluid Simulation with Convolutional Networks</a></li>
        </ul>
      </li>
      <li>Device Placement
        <ul>
          <li><a href="https://arxiv.org/pdf/1706.04972.pdf">Device Placement Optimization with Reinforcement Learning</a></li>
          <li><a href="https://openreview.net/pdf?id=Hkc-TeZ0W">A Hierarchical Model for Device Placement</a></li>
        </ul>
      </li>
      <li>Games
        <ul>
          <li><a href="https://arxiv.org/pdf/1711.02301.pdf">Can Deep Reinforcement Learning Solve Erdos-Selfridge-Spencer Games?</a></li>
        </ul>
      </li>
      <li>Art
        <ul>
          <li><a href="https://arxiv.org/pdf/1704.03477.pdf">A Neural Representation of Sketch Drawings</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Unsupervised Learning
    <ul>
      <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/38115.pdf">Building High-level Features Using Large Scale Unsupervised Learning</a></li>
      <li><a href="https://arxiv.org/pdf/1511.06440.pdf">Towards Principled Unsupervised Learning</a></li>
      <li><a href="https://arxiv.org/pdf/1704.06888.pdf">Time-Contrastive Networks: Self-Supervised Learning from Video</a></li>
      <li><a href="https://arxiv.org/pdf/1710.11252.pdf">Stochastic Variational Video prediction [Also, Model-Based RL]</a></li>
      <li><a href="https://openreview.net/pdf?id=r1br_2Kge">Short and Deep: Sketching Neural Networks</a></li>
      <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45984.pdf">Geometry-Based Next Frame Prediction from Monocular Video</a></li>
      <li><a href="https://sites.google.com/a/umich.edu/rubenevillegas/iclr2017">Decomposing Motion and Content for Natural Video Sequence Prediction</a></li>
      <li><a href="https://openreview.net/forum?id=BJubPWZRW">Cross-View Training for Semi-Supervised Learning</a></li>
    </ul>
  </li>
  <li>Attention
    <ul>
      <li><a href="https://arxiv.org/pdf/1405.5488.pdf">On Learning Where to Look</a></li>
      <li><a href="https://arxiv.org/pdf/1506.03134.pdf">Pointer Networks</a></li>
      <li><a href="https://arxiv.org/pdf/1412.7054.pdf">Attention for Fine-Grained Categorization</a></li>
      <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44926.pdf">Listen, Attend and Spell</a></li>
      <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45395.pdf">Collective Entity Resolution with Multi-Focal Attention</a></li>
      <li><a href="https://arxiv.org/pdf/1603.08575.pdf">Attend, Infer, Repeat: Fast Scene Understanding with Generative Models</a></li>
      <li><a href="https://research.google.com/pubs/pub46110.html">Online and Linear-Time Attention by Enforcing Monotonic Alignments</a></li>
      <li><a href="https://arxiv.org/pdf/1705.05524.pdf">Learning Hard Alignments with Variational Inference [Hard Attention]</a></li>
      <li><a href="https://arxiv.org/pdf/1707.00110.pdf">Efficient Attention using a Fixed-Size Memory Representation</a></li>
      <li><a href="https://arxiv.org/pdf/1706.03762.pdf">Attention is All You Need</a></li>
      <li><a href="http://www.isca-speech.org/archive/Interspeech_2017/pdfs/0232.PDF">An Analysis of “Attention” in Sequence-to-Sequence Models</a></li>
      <li><a href="https://openreview.net/pdf?id=Hko85plCW">Monotonic Chunkwise Attention</a></li>
    </ul>
  </li>
  <li>Memory
    <ul>
      <li><a href="https://openreview.net/pdf?id=SJTQLdqlg">Learning to Remember Rare Events</a></li>
    </ul>
  </li>
  <li>Transfer Learning
    <ul>
      <li><a href="https://arxiv.org/pdf/1511.05641.pdf">Net2Net: Accelerating Learning via Knowledge Transfer</a></li>
      <li><a href="https://arxiv.org/pdf/1608.06019.pdf">Domain Separation Networks</a></li>
      <li><a href="https://arxiv.org/pdf/1612.05424.pdf">Unsupervised Pixel-Level Domain Adaptation with Generative Adversarial Networks</a></li>
      <li><a href="https://arxiv.org/pdf/1701.08734.pdf">PathNet: Evolution Channels Gradient Descent in Super Neural networks</a></li>
      <li><a href="https://arxiv.org/pdf/1706.05137.pdf">One Model to Learn Them All</a></li>
      <li><a href="https://arxiv.org/pdf/1705.06830.pdf">Exploring the structure of a real-time, arbitrary neural artistic stylization network</a></li>
      <li><a href="https://arxiv.org/pdf/1707.03979.pdf">A Brief Study of In-Domain Transfer and Learning from Fewer Samples using a Few Simple Priors</a></li>
    </ul>
  </li>
  <li>Representation Learning
    <ul>
      <li><a href="https://arxiv.org/pdf/1706.05806.pdf">SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability</a></li>
      <li><a href="https://arxiv.org/pdf/1610.07629.pdf">A Learned Representation for Artistic Style</a></li>
      <li><a href="https://openreview.net/pdf?id=Byt3oJ-0W">Learning Latent Permutations with Gumbel-Sinkhorn Networks</a></li>
    </ul>
  </li>
  <li>Reinforcemnet Learning
    <ul>
      <li>Model-Based Reinforcement Learning
        <ul>
          <li><a href="https://arxiv.org/pdf/1605.07157.pdf">Unsupervised Learning for Physical Interaction through Video Prediction [Also, Robotics]</a></li>
          <li><a href="http://proceedings.mlr.press/v48/gu16.pdf">Continuous Deep Q-Learning with Model-based Acceleration</a></li>
          <li><a href="https://arxiv.org/pdf/1707.03497.pdf">Value Prediction Network</a></li>
          <li><a href="https://arxiv.org/pdf/1704.05831.pdf">Learning to Generate Long-term Future via Hierarchical Prediction</a></li>
          <li><a href="https://arxiv.org/pdf/1705.05035.pdf">Discrete Sequential Prediction of Continuous Actions for Deep RL</a></li>
          <li><a href="https://arxiv.org/pdf/1610.00696.pdf">Deep Visual Foresight for Planning Robot Motion [Also, Robotics]</a></li>
          <li><a href="https://openreview.net/pdf?id=Skw0n-W0Z">Temporal Difference Models: Model-Free Deep RL for Model-Based Control</a></li>
          <li><a href="https://drive.google.com/file/d/1HWDyhEUpVgAiSSQtEYEGb6EIeY8YQay8/view">Learning Unsupervised Latent Dynamics Models for Multi-task Continuous Control from Pixels</a></li>
        </ul>
      </li>
      <li>Multi-Task Learning
        <ul>
          <li><a href="https://arxiv.org/pdf/1706.05064.pdf">Zero-Shot Task Generalization with Multi-Task Deep Reinforcement Learning</a></li>
        </ul>
      </li>
      <li><a href="https://openreview.net/pdf?id=Byf3mmNFl">Unsupervised Perceptual Rewards for Imitation Learning</a></li>
      <li><a href="https://arxiv.org/pdf/1707.01891.pdf">Trust-PCL: An Off-Policy Trust Region Method for Continuous Control</a></li>
      <li><a href="https://arxiv.org/pdf/1703.02702.pdf">Robust Adversarial Reinforcement Learning [Also, Multi-Agent Systems]</a></li>
      <li><a href="https://arxiv.org/pdf/1703.07370.pdf">REBAR: Low-Variance, unbiased gradient estimates for discrete latent variable models</a></li>
      <li><a href="https://arxiv.org/pdf/1611.02247.pdf">Q-Prop: Sample Efficient Policy Gradient with an Off-Policy Critic</a></li>
      <li><a href="https://openreview.net/pdf?id=BJyBKyHKg">Particle Value Functions</a></li>
      <li><a href="https://arxiv.org/pdf/1610.00529.pdf">Path Integral Guided Policy Search [Also, Robotics]</a></li>
      <li><a href="https://arxiv.org/pdf/1706.00387.pdf">Interpolated Policy Gradient: Merging On-Policy and Off-Policy Gradient Estimation for Deep Reinforcement Learning</a></li>
      <li><a href="https://openreview.net/pdf?id=ryT4pvqll">Improving Policy Gradient by Exploring Under-Appreciated Rewards</a></li>
      <li><a href="https://arxiv.org/pdf/1610.00633.pdf">Deep Reinforcement Learning for Robotic Manipulation with Asynchronous Off-Policy Updates</a></li>
      <li><a href="https://arxiv.org/pdf/1610.00673.pdf">Collective Robot Reinforcement Learning with Distributed Asynchronous Guided Policy Search</a></li>
      <li><a href="https://arxiv.org/pdf/1702.07780.pdf">Changing Model Behavior at Test Time Using Reinforcement Learning</a></li>
      <li><a href="https://arxiv.org/pdf/1702.08892.pdf">Bridging the Gap Between Value and Policy Based Reinforcement Learning</a></li>
      <li><a href="https://arxiv.org/pdf/1704.00773.pdf">A comparative study of counterfactual estimators</a></li>
      <li><a href="https://arxiv.org/pdf/1710.03937.pdf">PRM-RL: Long Range Robotic Navigation Tasks by Combining Reinforcement Learning and Sampling-based Planning</a></li>
      <li><a href="https://arxiv.org/abs/1802.03501">Path consistency Learning in Tsallis Entropy Regularized MDPs</a></li>
      <li><a href="https://openreview.net/pdf?id=S1vuO-bCW">Leave No Trace: Learning to Reset for Safe and Autonomous Reinforcement Learning</a></li>
      <li><a href="https://openreview.net/pdf?id=SyYe6k-CW">Deep Bayesian Bandits Showdown</a></li>
    </ul>
  </li>
  <li>Metalearning
    <ul>
      <li>Neural Programming
        <ul>
          <li><a href="https://research.google.com/pubs/pub45478.html">Reinforcement Learning Neural Turing Machines</a></li>
          <li><a href="https://research.google.com/pubs/pub45472.html">Neural Random-Access Machines</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44927.pdf">Neural Programmer: Inducing Latent Programs with Gradient Descent</a></li>
          <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45139.pdf">Neural GPUs Learn Algorithms</a></li>
          <li><a href="https://arxiv.org/pdf/1611.08945.pdf">Learning a Natural Language Interface with Neural Programmer</a></li>
        </ul>
      </li>
      <li>Hyperparameter Optimization
        <ul>
          <li><a href="https://arxiv.org/pdf/1706.03199.pdf">Toward Optimal Run Racing: Application to Deep Learning Calibration</a></li>
          <li><a href="https://arxiv.org/pdf/1710.05941.pdf">Searching for Activation Functions</a></li>
          <li><a href="https://arxiv.org/pdf/1709.07417.pdf">Neural Optimizer Search with Reinforcement Learning</a></li>
          <li><a href="https://openreview.net/pdf?id=Bk9mxlSFx">Neural Combinatorial Optimization with Reinforcement Learning</a></li>
          <li><a href="https://arxiv.org/pdf/1611.01578.pdf">Neural Architecture Search with Reinforcement Learning</a></li>
          <li><a href="https://arxiv.org/pdf/1703.01041.pdf">Large-Scale Evolution of Image Classifiers</a></li>
          <li><a href="https://arxiv.org/pdf/1710.05941.pdf">Searching for Activation Functions</a></li>
        </ul>
      </li>
      <li><a href="https://arxiv.org/pdf/1703.04813.pdf">Learned Optimizers that Scale and Generalize</a></li>
      <li><a href="https://openreview.net/pdf?id=rkpACe1lx">HyperNetworks</a></li>
      <li><a href="http://metalearning.ml/papers/metalearn17_metz.pdf">Supervised Learning of Unsupervised Learning Rules</a></li>
      <li><a href="https://arxiv.org/pdf/1711.06798.pdf">MorphNet: Fast &amp; Simple Resource-Constrained Structure Learning of Deep Networks</a></li>
      <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46346.pdf">A Meta-Learning Perspective on Cold-Start Recommendations for Items</a></li>
      <li><a href="https://openreview.net/pdf?id=HJcSzz-CZ">Meta-Learning for Semi-Supervised Few-Shot Classification</a></li>
      <li><a href="https://openreview.net/pdf?id=B1n8LexRZ">Generalizing Hamiltonian Monte Carlo with Neural Networks</a></li>
    </ul>
  </li>
  <li>Generative
    <ul>
      <li>GANs
        <ul>
          <li><a href="https://arxiv.org/pdf/1612.02780.pdf">Improved Generator Objectives for GANs</a></li>
          <li><a href="https://openreview.net/pdf?id=BydrOIcle">Unrolled Generative Adversarial Networks</a></li>
          <li><a href="https://arxiv.org/pdf/1709.10459.pdf">Improving Image Generative Models with Human Interactions</a></li>
          <li><a href="https://arxiv.org/pdf/1610.09585.pdf">Conditional Image Synthesis with Auxiliary Classifier GANs</a></li>
          <li><a href="https://arxiv.org/pdf/1711.10337.pdf">Are GANs Created Equal? A Large-Scale Study</a></li>
          <li><a href="https://arxiv.org/pdf/1701.02386.pdf">AdaGAN: Boosting Generative Models</a></li>
          <li><a href="https://openreview.net/pdf?id=ByOExmWAb">MaskGAN: Better Text Generation Via Filling in the _____</a></li>
          <li><a href="https://openreview.net/pdf?id=ByQpn1ZA-">Many Paths to Equilibrium: GANs Do Not Need to Decrease a Divergence at Every Step</a></li>
        </ul>
      </li>
      <li><a href="https://distill.pub/2016/handwriting/">Experiments in Handwriting with a Neural Network</a></li>
      <li><a href="https://arxiv.org/pdf/1705.07642.pdf">From optimal transport to generative modeling: the VEGAN cookbook</a></li>
      <li><a href="https://arxiv.org/pdf/1605.08803.pdf">Density Estimation Using Real NVP</a></li>
      <li><a href="https://arxiv.org/pdf/1704.03477.pdf">A Neural Representation of Sketch Drawings</a></li>
      <li><a href="https://arxiv.org/pdf/1711.01558.pdf">Wasserstein Auto-Encoders</a></li>
      <li><a href="https://openreview.net/pdf?id=rk49Mg-CW">Stochastic Variational Video Prediction</a></li>
      <li><a href="https://openreview.net/pdf?id=Sy8XvGb0-">Latent Constraints: Learning to Generate Conditionally From Unconditional Generative Models</a></li>
    </ul>
  </li>
  <li>Intrepretability
    <ul>
      <li><a href="https://distill.pub/2016/deconv-checkerboard/">Deconvolution and Checkerboard Artifacts</a></li>
      <li><a href="http://idl.cs.washington.edu/files/2018-TensorFlowGraph-VAST.pdf">Visualizing Dataflow Graphs of Deep Learning Models in Tensorflow</a></li>
      <li><a href="https://arxiv.org/pdf/1702.08608.pdf">Towards A Rigorous Science of Interpretable Machine Learning</a></li>
      <li><a href="https://arxiv.org/pdf/1711.00867.pdf">The (Un)reliability of Saliency Methods</a></li>
      <li><a href="https://arxiv.org/pdf/1611.09434.pdf">Input Switched Affine Networks: An RNN Architecture Designed for Interpretability [Also, Recurrent Neural Networks]</a></li>
      <li><a href="https://arxiv.org/abs/1611.05418">VisualBackProp: Efficient Visualization of CNNs</a></li>
      <li><a href="https://openreview.net/pdf?id=Hkn7CBaTW">Learning How to Explain Neural Networks: PatternNet and PatternAttribution</a></li>
      <li><a href="https://openreview.net/pdf?id=rkRwGg-0Z">Beyond Word Importance: Contextual Decomposition to Extract Interactions from LSTMs [Also, Recurrent Neural Networks]</a></li>
    </ul>
  </li>
  <li>Tools, Environments &amp; Datasets
    <ul>
      <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41880.pdf">One Billion Word Benchmark for Measuring Progress in Statistical Language Modeling</a></li>
    </ul>
  </li>
  <li>Adversarial Examples
    <ul>
      <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42503.pdf">Intriguing Properties of Neural Networks</a></li>
      <li><a href="https://arxiv.org/pdf/1412.6572.pdf">Explaining and Harnessing Adversarial Examples</a></li>
      <li><a href="https://research.google.com/pubs/pub45403.html">Virtual Adversarial Training for Semi-Supervised Text Classification</a></li>
      <li><a href="https://arxiv.org/pdf/1704.03453.pdf">The Space of Transferable Adversarial Examples</a></li>
      <li><a href="https://arxiv.org/pdf/1607.02533.pdf">Adversarial Examples in the Physical World</a></li>
      <li><a href="https://arxiv.org/pdf/1605.07725.pdf">Adversarial Training Methods for Semi-Supervised Text Classification</a></li>
      <li><a href="https://arxiv.org/pdf/1611.01236.pdf">Adversarial Machine Learning at Scale</a></li>
      <li><a href="https://openreview.net/pdf?id=S18Su--CW">Thermometer Encoding: One Hot Way to Resist Adversarial Examples</a></li>
      <li><a href="https://arxiv.org/pdf/1711.02846.pdf">Intriguing Properties of Adversarial Examples</a></li>
      <li><a href="https://openreview.net/pdf?id=rkZvSe-RZ">Ensemble Adversarial Training: Attacks and Defences</a></li>
      <li><a href="https://arxiv.org/pdf/1801.02774.pdf">Adversarial Spheres</a></li>
    </ul>
  </li>
  <li>Multi-Agent Systems
    <ul>
      <li><a href="https://arxiv.org/pdf/1610.06918.pdf">Learning to Protect Communications with Adversarial Neural Cryptography</a></li>
      <li><a href="https://arxiv.org/pdf/1511.05644.pdf">Adversarial Autoencoders</a></li>
      <li><a href="https://arxiv.org/pdf/1711.05139.pdf">XGAN: Unsupervised Image-To-Image Translation for Many-To-Many Mappings</a></li>
      <li><a href="https://arxiv.org/pdf/1610.01685.pdf">Supervision via Competition: Robot Adversaries for Learning Tasks</a></li>
    </ul>
  </li>
  <li>Variational Inference
    <ul>
      <li><a href="https://arxiv.org/pdf/1611.06585.pdf">Variational Boosting: Iteratively Refining Posterior Approximations</a></li>
      <li><a href="https://arxiv.org/pdf/1705.07880.pdf">Reducing Reparameterization Gradient Variance</a></li>
      <li>Filtering Variational Objectives</li>
    </ul>
  </li>
  <li>Kernel Machines
    <ul>
      <li><a href="http://www-cs.stanford.edu/~quocle/LeSarlosSmola_ICML13.pdf">Fastfood - Approximating Kernel Expansions in Loglinear Time</a></li>
      <li><a href="https://arxiv.org/pdf/1703.07872.pdf">Random Features for Compositional Kernels</a></li>
      <li><a href="http://storage.googleapis.com/pub-tools-public-publication-data/pdf/70a89b15f9b160dd10248de8862d1584f03ddc22.pdf">The Geometry of Random Features</a></li>
    </ul>
  </li>
  <li>Collaborative Filtering
    <ul>
      <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42242.pdf">Local Collaborative Ranking</a></li>
    </ul>
  </li>
  <li>Graphical / Relational Learning
    <ul>
      <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42854.pdf">Large-Scale Object Classification Using Label Relation Graphs</a></li>
      <li><a href="http://drops.dagstuhl.de/opus/volltexte/2015/4902/pdf/2.pdf">Graph Searching Games and Width Measures for Directed Graphs</a></li>
      <li><a href="https://arxiv.org/pdf/1803.06272.pdf">Graph Partition Neural Networks for Semi-Supervised Classification</a></li>
    </ul>
  </li>
  <li>Miscellaneous
    <ul>
      <li><a href="https://dl.acm.org/citation.cfm?id=2976746">Tensorflow: Learning Functions at Scale</a></li>
      <li><a href="https://papers.nips.cc/paper/6315-deep-learning-games.pdf">Deep Learning Games</a></li>
      <li><a href="https://arxiv.org/pdf/1711.02712.pdf">Tangent: Automatic Differentiation Using Source Code Transformation in Python</a></li>
      <li><a href="http://www.aceslab.org/sites/default/files/main_0.pdf">ExtDict: Extensible Dictionaries for Data and Platform-Aware Large Scale Learning</a></li>
      <li><a href="https://research.google.com/pubs/pub46351.html">Dynamic Routing between Capsules</a></li>
      <li><a href="https://arxiv.org/pdf/1706.02733.pdf">Climbing a Shaky Ladder: Better ADaptive Risk Estimation</a></li>
      <li><a href="https://arxiv.org/pdf/1706.02744.pdf">Avoiding Discrimination through Causal Reasoning</a></li>
      <li><a href="https://arxiv.org/pdf/1703.08774.pdf">Who Said What: Modeling Individual Labelers Improves Classification</a></li>
      <li><a href="https://openreview.net/pdf?id=HJWLfGWRb">Matrix Capsules with EM Routing</a></li>
      <li><a href="http://storage.googleapis.com/pub-tools-public-publication-data/pdf/7174df3a5627e483b5d120d8edb5843fa593577e.pdf">Graph sketching-based Space-efficient Data Clustering</a></li>
    </ul>
  </li>
</ol>

<p>Major Researchers [10+ Papers / Founding]</p>
<ul>
  <li>Jeff Dean</li>
  <li>Samy Bengio</li>
  <li>Geoffrey Hinton</li>
  <li><del>Andrew Ng</del></li>
  <li>Quoc Le</li>
  <li>Greg Corrado</li>
  <li>Vincent Vanhoucke</li>
  <li>Yoran Singer</li>
  <li>Ian Goodfellow</li>
  <li><del>Tomas Mikolov</del></li>
  <li><del>Ilya Sutskever</del></li>
  <li><del>Oriol Vinyals</del></li>
  <li><del>Marc’ Aurelio Ranzato</del></li>
  <li>Christian Szegedy</li>
  <li>Navdeep Jaitly</li>
  <li>Mohammad Norouzi</li>
  <li>Lukasz Kaiser</li>
  <li>Jonathon Shlens</li>
</ul>

<p>Minor Researchers</p>
<ul>
  <li>Rajat Monga</li>
  <li>Kai Chen</li>
  <li>Matthieu Devin</li>
  <li>Mark Mao</li>
  <li>Andrew Senior</li>
  <li>Paul Tucker</li>
  <li>Ke Yang</li>
  <li>Patrick Nguyen</li>
  <li>Dumitru Erhan</li>
  <li>Eugene Ie</li>
  <li>Andrew Rabinovich</li>
  <li>Jon Shlens</li>
  <li>Yoram Singer</li>
  <li>Ciprian Chelba</li>
  <li>Mike Schuster</li>
  <li>Qi Ge</li>
  <li>Thorsten Brants</li>
  <li>Tamas Sarlos</li>
  <li>Georg Heigold</li>
  <li>Andrea Frome</li>
  <li>Maya Gupta</li>
  <li>David Sussillo</li>
  <li>Dragonir Anguelov</li>
  <li>Alexander Toshev</li>
  <li>Andrew Dai</li>
  <li>Anelia Angelova</li>
  <li>Alex Krizhevsky</li>
  <li>Lucasz Kaiser</li>
  <li>Terry Koo</li>
  <li>Slav Petrov</li>
  <li>Tara Sainath</li>
  <li>Hasim Sak</li>
  <li>Pierre Sermanet</li>
  <li>Esteban Real</li>
  <li>Peter Liu</li>
  <li>Sergey Levine</li>
  <li>Amit Daniely</li>
  <li>Roy Frostig</li>
  <li>Martin Abadi</li>
  <li>Zhifeng Chen</li>
  <li>Yonghui Wu</li>
  <li>Dale Schuurmans</li>
  <li>Jianmin Chen</li>
  <li>Rafal Jozefowicz</li>
  <li>Sergey Ioffe</li>
  <li>Honglak Lee</li>
  <li>Manjunath Kudlur</li>
  <li>Karol Kurach</li>
  <li>Minh-Thang Luong</li>
  <li>John Nahm</li>
  <li>Alexander Alemi</li>
  <li>Jascha Sohl-Dckstein</li>
  <li>Noam Shazeer</li>
  <li>David Ha</li>
  <li>Shan Carter</li>
  <li>Chris Olah</li>
  <li>Ignacio Moreno</li>
  <li>Douglas Eck</li>
  <li>Natasha Jaques</li>
  <li>Shixiang Gu</li>
  <li>Konstantinos Bousmalis</li>
  <li>Francois Chollet</li>
  <li>Geoffrey Irving</li>
  <li>Amarnag Subramanya</li>
  <li>Michael Ringgaard</li>
  <li>Fernando Pereira</li>
  <li>Adam Roberts</li>
  <li>Cinjon Resnick</li>
  <li>Anjuli Kannan</li>
  <li>Ryan Adams</li>
  <li>David Dohan</li>
  <li>Luke Metz</li>
  <li>Kelvin Xu</li>
  <li>Jan Chorowski</li>
  <li>Colin Raffel</li>
  <li>Dieterich Lawson</li>
  <li>George Papandreou</li>
  <li>Kevin Murphy</li>
  <li>Jonathan Tompson</li>
  <li>Olivier Bousquet</li>
  <li>Sylvain Gelly</li>
  <li>Olivier Teytaud</li>
  <li>Damien Vincent</li>
  <li>Eric Jang</li>
  <li>Jasmine Hsu</li>
  <li>Been Kim</li>
  <li>Bart van Merrienboer</li>
  <li>Alexander Wiltschko</li>
  <li>Dan Moldovan</li>
  <li>Yuxuan Wang</li>
  <li>RJ Skerry-Ryan</li>
  <li>James Davidson</li>
  <li>Ron Weiss</li>
  <li>Jan Chorowski</li>
  <li>Yonghui Wu</li>
  <li>Zhifeng Chen</li>
  <li>Kunal Talwar</li>
  <li>Barret Zoph</li>
  <li>Maithra Raghu</li>
  <li>Justin Gilmer</li>
  <li>Jeffrey Pennington</li>
  <li>Samuel Schoenholz</li>
  <li>Gabriel Pereyra</li>
  <li>George Tucker</li>
  <li>Vineet Gupta</li>
  <li>Ryan Dahl</li>
  <li>Azalia Mirhoseini</li>
  <li>Andy Davis</li>
  <li>Ashish Vaswani</li>
  <li>Krzysztof Maziarz</li>
  <li>Vikas Sindhwani</li>
  <li>Irwan Bello</li>
  <li>Hugo Larochelle</li>
  <li>Vijay Vasudevan</li>
  <li>Hieu Pham</li>
  <li>Jesse Engel</li>
  <li>Denny Britz</li>
  <li>Anna Goldie</li>
  <li>Connor Schenck</li>
  <li>Ruben Villegas</li>
  <li>Yuliang Zou</li>
  <li>Sungryull Sohn</li>
  <li>Danijar Hafner</li>
  <li>Alex Irpan</li>
  <li>James Davidson</li>
  <li>Chung-Cheng Chiu</li>
  <li>Kevin Swersky</li>
  <li>Olga Wichrowska</li>
  <li>Jakob Forester</li>
  <li>Andrew Lampinen</li>
  <li>David So</li>
  <li>Fred Bertsch</li>
  <li>Reza Mahjourian</li>
  <li>Yasaman Bahri</li>
  <li>Ofir Nachum</li>
  <li>Melody Guan</li>
  <li>Julian Ibarz</li>
  <li>Benoit Steiner</li>
  <li>Rasmus Larsen</li>
  <li>Ethan Holly</li>
  <li>Gal Chechik</li>
  <li>Augustus Odena</li>
  <li>Christopher Olah</li>
  <li>Jasmine Collins</li>
  <li>Michal Jastrzebski</li>
  <li>Philip Haeusser</li>
  <li>Mario Lucic</li>
  <li>Richard Sproat</li>
  <li>Alexey Kurakin</li>
  <li>Takeru Miyato</li>
  <li>Kristofer Schlachter</li>
  <li>Tomer Koren</li>
  <li>Ayush Sekhari</li>
  <li>Matthew Kelcey</li>
  <li>Laura Downs</li>
</ul>

<p>Genealogy
Founding Teams</p>
<ul>
  <li>Jeff Dean</li>
  <li>Samy Bengio</li>
  <li>Geoffrey Hinton</li>
  <li><del>Andrew Ng</del></li>
  <li>Quoc Le</li>
  <li>Greg Corrado</li>
  <li>Vincent Vanhoucke</li>
  <li>Yoran Singer</li>
  <li>Ian Goodfellow</li>
  <li><del>Tomas Mikolov</del></li>
  <li><del>Rajat Monga</del></li>
  <li>Kai Chen (Brain NY)</li>
  <li>Matthieu Devin</li>
  <li>Mark Mao</li>
  <li><del>Marc’ Aurelio Ranzato (Brain NY)</del></li>
  <li>Andrew Senior</li>
  <li>Paul Tucker</li>
  <li>Ke Yang</li>
  <li>Patrick Nguyen</li>
  <li>Yoram Singer</li>
  <li>Dzmitry Bahdanau</li>
</ul>

<p>In the early days, the exploration was mainly in scaling deep learning and discovering new applications to speech recognition, image categorization and language modeling.</p>

<p>Tensorflowers: Mart´ın Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Mane, Rajat Monga, Sherry Moore, Derek Murray, ´ Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viegas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng</p>

<p>Massive acceleration of Brain papers into ICLR 2016… Tensorflowers start making their way onto papers.</p>

<p>Noisy Counts (Scraped)</p>

<p>[29, ‘Oriol Vinyals’],
[27, ‘Samy Bengio’],
[23, ‘Ilya Sutskever’],
[20, ‘Navdeep Jaitly’],
[16, ‘Sergey Levine’],
[14, ‘Mohammad Norouzi’],1
[14, ‘Ian Goodfellow’],
[13, ‘Lukasz Kaiser’],
[13, ‘Jonathon Shlens’],
[12, ‘Vincent Vanhoucke’],
[10, ‘Quoc Le’],
[10, ‘Geoffrey Hinton’],
[9, ‘Dumitru Erhan’],
[8, ‘Shixiang Gu’],
[8, ‘Rajat Monga’],
[8, ‘Honglak Lee’],
[8, ‘Greg Corrado’],
[8, ‘Christian Szegedy’],
[8, ‘Andrew Senior’],
[7, ‘Yoram Singer’],
[7, ‘Tomas Mikolov’],
[7, ‘Sylvain Gelly’],
[7, ‘Olivier Bousquet’],
[7, ‘Karol Kurach’],
[7, ‘Georg Heigold’],
[7, ‘Anelia Angelova’],
[6, ‘Zhifeng Chen’],
[6, ‘Rafal Jozefowicz’],
[6, ‘Ofir Nachum’],
[6, ‘Matthieu Devin’],
[6, ‘Martin Abadi’],
[6, ‘James Davidson’],
[6, ‘Dieterich Lawson’],
[6, ‘Dale Schuurmans’],
[5, ‘Yonghui Wu’],
[5, ‘Yonghui Wu’],
[5, ‘Tara Sainath’],
[5, ‘Mike Schuster’],
[5, ‘Manjunath Kudlur’],
[5, ‘Kevin Murphy’],
[5, ‘Justin Gilmer’],
[5, ‘George Tucker’],
[5, ‘Douglas Eck’],
[4, ‘Pierre Sermanet’],
[4, ‘Noam Shazeer’],
[4, ‘Maithra Raghu’],
[4, ‘Kunal Talwar’],
[4, ‘Kelvin Xu’],
[4, ‘Kai Chen’],
[4, ‘Jeff Dean’],
[4, ‘Jan Chorowski’],
[4, ‘Geoffrey Irving’],
[4, ‘David Sussillo’],
[4, ‘David Ha’],
[4, ‘Colin Raffel’],
[4, ‘Chris Olah’],
[4, ‘Andrea Frome’],
[4, ‘Amit Daniely’],
[4, ‘Alexander Toshev’],
[3, ‘Vikas Sindhwani’],
[3, ‘Vijay Vasudevan’],
[3, ‘Tomer Koren’],
[3, ‘Paul Tucker’],
[3, ‘Patrick Nguyen’],
[3, ‘Olivier Teytaud’],
[3, ‘Natasha Jaques’],
[3, ‘Konstantinos Bousmalis’],
[3, ‘Julian Ibarz’],
[3, ‘Jonathan Tompson’],
[3, ‘Jeffrey Pennington’],
[3, ‘Hasim Sak’],
[3, ‘Denny Britz’],
[3, ‘Damien Vincent’],
[3, ‘Benoit Steiner’],
[3, ‘Barret Zoph’],
[3, ‘Azalia Mirhoseini’],
[3, ‘Augustus Odena’],
[3, ‘Andy Davis’],
[3, ‘Andrew Rabinovich’],
[3, ‘Alex Krizhevsky’],
[2, ‘Vineet Gupta’],
[2, ‘Sergey Ioffe’],
[2, ‘Ryan Dahl’],
[2, ‘Ruben Villegas’],
[2, ‘Roy Frostig’],
[2, ‘Peter Liu’],
[2, ‘Melody Guan’],
[2, ‘Luke Metz’],
[2, ‘Ke Yang’],
[2, ‘Jianmin Chen’],
[2, ‘Irwan Bello’],
[2, ‘Hugo Larochelle’],
[2, ‘Hieu Pham’],
[2, ‘Fred Bertsch’],
[2, ‘Francois Chollet’],
[2, ‘Esteban Real’],
[2, ‘Eric Jang’],
[2, ‘Cinjon Resnick’],
[2, ‘Been Kim’],
[2, ‘Ashish Vaswani’],
[2, ‘Anna Goldie’],
[2, ‘Anjuli Kannan’],
[2, ‘Andrew Dai’],
[2, ‘Amarnag Subramanya’],
[2, ‘Alexey Kurakin’],
[2, ‘Adam Roberts’],
[1, ‘Yuxuan Wang’],
[1, ‘Yuliang Zou’],
[1, ‘Yasaman Bahri’],
[1, ‘Thorsten Brants’],
[1, ‘Terry Koo’],
[1, ‘Tamas Sarlos’],
[1, ‘Takeru Miyato’],
[1, ‘Sungryull Sohn’],
[1, ‘Slav Petrov’],
[1, ‘Shan Carter’],
[1, ‘Ryan Adams’],
[1, ‘Richard Sproat’],
[1, ‘Reza Mahjourian’],
[1, ‘Rasmus Larsen’],
[1, ‘RJ Skerry-Ryan’],
[1, ‘Qi Ge’],
[1, ‘Philip Haeusser’],
[1, ‘Olga Wichrowska’],
[1, ‘Michal Jastrzebski’],
[1, ‘Mark Mao’],
[1, ‘Krzysztof Maziarz’],
[1, ‘Kristofer Schlachter’],
[1, ‘Kevin Swersky’],
[1, ‘Jesse Engel’],
[1, ‘Jasmine Hsu’],
[1, ‘Jasmine Collins’],
[1, ‘Ignacio Moreno’],
[1, ‘George Papandreou’],
[1, ‘Gal Chechik’],
[1, ‘Gabriel Pereyra’],
[1, ‘Fernando Pereira’],
[1, ‘Eugene Ie’],
[1, ‘Ethan Holly’],
[1, ‘David Dohan’],
[1, ‘Danijar Hafner’],
[1, ‘Dan Moldovan’],
[1, ‘Connor Schenck’],
[1, ‘Ciprian Chelba’],
[1, ‘Chung-Cheng Chiu’],
[1, ‘Christopher Olah’],
[1, ‘Ayush Sekhari’],
[1, ‘Andrew Ng’],
[1, ‘Andrew Lampinen’],
[1, ‘Alex Irpan’],</p>

