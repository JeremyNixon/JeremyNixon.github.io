<p>By Jeremy Nixon [<a href="mailto:jnixon2@gmail.com">jnixon2@gmail.com</a>]. Nov. 2017. Updated June 2018.</p>

<p>Overview</p>
<ol>
  <li>Deepmind Paper Framing</li>
  <li>Deepmind Papers through Framing</li>
  <li>Current Frontier</li>
  <li>Examples of Systems Neuroscience Inspiration</li>
</ol>

<p>Deepmind Papers
Categories of the path to date:</p>
<ol>
  <li>Transfer Learning</li>
  <li>Multi-task Learning</li>
  <li>Tools, Environment &amp; Datasets</li>
  <li>Intuitive Physics</li>
  <li>Reinforcement Learning
    <ul>
      <li>Model-based RL</li>
      <li>Exploration in RL</li>
    </ul>
  </li>
  <li>Applications</li>
  <li>Safety</li>
  <li>Deep Learning
    <ul>
      <li>RNNs</li>
      <li>CNNs</li>
    </ul>
  </li>
  <li>Generative Models</li>
  <li>Variational Inference</li>
  <li>Unsupervised Learning</li>
  <li>Representation Learning</li>
  <li>Attention</li>
  <li>Memory</li>
  <li>Multi-Agent Systems</li>
  <li>Imitation Learning</li>
  <li>Metalearning
    <ul>
      <li>Neural Programming</li>
    </ul>
  </li>
  <li>Evolution</li>
  <li>Game Theory</li>
  <li>Natural Language Processing</li>
  <li>Multi-Modal Learning</li>
  <li>General Machine Learning</li>
  <li>Theory</li>
  <li>Miscellaneous</li>
  <li>Neuroscience</li>
</ol>

<p>Papers:</p>
<ol>
  <li>Transfer Learning
    <ul>
      <li><a href="https://arxiv.org/pdf/1707.08475.pdf">DARLA: Improving Zero-Shot Transfer In Reinforcement Learning</a></li>
      <li><a href="https://arxiv.org/pdf/1701.08734.pdf">PathNet: Evolution Channels Gradient Descent in Super Neural Networks</a></li>
      <li><a href="https://arxiv.org/abs/1606.04080">Matching Networks for One Shot Learning</a></li>
      <li><a href="https://arxiv.org/pdf/1606.04671.pdf">Progressive Neural Networks</a></li>
      <li><a href="https://arxiv.org/pdf/1610.04286.pdf">Sim-to-Real Robot Learning from Pixels with Progressive Nets</a></li>
      <li><a href="https://arxiv.org/pdf/1606.05312.pdf">Successor Features for Transfer in Reinforcement Learning</a></li>
    </ul>
  </li>
  <li>Multi-Task Learning
    <ul>
      <li><a href="https://arxiv.org/pdf/1708.07860.pdf">Multi-task Self-Supervised Visual Learning</a></li>
      <li><a href="https://arxiv.org/pdf/1707.03300.pdf">The Intentional Unintentional Agent: Learning to Solve Many Continuous Control Tasks Simultaneously</a></li>
      <li><a href="https://arxiv.org/pdf/1707.04175.pd">Distral: Robust Multitask Reinforcement Learning</a></li>
      <li><a href="https://arxiv.org/pdf/1707.02286.pdf">Emergence of Locomotion Behaviors in Rich Environments</a></li>
      <li><a href="https://arxiv.org/pdf/1611.05397.pdf">Reinforcement Learning with Unsupervised Auxiliary Tasks</a></li>
      <li><a href="https://arxiv.org/pdf/1611.03673.pdf">Learning to Navigate in Complex Environments</a></li>
      <li><a href="https://arxiv.org/pdf/1610.05182.pdf">Learning and Transfer of Modulated Locomotor Controllers</a></li>
      <li><a href="https://arxiv.org/pdf/1511.06114v3.pdf">Multi-Task Sequence to Sequence Learning</a></li>
      <li><a href="https://arxiv.org/abs/1802.10567">Learning by Playing - Solving Sparse Reward Tasks from Scratch</a></li>
      <li><a href="https://arxiv.org/abs/1802.08294">Unicorn: Continual Learning with a Universal, Off-policy Agent</a></li>
      <li><a href="https://arxiv.org/abs/1805.06370">Progress &amp; Compress: A Scalable Framework for Continual Learning</a></li>
    </ul>
  </li>
  <li>Tools, Environments, Evaluation &amp; Datasets
    <ul>
      <li><a href="https://arxiv.org/pdf/1708.04782.pdf">Starcraft II: A New Challenge for Reinforcement Learning</a></li>
      <li><a href="https://arxiv.org/pdf/1612.03801.pdf">DeepMind Lab</a></li>
      <li><a href="https://arxiv.org/pdf/1705.06950.pdf">The Kinetics Human Action Video Dataset</a></li>
      <li><a href="https://arxiv.org/pdf/1109.5951v2.pdf">An approximation of the Universal Intelligence Measure</a></li>
      <li><a href="https://arxiv.org/abs/1801.08116">Psychlab: A Psychology Laboratory for Deep Reinforcement Learning</a></li>
      <li><a href="https://arxiv.org/pdf/1801.00690v1.pdf">Deepmind Control Suite</a></li>
      <li><a href="https://arxiv.org/pdf/1705.07750.pdf">Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset</a></li>
    </ul>
  </li>
  <li>Intuitive Physics
    <ul>
      <li><a href="https://arxiv.org/pdf/1705.09805.pdf">Position-Velocity Encoders for Unsupervised Learning of Structured State Representations</a></li>
      <li><a href="https://arxiv.org/pdf/1611.01843.pdf">Learning to Perform Physics Experiments via Deep Reinforcement Learning</a></li>
      <li><a href="https://arxiv.org/pdf/1509.02971v2.pdf">Continuous Control with Deep Reinforcement Learning</a></li>
    </ul>
  </li>
  <li>Reinforcement Learning (Papers with a pure RL focus)
    <ul>
      <li>Model-Based RL
        <ul>
          <li><a href="https://arxiv.org/pdf/1707.06170.pdf">Learning Model-Based Planning from Scratch [Also, Planning]</a></li>
          <li><a href="https://arxiv.org/pdf/1704.02254.pdf">Recurrent Environment Simulators</a></li>
          <li><a href="https://arxiv.org/pdf/1706.06827.pdf">Structure Learning in Motor Control: A Deep Reinforcement Learning Model [Also Transfer, Intuitive Physics]</a></li>
          <li><a href="https://arxiv.org/abs/1707.06203">Imagination-Augmented Agents for Deep Reinforcement Learning [Also, Planning]</a></li>
          <li><a href="https://arxiv.org/abs/1603.00748">Continuous Deep Q-Learning with Model-based Acceleration</a></li>
          <li><a href="http://proceedings.mlr.press/v32/bellemare14.pdf">Skip Context Tree Switching</a></li>
          <li><a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Publications_files/bafa.pdf">Bayes-Adaptive Simulation-Based Search with Value Function Approximation</a></li>
          <li><a href="https://arxiv.org/abs/1802.03006">Learning and Querying Fast Generative Models for Reinforcement Learning</a></li>
        </ul>
      </li>
      <li>Exploration in RL
        <ul>
          <li><a href="https://arxiv.org/pdf/1703.01310.pdf">Count-Based Exploration with Neural Density Models</a></li>
          <li><a href="https://arxiv.org/abs/1606.01868">Unifying Count-Based Exploration and Intrinsic Motivation</a></li>
          <li><a href="https://arxiv.org/abs/1602.04621">Deep Exploration via Bootstrapped DQN</a></li>
          <li><a href="https://arxiv.org/pdf/1611.07507.pdf">Variational Intrinsic Control</a></li>
          <li><a href="https://arxiv.org/abs/1802.04697v1">Learning to Search with MCTSnets</a></li>
          <li><a href="https://arxiv.org/abs/1805.11593">Observe and Look Further: Achieving Consistent Performance on Atari</a></li>
        </ul>
      </li>
      <li><a href="https://arxiv.org/pdf/1707.06887.pdf">A Distributional Perspective on Reinforcement Learning</a></li>
      <li><a href="https://arxiv.org/pdf/1703.01161.pdf">FeUdal Networks for Hierarchical Reinforcement Learning [Also, Planning]</a></li>
      <li><a href="https://arxiv.org/pdf/1611.01626.pdf">Combining Policy Gradient and Q-Learning</a></li>
      <li><a href="https://arxiv.org/pdf/1606.04695.pdf">Strategic Attentive Writer for Learning Macro-Actions</a></li>
      <li><a href="https://arxiv.org/abs/1606.02647">Safe and Efficient Off-Policy Reinforcement Learning</a></li>
      <li><a href="https://arxiv.org/pdf/1610.00633.pdf">Deep Reinforcement Learning for Robotic Manipulation with Asynchronous Off-Policy Updates</a></li>
      <li><a href="https://arxiv.org/pdf/1602.07905.pdf">Thompson Sampling is Asymptotically Optimal in General Environments</a></li>
      <li><a href="https://arxiv.org/abs/1602.01783">Asynchronous Methods for Deep Reinforcement Learning</a></li>
      <li><a href="https://arxiv.org/abs/1511.06581">Dueling Network Architectures for Deep Reinforcement Learning</a></li>
      <li><a href="https://arxiv.org/abs/1512.04860">Increasing the Action Gap: New Operators for Reinforcement Learning</a></li>
      <li><a href="https://arxiv.org/abs/1509.06461">Deep Reinforcement Learning with Double Q-Learning</a></li>
      <li><a href="https://arxiv.org/pdf/1511.06295.pdf">Policy Distillation</a></li>
      <li><a href="http://proceedings.mlr.press/v37/schaul15.pdf">Universal Value Function Approximators</a></li>
      <li><a href="https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf">Human-level Control through Deep Reinforcement Learning</a></li>
      <li><a href="https://arxiv.org/pdf/1510.09142v1.pdf">Learning Continuous Control Policies by Stochastic Value Gradients</a></li>
      <li><a href="http://proceedings.mlr.press/v37/heinrich15.pdf">Fictitious Self-Play in Extensive Form Games</a></li>
      <li><a href="http://proceedings.mlr.press/v38/li15b.html">Toward Minimax Off-policy Value Estimation</a></li>
      <li><a href="https://arxiv.org/pdf/1507.04296.pdf">Massively Parallel Methods for Deep Reinforcement Learning</a></li>
      <li><a href="https://arxiv.org/pdf/1411.5326v1.pdf">Compress and Control</a></li>
      <li><a href="http://proceedings.mlr.press/v32/silver14.pdf">Deterministic Policy Gradient Algorithms</a></li>
      <li><a href="https://arxiv.org/pdf/1312.5602v1.pdf">Playing Atari with Deep Reinforcement Learning</a></li>
      <li><a href="http://www.sciencedirect.com/science/article/pii/S2352154615001151">Reinforcement Learning, Efficient Coding, and the Statistics of Natural Tasks</a></li>
      <li><a href="https://arxiv.org/abs/1710.02298">Rainbow: Combining Improvements in Deep Reinforcement Learning</a></li>
      <li><a href="https://arxiv.org/abs/1802.03501">Path Consistency Learning in Tsallis Entropy Regularized MDPs</a></li>
      <li><a href="https://arxiv.org/abs/1802.03493">More Robust Doubly Robust Off-Policy Evaluation</a></li>
      <li><a href="https://arxiv.org/abs/1802.01561">IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures</a></li>
      <li><a href="https://arxiv.org/abs/1806.01780">Mis&amp;Match - Agent Curricula for Reinforcement Learning</a></li>
      <li><a href="https://www.nature.com/articles/s41586-018-0102-6.epdf?">Vector-based Navigation Using Grid-Like Representations in Artificial Agents</a></li>
      <li><a href="https://arxiv.org/abs/1803.03835">Kickstarting Deep Reinforcement Learning</a></li>
    </ul>
  </li>
  <li>Applications
    <ul>
      <li>Go
        <ul>
          <li><a href="https://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf">Mastering the Game of Go with Deep Neural Networks and Tree Search</a></li>
          <li><a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Publications_files/deepgo.pdf">More Evaluation in Go using Deep Convolutional Neural Networks [Also, Convolutional Neural Networks]</a></li>
          <li><a href="https://www.nature.com/articles/nature24270.epdf?">Mastering the Game of Go Without Human Knowledge</a></li>
        </ul>
      </li>
      <li>Poker
        <ul>
          <li><a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Publications_files/smooth_uct.pdf">Smooth UCT Search in Computer Poker</a></li>
        </ul>
      </li>
      <li>Fairness
        <ul>
          <li><a href="https://arxiv.org/pdf/1802.08139.pdf">Path-Specific Counterfactual Fairness</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Safety / Security
    <ul>
      <li><a href="https://arxiv.org/pdf/1705.08417.pdf">Reinforcement Learning with a Corrupted Reward Channel [Also, Safety]</a></li>
      <li><a href="https://intelligence.org/files/Interruptibility.pdf">Safely Interruptible Agents [Also, Safety]</a></li>
      <li><a href="https://arxiv.org/abs/1711.09883">AI Safety Gridworlds</a></li>
      <li><a href="https://arxiv.org/abs/1802.05666">Adversarial Risk and the Dangers of Evaluating Against Weak Attacks</a></li>
      <li><a href="https://arxiv.org/abs/1801.08757">Safe Exploration in Continuous Action Spaces</a></li>
      <li><a href="https://arxiv.org/abs/1806.01186">Measuring and Avoiding Side Effects Using Relative Reachability</a></li>
    </ul>
  </li>
  <li>Deep Learning
    <ul>
      <li>Recurrent Neural Networks
        <ul>
          <li><a href="https://arxiv.org/abs/1605.07571">Sequential Neural Models with Stochastic Layers [Also, Planning]</a></li>
          <li><a href="https://arxiv.org/abs/1606.03401">Memory-Efficient Backpropagation Through Time</a></li>
          <li><a href="https://arxiv.org/abs/1603.08983">Adaptive Computation Time for Recurrent Neural Networks</a></li>
          <li><a href="https://arxiv.org/pdf/1507.01526v3.pdf">Grid Long-Short Term Memory</a></li>
          <li><a href="https://arxiv.org/pdf/1511.06391v3.pdf">Order Matters: Sequence to Sequence for Sets</a></li>
        </ul>
      </li>
      <li>Convolutional Neural Networks
        <ul>
          <li><a href="https://arxiv.org/abs/1602.02660">Exploiting Cyclic Symmetry in Convolutional Neural Networks</a></li>
          <li><a href="https://arxiv.org/pdf/1506.02025.pdf">Spatial Transformer Networks</a></li>
          <li><a href="https://arxiv.org/pdf/1409h.1556v6.pdf">Very Deep Convolutional Networks for Large Scale Image Recognition</a></li>
          <li><a href="https://arxiv.org/abs/1804.04438">Pooling is Neither Necessary Nor Sufficient for Appropriate Deformation Stability in CNNs</a></li>
        </ul>
      </li>
      <li><a href="https://arxiv.org/pdf/1706.10295.pdf">Noisy Networks for Exploration</a></li>
      <li><a href="https://arxiv.org/abs/1706.04859">Sobolev Training for Neural Networks</a></li>
      <li><a href="https://arxiv.org/pdf/1608.05343.pdf">Decoupled Neural Interfaces using Synthetic Gradients</a></li>
      <li><a href="https://arxiv.org/pdf/1703.00522.pdf">Understanding Synthetic Gradients and Decoupled Neural Interfaces</a></li>
      <li><a href="https://arxiv.org/pdf/1612.01474.pdf">Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles</a></li>
      <li><a href="https://arxiv.org/pdf/1612.00796.pdf">Overcoming Catastrophic Forgetting in Neural Networks</a></li>
      <li><a href="https://arxiv.org/pdf/1611.06310.pdf">Local Minima in Training of Neural Networks</a></li>
      <li><a href="https://arxiv.org/abs/1602.07714">Learning Values Across Many Orders of Magnitude</a></li>
      <li><a href="https://arxiv.org/pdf/1511.05176v2.pdf">MuProp: Unbiased Backpropagation for Stochastic Neural Networks</a></li>
      <li><a href="https://arxiv.org/pdf/1511.05946v3.pdf">ACDC: A Structured Efficient Linear Layer</a></li>
      <li><a href="https://arxiv.org/pdf/1507.00210.pdf">Natural Neural Networks</a></li>
      <li><a href="https://arxiv.org/pdf/1506.05254v1.pdf">Gradient Estimation Using Stochastic Computation Graphs</a></li>
      <li><a href="http://proceedings.mlr.press/v37/blundell15.pdf">Weight Uncertainty in Neural Networks</a></li>
      <li><a href="https://arxiv.org/abs/1401.4082">Stochastic Backpropagation and Approximate Inference in Deep Generative Models</a></li>
      <li><a href="https://arxiv.org/abs/1803.06959">On the Importance of Single Directions for Generalization</a></li>
    </ul>
  </li>
  <li>Variational Inference
    <ul>
      <li><a href="https://arxiv.org/pdf/1705.09279.pdf">Filtering Variational Objectives</a></li>
      <li><a href="https://arxiv.org/abs/1602.06725">Variational Inference for Monte Carlo Objectives</a></li>
      <li><a href="https://arxiv.org/pdf/1505.05770.pdf">Variational Inference with Normalizing Flows</a></li>
      <li><a href="https://arxiv.org/pdf/1509.08731v1.pdf">Variational Information Maximization for Intrinsically Motivated Reinforcement Learning [Also, Reinforcement Learning]</a></li>
      <li><a href="https://arxiv.org/pdf/1402.0030v2.pdf">Neural Variational Inference and Learning in Belief Networks</a></li>
      <li><a href="https://arxiv.org/abs/1802.06847">Distribution Matching in Variational Inference [Also, Generative, Unsupervised Learning]</a></li>
    </ul>
  </li>
  <li>Generative Models
    <ul>
      <li><a href="https://arxiv.org/pdf/1705.10743.pdf">The Cramer Distance as a Solution to Biased Wasserstein Gradients</a></li>
      <li><a href="https://arxiv.org/pdf/1706.04987.pdf">Variational Approaches for Auto-Encoding Generative Adversarial Networks</a></li>
      <li><a href="https://arxiv.org/pdf/1705.05263.pdf">Comparison of Maximum Likelihood and GAN-based training of Real NVPs</a></li>
      <li><a href="https://arxiv.org/pdf/1703.03664.pdf">Parallel Multiscale Autoregressive Density Estimation</a></li>
      <li><a href="https://arxiv.org/pdf/1606.05328.pdf">Conditional Image Generation with PixelCNN Decoders</a></li>
      <li><a href="https://arxiv.org/pdf/1609.03499.pdf">WaveNet: A Generative Model for Raw Audio</a></li>
      <li><a href="https://arxiv.org/pdf/1610.00527.pdf">Video Pixel Networks</a></li>
      <li><a href="https://arxiv.org/pdf/1610.03483.pdf">Learning in Implicit Generative Models</a></li>
      <li><a href="https://arxiv.org/pdf/1610.01945.pdf">Connecting Generative Adversarial Networks and Actor-Critic Methods [Also, Reinforcement Learning]</a></li>
      <li><a href="https://arxiv.org/abs/1601.06759">Pixel Recurrent Neural Networks</a></li>
      <li><a href="https://arxiv.org/abs/1603.05106">One-Shot Generalization in Deep Generative Models</a></li>
      <li><a href="https://arxiv.org/pdf/1511.04581.pdf">A Test of Relative Similarity for Model Selection in Generative Models</a></li>
      <li><a href="http://proceedings.mlr.press/v37/gregor15.pdf">DRAW: A Recurrent Neural Network for Image Generation [Also, Attention]</a></li>
      <li><a href="https://arxiv.org/abs/1406.5298">Semi-Supervised Learning with Deep Generative Models</a></li>
      <li><a href="https://arxiv.org/abs/1310.8499">Deep AutoRegressive Networks</a></li>
      <li><a href="https://arxiv.org/pdf/1511.01844v2.pdf">A Note on the Evaluation of Generative Models</a></li>
      <li><a href="https://arxiv.org/abs/1711.10433">Parallel WaveNet: Fast High-Fidelity Speech Synthesis (WaveRNN)</a></li>
      <li><a href="https://arxiv.org/abs/1802.08435">Efficient Neural Audio synthesis</a></li>
      <li><a href="https://arxiv.org/abs/1802.03006">Learning and Querying Fast Generative Models for Reinforcement Learning</a></li>
    </ul>
  </li>
  <li>Unsupervised Learning
    <ul>
      <li><a href="https://arxiv.org/pdf/1607.00662.pdf">Unsupervised Learning of 3D Structure from Images [Also, Computer Vision]</a></li>
      <li><a href="https://arxiv.org/pdf/1606.05579.pdf">Early Visual Concept Learning with Unsupervised Deep Learning (beta-VAE)</a></li>
      <li><a href="http://science.sciencemag.org/content/360/6394/1204">Neural Scene Representation and Rendering</a></li>
      <li><a href="https://arxiv.org/abs/1806.02215">Spectral Inference Networks: Unifying Spectral Methods with Deep Learning</a></li>
    </ul>
  </li>
  <li>Representation Learning
    <ul>
      <li><a href="https://arxiv.org/pdf/1707.03389.pdf">SCAN: Learning Abstract Hierarchical Compositional Visual Concepts</a></li>
      <li><a href="https://arxiv.org/abs/1604.08772">Towards Conceptual Compression</a></li>
      <li><a href="https://arxiv.org/abs/1711.00937">Neural Discrete Representation Learning [Also, Unsupervised Learning]</a></li>
      <li><a href="https://arxiv.org/abs/1802.05983">Disentangling by Factorising</a></li>
      <li><a href="https://arxiv.org/abs/1804.02476">Associative Compression Networks for Representation Learning</a></li>
    </ul>
  </li>
  <li>Attention
    <ul>
      <li><a href="https://arxiv.org/pdf/1603.08575.pdf">Attend, Infer, Repeat: Fast Scene Understanding with Generative Models</a></li>
      <li><a href="https://arxiv.org/pdf/1509.06664v2.pdf">Reasoning about Entailment with Neural Attention [Also, Natural Language Processing]</a></li>
      <li><a href="https://arxiv.org/pdf/1412.7755v2.pdf">Multiple Object Recognition with Visual Attention</a></li>
      <li><a href="https://arxiv.org/abs/1406.6247">Recurrent Models of Visual Attention</a></li>
    </ul>
  </li>
  <li>Memory
    <ul>
      <li><a href="https://arxiv.org/pdf/1703.01988.pdf">Neural Episodic Control</a></li>
      <li><a href="https://arxiv.org/pdf/1702.04649.pdf">Generative Temporal Models With Memory</a></li>
      <li><a href="https://arxiv.org/pdf/1610.09027.pdf">Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes</a></li>
      <li><a href="https://arxiv.org/abs/1606.04460">Model-Free Episodic Control</a></li>
      <li><a href="https://arxiv.org/abs/1605.06065">One-Shot Learning with Memory-Augmented Neural Networks</a></li>
      <li><a href="https://arxiv.org/abs/1602.03032">Associative Long Short-Term Memory</a></li>
      <li><a href="https://arxiv.org/pdf/1511.05952v3.pdf">Prioritized Experience Replay</a></li>
      <li><a href="https://arxiv.org/pdf/1611.01224.pdf">Sample Efficient Actor-Critic with Experience Replay</a></li>
      <li><a href="https://arxiv.org/abs/1602.03218">Learning Efficient Algorithms with Hierarchical Attentive Memory [Also, attention]</a></li>
      <li><a href="http://www.ijcai.org/Proceedings/15/Papers/470.pdf">Count-Based Frequency Estimation with Bounded Memory [Also, Natural Language Processing]</a></li>
      <li><a href="https://arxiv.org/abs/1802.10542">Memory-based Parameter Adaptation</a></li>
    </ul>
  </li>
  <li>Multi-Agent Systems
    <ul>
      <li><a href="https://arxiv.org/pdf/1706.05296.pdf">Value Decomposition Networks For Cooperative Multi-Agent Learning</a></li>
      <li><a href="https://arxiv.org/pdf/1605.06676v2.pdf">Learning to Communicate with Deep Multi-Agent Reinforcement Learning [Also, Multi-Task RL]</a></li>
      <li><a href="https://arxiv.org/abs/1711.00832">A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning [Also, Game Theory]</a></li>
      <li><a href="https://arxiv.org/abs/1802.07740">Machine Theory of Mind</a></li>
    </ul>
  </li>
  <li>Imitation Learning
    <ul>
      <li><a href="https://arxiv.org/pdf/1707.02747.pdf">Robust Imitation of Diverse Behaviors</a></li>
      <li><a href="https://arxiv.org/abs/1707.02201">Learning Human Behaviors from Motion Capture by Adversarial Imitation</a></li>
      <li><a href="https://arxiv.org/pdf/1707.08817.pdf">Leveraging Demonstrations for Deep Reinforcement Learning on Robotics Problems with Sparse Rewards</a></li>
      <li><a href="https://arxiv.org/abs/1802.09564">Reinforcement and Imitation Learning for Diverse Visuomotor Skills</a></li>
      <li><a href="https://arxiv.org/abs/1805.11592">Playing Hard Exploration Games by Watching Youtube</a></li>
    </ul>
  </li>
  <li>Metalearning
    <ul>
      <li>Neural Programming
        <ul>
          <li><a href="https://www.nature.com/articles/nature20101.epdf?author_access_token=ImTXBI8aWbYxYQ51Plys8NRgN0jAjWel9jnR3ZoTv0MggmpDmwljGswxVdeocYSurJ3hxupzWuRNeGvvXnoO8o4jTJcnAyhGuZzXJ1GEaD-Z7E6X_a9R-xqJ9TfJWBqz">Hybrid Computing Using a Neural Network with Dynamic External Memory</a></li>
          <li><a href="https://arxiv.org/pdf/1706.06383.pdf">Programmable Agents [Also, Representation Learning]</a></li>
          <li><a href="https://arxiv.org/pdf/1511.06279v3.pdf">Neural Programmer-Interpreters</a></li>
          <li><a href="https://arxiv.org/pdf/1511.06392v3.pdf">Neural Random-Access Machines</a></li>
          <li><a href="https://arxiv.org/abs/1410.5401">Neural Turing Machines</a></li>
          <li><a href="https://arxiv.org/abs/1711.04574">Learning Explanatory Rules from Noisy Data</a></li>
          <li><a href="https://arxiv.org/abs/1804.01118">Synthesizing Programs for Images using Reinforced Adversarial Learning (SPIRAL)</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Evolution
    <ul>
      <li><a href="https://arxiv.org/pdf/1606.02580.pdf">Convolution by Evolution</a></li>
    </ul>
  </li>
  <li>Game Theory
    <ul>
      <li><a href="https://arxiv.org/pdf/1606.08718.pdf">Learning Nash Equilibrium for General-Sum Markov Games from Batch Data</a></li>
      <li><a href="https://arxiv.org/abs/1802.05642">The Mechanics of n-Player Differentiable Games [Also, Generative Models (GANs)]</a></li>
      <li><a href="https://www.nature.com/articles/s41598-018-19194-4">Symmetric Decomposition of Asymmetric Games</a></li>
      <li><a href="https://arxiv.org/abs/1803.06376">A Generalised Method for Empirical Game Theoretic Analysis</a></li>
      <li><a href="https://arxiv.org/abs/1803.08884">Inequity Aversion Resolves Intertemporal Social Dilemmas</a></li>
    </ul>
  </li>
  <li>Natural Language Processing
    <ul>
      <li><a href="https://arxiv.org/pdf/1703.01898.pdf">Generative and Discriminative Text Classification with Recurrent Neural Networks</a></li>
      <li><a href="https://arxiv.org/pdf/1611.09100.pdf">Learning to Compose Words Into Sentences with Reinforcement Learning</a></li>
      <li><a href="https://arxiv.org/pdf/1611.01628.pdf">Reference-Aware Language Models</a></li>
      <li><a href="https://arxiv.org/pdf/1611.02554.pdf">The Neural Noisy Channel</a></li>
      <li><a href="https://arxiv.org/pdf/1603.06744.pdf">Latent Predictor Networks for Code Generation</a></li>
      <li><a href="https://arxiv.org/pdf/1605.03852.pdf">Learning the Curriculum with Bayesian Optimization for Task-Specific Word Representation Learning</a></li>
      <li><a href="https://arxiv.org/pdf/1609.09315.pdf">Semantic Parsing with Semi-Supervised Sequential Autoencoders</a></li>
      <li><a href="https://arxiv.org/abs/1707.05589]">On the State of the Art of Evaluation in Neural Language Models</a></li>
      <li><a href="https://arxiv.org/pdf/1506.03340v1.pdf">Teaching Machines to Read and Comprehend</a></li>
      <li><a href="https://arxiv.org/pdf/1506.02516v1.pdf">Learning to Transduce with Unbounded Memory [Also, Memory, Neural Programming]</a></li>
      <li><a href="http://cs.nyu.edu/~mirowski/pub/MirowskiVlachos_ACL2015_DependencyTreeRNN.pdf">Dependency Recurrent Neural Language Models for Sentence Completion</a></li>
      <li><a href="http://proceedings.mlr.press/v32/graves14.pdf">Towards End-to-End Speech Recognition with Recurrent Neural Networks</a></li>
      <li><a href="http://papers.nips.cc/paper/5165-learning-word-embeddings-efficiently-with-noise-contrastive-estimation.pdf">Learning Word Embeddings Efficiently with Noise-Contrastive Estimation</a></li>
      <li><a href="https://arxiv.org/abs/1712.07040v1">The NarrativeQA Reading Comprehension Challenge</a></li>
      <li><a href="https://arxiv.org/abs/1806.01946">Learning to Follow Language Instructions with Adversarial Reward Induction [Also, Loss Function Learning]</a></li>
    </ul>
  </li>
  <li>Multi-Modal
    <ul>
      <li><a href="https://arxiv.org/pdf/1705.08168.pdf">Look, Listen and Learn</a></li>
      <li><a href="https://arxiv.org/pdf/1703.05423.pdf">End-to-end Optimization of Goal-Driven and Visually Grounded Dialogue Systems</a></li>
      <li><a href="https://arxiv.org/pdf/1611.08481.pdf">GuessWhat?! Visual Object Discovery through Multi-Modal Dialogue</a></li>
      <li><a href="https://arxiv.org/pdf/1706.06551.pdf">Grounded Language Learning in a Simulated 3D World</a></li>
      <li><a href="https://arxiv.org/abs/1710.09867">Understanding Grounded Language Learning Agents [Also, Natural Language Processing]</a></li>
      <li><a href="https://arxiv.org/abs/1712.06651">Objects that Sound</a></li>
    </ul>
  </li>
  <li>General Machine Learning
    <ul>
      <li><a href="https://arxiv.org/pdf/1611.00712.pdf">The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables</a></li>
      <li><a href="https://arxiv.org/pdf/1702.08833.pdf">Learning Deep Nearest Neighbor Representations Using Differentiable Boundary Trees</a></li>
      <li><a href="https://arxiv.org/pdf/1312.6055v3.pdf">Unit Tests for Stochastic Optimization</a></li>
      <li><a href="http://papers.nips.cc/paper/5048-bayesian-hierarchical-community-discovery.pdf">Bayesian Hierarchical Community Discovery</a></li>
      <li><a href="https://arxiv.org/abs/1805.08498">Implicit Reparameterization Gradients</a></li>
      <li><a href="https://arxiv.org/abs/1805.09247">Cleaning up the Neighborhood: A Full Classification for Adversarial Partial Monitoring</a></li>
    </ul>
  </li>
  <li>Theory
    <ul>
      <li><a href="https://arxiv.org/abs/1712.01897v1">Online Learning with Gated Linear Networks</a></li>
    </ul>
  </li>
  <li>Miscellaneous
    <ul>
      <li><a href="https://arxiv.org/abs/1712.02151">Generalized Probability Smoothing</a></li>
      <li><a href="https://arxiv.org/abs/1805.12387">Agents and Devices: A Relative Definition of Agency</a></li>
    </ul>
  </li>
  <li>Neuroscience
    <ul>
      <li><a href="http://www.biorxiv.org/content/biorxiv/early/2017/07/04/083824.full.pdf">The Successor representation in human reinforcement learning</a></li>
      <li><a href="https://www.nature.com/articles/nn.4613.epdf?author_access_token=OfuqRzRgBmFKQdGE1Qw7FdRgN0jAjWel9jnR3ZoTv0N3IprbEH8EVdPgVTpPLVjgaMNMGW_KprBhEEIm7f1drNjI5FB2fds3h58n3XEtMJPC3kLK1Pp3J2_Qb45cy7uk">Dorsal Hippocampus Contributes to Model-Based Planning</a></li>
      <li><a href="http://www.cell.com/neuron/fulltext/S0896-6273(17)30509-3">Neuroscience-Inspired Artificial Intelligence</a></li>
      <li><a href="http://www.cell.com/neuron/pdf/S0896-6273(16)30802-9.pdf">Computations Underlying Social Hierarchy Learning: Distinct Neural Mechanism for Updating and Representing Self-Relevant Information</a></li>
      <li><a href="https://www.nature.com/articles/nn.4384.epdf?author_access_token=dq-w7RyWLn3z-0m4nbyTW9RgN0jAjWel9jnR3ZoTv0N7RVyemANPvboWSepiJaSAsTFiGqyORVbog9B6IjN113kC9aqMAEoNVCCfdRA4gLVJXcy4e1klhW0KiKS5F1gp">Dorsal Anterior Cingulate Cortex and the Value of Control</a></li>
      <li><a href="http://www.pnas.org/content/113/36/10180.abstract">Semantic Representations in the Temporal Pole Predict False Memories</a></li>
      <li><a href="http://www.biorxiv.org/content/early/2016/06/13/058545">Towards an Integration of Deep Learning and Neuroscience</a></li>
      <li><a href="http://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(16)30043-2">What Learning Systems do Intelligent Agents Need? Complementary Learning systems Theory Updated</a></li>
      <li><a href="http://www.cell.com/neuron/abstract/S0896-6273(16)30057-5">Neural Mechanisms of Hierarchical Planning in a Virtual Subway Network [Also, Planning]</a></li>
      <li><a href="https://www.biorxiv.org/content/early/2016/10/27/083857">Predictive Representations can Link Model-Based Reinforcement Learning to Model-Free Mechanisms</a></li>
      <li><a href="https://elifesciences.org/articles/06063">Hippocampal place cells construct reward related sequences through unexplored space</a></li>
      <li><a href="http://www.nature.com/neuro/journal/v20/n1/full/nn.4444.html">A Probabilistic Approach to Demixing Odors</a></li>
      <li><a href="https://arxiv.org/pdf/1512.08457v1.pdf">Approximate Hubel-Wiesel Modules and the Data Structures of Neural Computation</a></li>
      <li><a href="http://static1.1.sqspcdn.com/static/f/1096238/22043246/1361990370157/FutureMemory--Neuron12.pdf?token=b5gB3ycz3e%2BmKnQQCW3%2FvwZyHwE%3D">The Future of Memory: Remembering, Imagining, and the Brain</a></li>
      <li><a href="http://www.gatsby.ucl.ac.uk/~demis/TuringSpecialIssue(Nature2012).pdf">Is the Brain a Good Model for Machine Intelligence?</a></li>
      <li><a href="http://www.pnas.org/content/112/37/11708.full.pdf">Evidence Integration in Model-Based Tree Search</a></li>
      <li><a href="https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/building-machines-that-learn-and-think-for-themselves/E28DBFEC380D4189FB7754B50066A96F">Commentary on0 Building Machines that Learn and Think for Themselves</a></li>
      <li><a href="https://www.nature.com/articles/s41593-018-0147-8">Prefrontal Cortex as a Meta-Reinforcement Learning System</a></li>
    </ul>
  </li>
</ol>

<p>Current Frontier:</p>
<ol>
  <li>Hierarchical planning</li>
  <li>Imagination-based planning with generative models</li>
  <li>Unsupervised Learning</li>
  <li>Memory and one-shot learning</li>
  <li>Abstract Concepts</li>
  <li>Continual and Transfer Learning</li>
</ol>

<p>Emphasis on systems neuroscience - using the brain as inspiration for the structure and function of algorithms.</p>

<p><a href="http://sci-hub.tw/10.1016/j.neuron.2017.06.011">Neuroscience Inspired Artificial Intelligence</a></p>

<p>Examples of previous success of neuro-inspiration:</p>
<ul>
  <li>Reinforcement Learning
    <ul>
      <li>Inspired by animal learning</li>
      <li>TD Learning came out of animal behavior research.</li>
      <li>Second-order conditioning (Conditional Stimulus) (Sutton and Barto, 1981)
    * Deep Learning</li>
      <li>Convolutional Neural Networks. Visual Cortex (V1)
        <ul>
          <li>Uses hierarchical structure (successive processing layers)</li>
          <li>Neurons in the early visual systems responds strongly to specific patterns of light (say, precisely oriented bars) but hardly responds to many other patterns.</li>
          <li>Gabor functions describe the weights in V1 cells.</li>
          <li>Nonlinear Transduction</li>
          <li>Divisive Normalization</li>
        </ul>
      </li>
      <li>Word / Sentence Vectors - Distributed Embeddings
        <ul>
          <li>Parallel Distributed Processing in the brain for representation and computation</li>
        </ul>
      </li>
      <li>Dropout
        <ul>
          <li>Stochasticity in neurons that fire with` Poisson-like statistics (Hinton 2012)
            <ul>
              <li>Attention</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Applying attention to memory</li>
      <li>Thought - it doesn’t make much sense to train an attention model over a static image, rather than over a time series. With a time series, bringing attention to changing aspects of the input makes sense.
    * Multiple Memory Systems</li>
      <li>Episodic Memory
        <ul>
          <li>Experience Replay</li>
          <li>Especially for one shot experiences</li>
        </ul>
      </li>
      <li>Working Memory
        <ul>
          <li>LSTM - gating allows for conditioning on current state</li>
        </ul>
      </li>
      <li>Long-term Memory
        <ul>
          <li>External Memory</li>
          <li>Gating in LSTM
            <ul>
              <li>Continual Learning</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Elastic weight consolidation for slowing down learning on weights that are important for previous tasks.</li>
    </ul>
  </li>
</ul>

<p>Example of future success:</p>
<ul>
  <li>Intuitive Understanding of Physics
    <ul>
      <li>Need to understand space, number, objectness</li>
      <li>Need to disentangle representations for transfer. (Dude, I feel so stolen from)
    * Efficient Learning (Learning from few examples)
    * Transfer Learning</li>
      <li>Transferring generalized knowledge gained in one context to novel domains</li>
      <li>Concept representations for transfer
        <ul>
          <li>No direct evidence of concept representations in brains
            <ul>
              <li>Imagination and Planning</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Toward model-based RL</li>
      <li>Internal model of the environment
        <ul>
          <li>Model needs to include compositional / disentangled representations for flexibility</li>
        </ul>
      </li>
      <li>Implementing a forecasted-based method of action selection</li>
      <li>Monte-carlo Tree Search as simulation based planning</li>
      <li>In rat brains, we observe ‘preplay’ where rats imagine the likely future experience - measured by comparing neural activations at preplay to activations during the activity</li>
      <li>Generalization + Transfer in human planning</li>
      <li>Hierarchical Planning
    * Virtual Brain Analytics
deepminds-path-to-neuro-inspired-general-intelligence.md
Displaying deepminds-path-to-neuro-inspired-general-intelligence.md.</li>
    </ul>
  </li>
</ul>
