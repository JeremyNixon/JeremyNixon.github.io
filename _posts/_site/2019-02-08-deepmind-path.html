<p>By Jeremy Nixon [<a href="mailto:jnixon2@gmail.com">jnixon2@gmail.com</a>]. Nov. 2017. Updated June 2018.</p>

<p>Overview</p>

<ol>
  <li>
    <p>Deepmind Paper Framing</p>
  </li>
  <li>
    <p>Deepmind Papers through Framing</p>
  </li>
  <li>
    <p>Current Frontier</p>
  </li>
  <li>
    <p>Examples of Systems Neuroscience Inspiration</p>
  </li>
</ol>

<p>Deepmind Papers</p>

<p>Categories of the path to date:</p>

<ol>
  <li>
    <p>Transfer Learning</p>
  </li>
  <li>
    <p>Multi-task Learning</p>
  </li>
  <li>
    <p>Tools, Environment &amp; Datasets</p>
  </li>
  <li>
    <p>Intuitive Physics</p>
  </li>
  <li>
    <p>Reinforcement Learning</p>

    <ol>
      <li>
        <p>Model-based RL</p>
      </li>
      <li>
        <p>Exploration in RL</p>
      </li>
    </ol>
  </li>
  <li>
    <p>Applications</p>
  </li>
  <li>
    <p>Safety</p>
  </li>
  <li>
    <p>Deep Learning</p>
  </li>
  <li>
    <p>RNNs</p>
  </li>
  <li>
    <p>CNNs</p>
  </li>
  <li>
    <p>Generative Models</p>
  </li>
  <li>
    <p>Variational Inference</p>
  </li>
  <li>
    <p>Unsupervised Learning</p>
  </li>
  <li>
    <p>Representation Learning</p>
  </li>
  <li>
    <p>Attention</p>
  </li>
  <li>
    <p>Memory</p>
  </li>
  <li>
    <p>Multi-Agent Systems</p>
  </li>
  <li>
    <p>Imitation Learning</p>
  </li>
  <li>
    <p>Metalearning</p>
  </li>
  <li>
    <p>Neural Programming</p>
  </li>
  <li>
    <p>Evolution</p>
  </li>
  <li>
    <p>Game Theory</p>
  </li>
  <li>
    <p>Natural Language Processing</p>
  </li>
  <li>
    <p>Multi-Modal Learning</p>
  </li>
  <li>
    <p>General Machine Learning</p>
  </li>
  <li>
    <p>Theory</p>
  </li>
  <li>
    <p>Miscellaneous</p>
  </li>
  <li>
    <p>Neuroscience</p>
  </li>
</ol>

<p>Papers:</p>

<ol>
  <li>Transfer Learning<br />
<a href="https://arxiv.org/pdf/1707.08475.pdf">DARLA: Improving Zero-Shot Transfer In Reinforcement Learning</a><br />
<a href="https://arxiv.org/pdf/1701.08734.pdf">PathNet: Evolution Channels Gradient Descent in Super Neural Networks</a><br />
<a href="https://arxiv.org/abs/1606.04080">Matching Networks for One Shot Learning</a><br />
<a href="https://arxiv.org/pdf/1606.04671.pdf">Progressive Neural Networks</a><br />
<a href="https://arxiv.org/pdf/1610.04286.pdf">Sim-to-Real Robot Learning from Pixels with Progressive Nets</a><br />
<a href="https://arxiv.org/pdf/1606.05312.pdf">Successor Features for Transfer in Reinforcement Learning</a></li>
  <li>Multi-Task Learning<br />
<a href="https://arxiv.org/pdf/1708.07860.pdf">Multi-task Self-Supervised Visual Learning</a><br />
<a href="https://arxiv.org/pdf/1707.03300.pdf">The Intentional Unintentional Agent: Learning to Solve Many Continuous Control Tasks Simultaneously</a><br />
<a href="https://arxiv.org/pdf/1707.04175.pdf">Distral: Robust Multitask Reinforcement Learning</a><br />
<a href="https://arxiv.org/pdf/1707.02286.pdf">Emergence of Locomotion Behaviors in Rich Environments</a><br />
<a href="https://arxiv.org/pdf/1611.05397.pdf">Reinforcement Learning with Unsupervised Auxiliary Tasks</a><br />
<a href="https://arxiv.org/pdf/1611.03673.pdf">Learning to Navigate in Complex Environments</a><br />
<a href="https://arxiv.org/pdf/1610.05182.pdf">Learning and Transfer of Modulated Locomotor Controllers</a><br />
<a href="https://arxiv.org/pdf/1511.06114v3.pdf">Multi-Task Sequence to Sequence Learning</a><br />
<a href="https://arxiv.org/abs/1802.10567">Learning by Playing - Solving Sparse Reward Tasks from Scratch</a><br />
<a href="https://arxiv.org/abs/1802.08294">Unicorn: Continual Learning with a Universal, Off-policy Agent</a><br />
<a href="https://arxiv.org/abs/1805.06370">Progress &amp; Compress: A Scalable Framework for Continual Learning</a></li>
  <li>Tools, Environments, Evaluation &amp; Datasets<br />
<a href="https://arxiv.org/pdf/1708.04782.pdf">Starcraft II: A New Challenge for Reinforcement Learning</a><br />
<a href="https://arxiv.org/pdf/1612.03801.pdf">DeepMind Lab</a><br />
<a href="https://arxiv.org/pdf/1705.06950.pdf">The Kinetics Human Action Video Dataset</a><br />
<a href="https://arxiv.org/pdf/1109.5951v2.pdf">An approximation of the Universal Intelligence Measure</a><br />
<a href="https://arxiv.org/abs/1801.08116">Psychlab: A Psychology Laboratory for Deep Reinforcement Learning</a><br />
<a href="https://arxiv.org/pdf/1801.00690v1.pdf">Deepmind Control Suite</a><br />
<a href="https://arxiv.org/pdf/1705.07750.pdf">Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset</a></li>
  <li>Intuitive Physics<br />
<a href="https://arxiv.org/pdf/1705.09805.pdf">Position-Velocity Encoders for Unsupervised Learning of Structured State Representations</a><br />
<a href="https://arxiv.org/pdf/1611.01843.pdf">Learning to Perform Physics Experiments via Deep Reinforcement Learning</a><br />
<a href="https://arxiv.org/pdf/1509.02971v2.pdf">Continuous Control with Deep Reinforcement Learning</a></li>
  <li>Reinforcement Learning (Papers with a pure RL focus)<br />
[Model-Based RL]<br />
[Learning Model-Based Planning from Scratch]<br />
<a href="https://arxiv.org/pdf/1704.02254.pdf">Recurrent Environment Simulators</a><br />
[Structure Learning in Motor Control: A Deep Reinforcement Learning Model<br />
[Imagination-Augmented Agents for Deep Reinforcement Learning]<br />
<a href="https://arxiv.org/abs/1603.00748">Continuous Deep Q-Learning with Model-based Acceleration</a><br />
<a href="http://proceedings.mlr.press/v32/bellemare14.pdf">Skip Context Tree Switching</a><br />
<a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Publications_files/bafa.pdf">Bayes-Adaptive Simulation-Based Search with Value Function Approximation</a><br />
<a href="https://arxiv.org/abs/1802.03006">Learning and Querying Fast Generative Models for Reinforcement Learning</a></li>
  <li>Exploration in RL<br />
<a href="https://arxiv.org/pdf/1703.01310.pdf">Count-Based Exploration with Neural Density Models</a><br />
<a href="https://arxiv.org/abs/1606.01868">Unifying Count-Based Exploration and Intrinsic Motivation</a><br />
<a href="https://arxiv.org/abs/1602.04621">Deep Exploration via Bootstrapped DQN</a><br />
<a href="https://arxiv.org/pdf/1611.07507.pdf">Variational Intrinsic Control</a><br />
<a href="https://arxiv.org/abs/1802.04697v1">Learning to Search with MCTSnets</a><br />
<a href="https://arxiv.org/abs/1805.11593">Observe and Look Further: Achieving Consistent Performance on Atari</a><br />
<a href="https://arxiv.org/pdf/1707.06887.pdf">A Distributional Perspective on Reinforcement Learning</a><br />
[FeUdal Networks for Hierarchical Reinforcement Learning]<br />
<a href="https://arxiv.org/pdf/1611.01626.pdf">Combining Policy Gradient and Q-Learning</a><br />
<a href="https://arxiv.org/pdf/1606.04695.pdf">Strategic Attentive Writer for Learning Macro-Actions</a><br />
<a href="https://arxiv.org/abs/1606.02647">Safe and Efficient Off-Policy Reinforcement Learning</a><br />
<a href="https://arxiv.org/pdf/1610.00633.pdf">Deep Reinforcement Learning for Robotic Manipulation with Asynchronous Off-Policy Updates</a><br />
<a href="https://arxiv.org/pdf/1602.07905.pdf">Thompson Sampling is Asymptotically Optimal in General Environments</a><br />
<a href="https://arxiv.org/abs/1602.01783">Asynchronous Methods for Deep Reinforcement Learning</a><br />
<a href="https://arxiv.org/abs/1511.06581">Dueling Network Architectures for Deep Reinforcement Learning</a><br />
<a href="https://arxiv.org/abs/1512.04860">Increasing the Action Gap: New Operators for Reinforcement Learning</a><br />
<a href="https://arxiv.org/abs/1509.06461">Deep Reinforcement Learning with Double Q-Learninghttps://arxiv.org/abs/1509.06461</a><br />
<a href="https://arxiv.org/pdf/1511.06295.pdf">Policy Distillation</a><br />
<a href="http://proceedings.mlr.press/v37/schaul15.pdf">Universal Value Function Approximators</a><br />
<a href="https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf">Human-level Control through Deep Reinforcement Learning</a><br />
<a href="https://arxiv.org/pdf/1510.09142v1.pdf">Learning Continuous Control Policies by Stochastic Value Gradients</a><br />
<a href="http://proceedings.mlr.press/v37/heinrich15.pdf">Fictitious Self-Play in Extensive Form Games</a><br />
<a href="http://proceedings.mlr.press/v38/li15b.html">Toward Minimax Off-policy Value Estimation</a><br />
<a href="https://arxiv.org/pdf/1507.04296.pdf">Massively Parallel Methods for Deep Reinforcement Learning</a><br />
<a href="https://arxiv.org/pdf/1411.5326v1.pdf">Compress and Control</a><br />
<a href="http://proceedings.mlr.press/v32/silver14.pdf">Deterministic Policy Gradient Algorithms</a><br />
<a href="https://arxiv.org/pdf/1312.5602v1.pdf">Playing Atari with Deep Reinforcement Learning</a><br />
<a href="http://www.sciencedirect.com/science/article/pii/S2352154615001151">Reinforcement Learning, Efficient Coding, and the Statistics of Natural Tasks</a><br />
<a href="https://arxiv.org/abs/1710.02298">Rainbow: Combining Improvements in Deep Reinforcement Learning</a><br />
<a href="https://arxiv.org/abs/1802.03501">Path Consistency Learning in Tsallis Entropy Regularized MDPs</a><br />
<a href="https://arxiv.org/abs/1802.03493">More Robust Doubly Robust Off-Policy Evaluation</a><br />
<a href="https://arxiv.org/abs/1802.01561">IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures</a><br />
<a href="https://arxiv.org/abs/1806.01780">Mis&amp;Match - Agent Curricula for Reinforcement Learning</a><br />
<a href="https://www.nature.com/articles/s41586-018-0102-6.epdf">Vector-based Navigation Using Grid-Like Representations in Artificial Agents</a>?<br />
<a href="https://arxiv.org/abs/1803.03835">Kickstarting Deep Reinforcement Learning</a></li>
  <li>Applications</li>
  <li>Go<br />
<a href="https://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf">Mastering the Game of Go with Deep Neural Networks and Tree Search</a><br />
[More Evaluation in Go using Deep Convolutional Neural Networks]<br />
<a href="https://www.nature.com/articles/nature24270.epdf">Mastering the Game of Go Without Human Knowledge</a>?</li>
  <li>Poker<br />
<a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Publications_files/smooth_uct.pdf">Smooth UCT Search in Computer Poker</a></li>
  <li>Fairness<br />
<a href="https://arxiv.org/pdf/1802.08139.pdf">Path-Specific Counterfactual Fairness</a><br />
[Safety / Security]<br />
[Reinforcement Learning with a Corrupted Reward Channel]<br />
[Safely Interruptible Agents]<br />
<a href="https://arxiv.org/abs/1711.09883">AI Safety Gridworlds</a><br />
<a href="https://arxiv.org/abs/1802.05666">Adversarial Risk and the Dangers of Evaluating Against Weak Attacks</a><br />
<a href="https://arxiv.org/abs/1801.08757">Safe Exploration in Continuous Action Spaces</a><br />
<a href="https://arxiv.org/abs/1806.01186">Measuring and Avoiding Side Effects Using Relative Reachability</a></li>
  <li>Deep Learning<br />
[Recurrent Neural Networks]<br />
[Sequential Neural Models with Stochastic Layers]<br />
<a href="https://arxiv.org/abs/1606.03401">Memory-Efficient Backpropagation Through Time</a><br />
<a href="https://arxiv.org/abs/1603.08983">Adaptive Computation Time for Recurrent Neural Networks</a><br />
<a href="https://arxiv.org/pdf/1507.01526v3.pdf">Grid Long-Short Term Memory</a><br />
<a href="https://arxiv.org/pdf/1511.06391v3.pdf">Order Matters: Sequence to Sequence for Sets</a></li>
  <li>Convolutional Neural Networks<br />
<a href="https://arxiv.org/abs/1602.02660">Exploiting Cyclic Symmetry in Convolutional Neural Networks</a><br />
<a href="https://arxiv.org/pdf/1506.02025.pdf">Spatial Transformer Networks</a><br />
<a href="https://arxiv.org/pdf/1409h.1556v6.pdf">Very Deep Convolutional Networks for Large Scale Image Recognition</a><br />
<a href="https://arxiv.org/abs/1804.04438">Pooling is Neither Necessary Nor Sufficient for Appropriate Deformation Stability in CNNs</a><br />
<a href="https://arxiv.org/pdf/1706.10295.pdf">Noisy Networks for Exploration</a><br />
<a href="https://arxiv.org/abs/1706.04859">Sobolev Training for Neural Networks</a><br />
<a href="https://arxiv.org/pdf/1608.05343.pdf">Decoupled Neural Interfaces using Synthetic Gradients</a><br />
<a href="https://arxiv.org/pdf/1703.00522.pdf">Understanding Synthetic Gradients and Decoupled Neural Interfaces</a><br />
<a href="https://arxiv.org/pdf/1612.01474.pdf">Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles</a><br />
<a href="https://arxiv.org/pdf/1612.00796.pdf">Overcoming Catastrophic Forgetting in Neural Networks</a><br />
<a href="https://arxiv.org/pdf/1611.06310.pdf">Local Minima in Training of Neural Networks</a><br />
<a href="https://arxiv.org/abs/1602.07714">Learning Values Across Many Orders of Magnitude</a><br />
<a href="https://arxiv.org/pdf/1511.05176v2.pdf">MuProp: Unbiased Backpropagation for Stochastic Neural Networks</a><br />
<a href="https://arxiv.org/pdf/1511.05946v3.pdf">ACDC: A Structured Efficient Linear Layer</a><br />
<a href="https://arxiv.org/pdf/1507.00210.pdf">Natural Neural Networks</a><br />
<a href="https://arxiv.org/pdf/1506.05254v1.pdf">Gradient Estimation Using Stochastic Computation Graphs</a><br />
<a href="http://proceedings.mlr.press/v37/blundell15.pdf">Weight Uncertainty in Neural Networks</a><br />
<a href="https://arxiv.org/abs/1401.4082">Stochastic Backpropagation and Approximate Inference in Deep Generative Models</a><br />
<a href="https://arxiv.org/abs/1803.06959">On the Importance of Single Directions for Generalization</a></li>
  <li>Variational Inference<br />
<a href="https://arxiv.org/pdf/1705.09279.pdf">Filtering Variational Objectives</a><br />
<a href="https://arxiv.org/abs/1602.06725">Variational Inference for Monte Carlo Objectives</a><br />
<a href="https://arxiv.org/pdf/1505.05770.pdf">Variational Inference with Normalizing Flows</a><br />
[Variational Information Maximization for Intrinsically Motivated Reinforcement Learning]<br />
<a href="https://arxiv.org/pdf/1402.0030v2.pdf">Neural Variational Inference and Learning in Belief Networks</a><br />
<a href="https://arxiv.org/abs/1802.06847">Distribution Matching in Variational Infeence</a></li>
  <li>Generative Models<br />
<a href="https://arxiv.org/pdf/1705.10743.pdf">The Cramer Distance as a Solution to Biased Wasserstein Gradients</a><br />
<a href="https://arxiv.org/pdf/1706.04987.pdf">Variational Approaches for Auto-Encoding Generative Adversarial Networks</a><br />
<a href="https://arxiv.org/pdf/1705.05263.pdf">Comparison of Maximum Likelihood and GAN-based training of Real NVPs</a><br />
<a href="https://arxiv.org/pdf/1703.03664.pdf">Parallel Multiscale Autoregressive Density Estimation</a><br />
<a href="https://arxiv.org/pdf/1606.05328.pdf">Conditional Image Generation with PixelCNN Decoders</a><br />
<a href="https://arxiv.org/pdf/1609.03499.pdf">WaveNet: A Generative Model for Raw Audio</a><br />
<a href="https://arxiv.org/pdf/1610.00527.pdf">Video Pixel Networks</a><br />
<a href="https://arxiv.org/pdf/1610.03483.pdf">Learning in Implicit Generative Models</a><br />
*Connecting Generative Adversarial Networks and Actor-Critic Methods]<br />
<a href="https://arxiv.org/abs/1601.06759">Pixel Recurrent Neural Networks</a><br />
<a href="https://arxiv.org/abs/1603.05106">One-Shot Generalization in Deep Generative Models</a><br />
<a href="https://arxiv.org/pdf/1511.04581.pdf">A Test of Relative Similarity for Model Selection in Generative Models</a><br />
[DRAW: A Recurrent Neural Network for Image Generation]<br />
<a href="https://arxiv.org/abs/1406.5298">Semi-Supervised Learning with Deep Generative Models</a><br />
<a href="https://arxiv.org/abs/1310.8499">Deep AutoRegressive Networks</a><br />
<a href="https://arxiv.org/pdf/1511.01844v2.pdf">A Note on the Evaluation of Generative Models</a><br />
<a href="https://arxiv.org/abs/1711.10433">Parallel WaveNet: Fast High-Fidelity Speech Synthesis (WaveRNN)</a><br />
<a href="https://arxiv.org/abs/1802.08435">Efficient Neural Audio synthesis</a><br />
<a href="https://arxiv.org/abs/1802.03006">Learning and Querying Fast Generative Models for Reinforcement Learning</a><br />
[Unsupervised Learning]<br />
<a href="https://arxiv.org/pdf/1607.00662.pdf">of 3D Structure from Image</a><br />
<a href="https://arxiv.org/pdf/1606.05579.pdf">Early Visual Concept Learning with Unsupervised Deep Learning (beta-VAE)</a><br />
<a href="http://science.sciencemag.org/content/360/6394/1204">Neural Scene Representation and Rendering</a><br />
<a href="https://arxiv.org/abs/1806.02215">Spectral Inference Networks: Unifying Spectral Methods with Deep Learning</a></li>
  <li>Representation Learning<br />
<a href="https://arxiv.org/pdf/1707.03389.pdf">SCAN: Learning Abstract Hierarchical Compositional Visual Concepts</a><br />
<a href="https://arxiv.org/abs/1604.08772">Towards Conceptual Compression</a><br />
[Neural Discrete Representation Learning]<br />
<a href="https://arxiv.org/abs/1802.05983">Disentangling by Factorising</a><br />
<a href="https://arxiv.org/abs/1804.02476">Associative Compression Networks for Representation Learning</a></li>
  <li>Attention<br />
<a href="https://arxiv.org/pdf/1603.08575.pdf">Attend, Infer, Repeat: Fast Scene Understanding with Generative Models</a><br />
[Reasoning about Entailment with Neural Attention]<br />
<a href="https://arxiv.org/pdf/1412.7755v2.pdf">Multiple Object Recognition with Visual Attention</a><br />
<a href="https://arxiv.org/abs/1406.6247">Recurrent Models of Visual Attention</a></li>
  <li>Memory<br />
<a href="https://arxiv.org/pdf/1703.01988.pdf">Neural Episodic Control</a><br />
<a href="https://arxiv.org/pdf/1702.04649.pdf">Generative Temporal Models With Memory</a><br />
<a href="https://arxiv.org/pdf/1610.09027.pdf">Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes</a><br />
<a href="https://arxiv.org/abs/1606.04460">Model-Free Episodic Control</a><br />
<a href="https://arxiv.org/abs/1605.06065">One-Shot Learning with Memory-Augmented Neural Networks</a><br />
<a href="https://arxiv.org/abs/1602.03032">Associative Long Short-Term Memory</a><br />
<a href="https://arxiv.org/pdf/1511.05952v3.pdf">Prioritized Experience Replay</a><br />
<a href="https://arxiv.org/pdf/1611.01224.pdf">Sample Efficient Actor-Critic with Experience Replay</a><br />
<a href="https://arxiv.org/abs/1602.03218">Algorithms with Hierarchical Attentive Memory</a><br />
<a href="http://www.ijcai.org/Proceedings/15/Papers/470.pdf">Estimation with Bounded Memory</a><br />
<a href="https://arxiv.org/abs/1802.10542">Memory-based Parameter Adaptation</a></li>
  <li>Multi-Agent Systems<br />
<a href="https://arxiv.org/pdf/1706.05296.pdf">Value Decomposition Networks For Cooperative Multi-Agent Learning</a><br />
[Learning to Communicate with Deep Multi-Agent Reinforcement Learning]<br />
[A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning<br />
]<a href="https://arxiv.org/abs/1802.07740">Machine Theory of Mind</a></li>
  <li>Imitation Learning<br />
<a href="https://arxiv.org/pdf/1707.02747.pdf">Robust Imitation of Diverse Behaviors</a><br />
<a href="https://arxiv.org/abs/1707.02201">Learning Human Behaviors from Motion Capture by Adversarial Imitation</a><br />
<a href="https://arxiv.org/pdf/1707.08817.pdf">Leveraging Demonstrations for Deep Reinforcement Learning on Robotics Problems with Sparse Rewards</a><br />
<a href="https://arxiv.org/abs/1802.09564">Reinforcement and Imitation Learning for Diverse Visuomotor Skills</a><br />
<a href="https://arxiv.org/abs/1805.11592">Playing Hard Exploration Games by Watching Youtube</a></li>
  <li>Metalearning</li>
  <li>Neural Programming<br />
<a href="https://www.nature.com/articles/nature20101.epdf?author_access_token=ImTXBI8aWbYxYQ51Plys8NRgN0jAjWel9jnR3ZoTv0MggmpDmwljGswxVdeocYSurJ3hxupzWuRNeGvvXnoO8o4jTJcnAyhGuZzXJ1GEaD-Z7E6X_a9R-xqJ9TfJWBqz">Hybrid Computing Using a Neural Network with Dynamic External Memory</a><br />
[Programmable Agents]<br />
<a href="https://arxiv.org/pdf/1511.06279v3.pdf">Neural Programmer-Interpreters</a><br />
<a href="https://arxiv.org/pdf/1511.06392v3.pdf">Neural Random-Access Machines</a><br />
<a href="https://arxiv.org/abs/1410.5401">Neural Turing Machines</a><br />
<a href="https://arxiv.org/abs/1711.04574">Learning Explanatory Rules from Noisy Data</a><br />
<a href="https://arxiv.org/abs/1804.01118">Synthesizing Programs for Images using Reinforced Adversarial Learning (SPIRAL)</a><br />
<a href="https://arxiv.org/abs/1606.04474">Learning to learn by gradient descent by gradient descent</a><br />
[<br />
<a href="https://arxiv.org/pdf/1711.00436.pdf">Hierarchical Representations for Efficient Architecture Search</a><br />
<a href="https://arxiv.org/abs/1711.09846">Population Based Training of Neural Networks</a><br />
<a href="https://arxiv.org/abs/1805.09801">Meta-Gradient Reinforcement Learning</a></li>
  <li>Evolution<br />
<a href="https://arxiv.org/pdf/1606.02580.pdf">Convolution by Evolution</a></li>
  <li>Game Theory<br />
<a href="https://arxiv.org/pdf/1606.08718.pdf">Learning Nash Equilibrium for General-Sum Markov Games from Batch Data</a><br />
[The Mechanics of n-Player Differentiable Games]<br />
<a href="https://www.nature.com/articles/s41598-018-19194-4">Symmetric Decomposition of Asymmetric Games</a><br />
<a href="https://arxiv.org/abs/1803.06376">A Generalised Method for Empirical Game Theoretic Analysis</a><br />
<a href="https://arxiv.org/abs/1803.08884">Inequity Aversion Resolves Intertemporal Social Dilemmas</a></li>
  <li>Natural Language Processing<br />
<a href="https://arxiv.org/pdf/1703.01898.pdf">Generative and Discriminative Text Classification with Recurrent Neural Networks</a><br />
<a href="https://arxiv.org/pdf/1611.09100.pdf">Learning to Compose Words Into Sentences with Reinforcement Learning</a><br />
<a href="https://arxiv.org/pdf/1611.01628.pdf">Reference-Aware Language Models</a><br />
<a href="https://arxiv.org/pdf/1611.02554.pdf">The Neural Noisy Channel</a><br />
<a href="https://arxiv.org/pdf/1603.06744.pdf">Latent Predictor Networks for Code Generation</a><br />
<a href="https://arxiv.org/pdf/1605.03852.pdf">Learning the Curriculum with Bayesian Optimization for Task-Specific Word Representation Learning</a><br />
<a href="https://arxiv.org/pdf/1609.09315.pdf">Semantic Parsing with Semi-Supervised Sequential Autoencoders</a><br />
<a href="https://arxiv.org/abs/1707.05589">On the State of the Art of Evaluation in Neural Language Models</a><br />
<a href="https://arxiv.org/pdf/1506.03340v1.pdf">Teaching Machines to Read and Comprehend</a><br />
<a href="http://cs.nyu.edu/~mirowski/pub/MirowskiVlachos_ACL2015_DependencyTreeRNN.pdf">Dependency Recurrent Neural Language Models for Sentence Completion</a><br />
<a href="http://proceedings.mlr.press/v32/graves14.pdf">Towards End-to-End Speech Recognition with Recurrent Neural Networks</a><br />
<a href="http://papers.nips.cc/paper/5165-learning-word-embeddings-efficiently-with-noise-contrastive-estimation.pdf">Learning Word Embeddings Efficiently with Noise-Contrastive Estimation</a><br />
<a href="https://arxiv.org/abs/1712.07040v1">The NarrativeQA Reading Comprehension Challenge</a><br />
<a href="https://arxiv.org/abs/1806.01946">Learning to Follow Language Instructions with Adversarial Reward Induction</a></li>
  <li>Multi-Modal<br />
<a href="https://arxiv.org/pdf/1705.08168.pdf">Look, Listen and Learn</a><br />
<a href="https://arxiv.org/pdf/1703.05423.pdf">End-to-end Optimization of Goal-Driven and Visually Grounded Dialogue Systems</a><br />
<a href="https://arxiv.org/pdf/1611.08481.pdf">GuessWhat?! Visual Object Discovery through Multi-Modal Dialogue</a><br />
<a href="https://arxiv.org/pdf/1706.06551.pdf">Grounded Language Learning in a Simulated 3D World</a><br />
[Understanding Grounded Language Learning Agents]<br />
<a href="https://arxiv.org/abs/1712.06651">Objects that Sound</a></li>
  <li>General Machine Learning<br />
<a href="https://arxiv.org/pdf/1611.00712.pdf">The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables</a><br />
<a href="https://arxiv.org/pdf/1702.08833.pdf">Learning Deep Nearest Neighbor Representations Using Differentiable Boundary Trees</a><br />
<a href="https://arxiv.org/pdf/1312.6055v3.pdf">Unit Tests for Stochastic Optimization</a><br />
<a href="http://papers.nips.cc/paper/5048-bayesian-hierarchical-community-discovery.pdf">Bayesian Hierarchical Community Discovery</a><br />
<a href="https://arxiv.org/abs/1805.08498">Implicit Reparameterization Gradients</a></li>
  <li>Cleaning up the Neighborhood: A Full Classification for Adversarial Partial Monitoring<br />
[<a href="https://arxiv.org/abs/1805.09247">https://arxiv.org/abs/1805.09247</a></li>
  <li>Theory</li>
  <li>Online Learning with Gated Linear Networks<br />
[<a href="https://arxiv.org/abs/1712.01897v1">https://arxiv.org/abs/1712.01897v1</a></li>
  <li>Miscellaneous<br />
<a href="https://arxiv.org/abs/1712.02151">Generalized Probability Smoothing</a><br />
<a href="https://arxiv.org/abs/1805.12387">Agents and Devices: A Relative Definition of Agency</a></li>
  <li>Neuroscience<br />
<a href="http://www.biorxiv.org/content/biorxiv/early/2017/07/04/083824.full.pdf">The Successor representation in human reinforcement learning</a><br />
<a href="https://www.nature.com/articles/nn.4613.epdf?author_access_token=OfuqRzRgBmFKQdGE1Qw7FdRgN0jAjWel9jnR3ZoTv0N3IprbEH8EVdPgVTpPLVjgaMNMGW_KprBhEEIm7f1drNjI5FB2fds3h58n3XEtMJPC3kLK1Pp3J2_Qb45cy7uk">Dorsal Hippocampus Contributes to Model-Based Planning</a><br />
<a href="http://www.cell.com/neuron/fulltext/S0896-6273(17)30509-3">Neuroscience-Inspired Artificial Intelligence</a><br />
<a href="http://www.cell.com/neuron/pdf/S0896-6273(16)30802-9.pdf">Computations Underlying Social Hierarchy Learning: Distinct Neural Mechanism for Updating and Representing Self-Relevant Information</a><br />
<a href="https://www.nature.com/articles/nn.4384.epdf?author_access_token=dq-w7RyWLn3z-0m4nbyTW9RgN0jAjWel9jnR3ZoTv0N7RVyemANPvboWSepiJaSAsTFiGqyORVbog9B6IjN113kC9aqMAEoNVCCfdRA4gLVJXcy4e1klhW0KiKS5F1gp">Dorsal Anterior Cingulate Cortex and the Value of Control</a><br />
<a href="http://www.pnas.org/content/113/36/10180.abstract">Semantic Representations in the Temporal Pole Predict False Memories</a><br />
<a href="http://www.biorxiv.org/content/early/2016/06/13/058545">Towards an Integration of Deep Learning and Neuroscience</a><br />
<a href="http://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(16)30043-2">What Learning Systems do Intelligent Agents Need? Complementary Learning systems Theory Updated</a><br />
[Neural Mechanisms of Hierarchical Planning in a Virtual Subway Network]<br />
<a href="https://www.biorxiv.org/content/early/2016/10/27/083857">Predictive Representations can Link Model-Based Reinforcement Learning to Model-Free Mechanisms</a><br />
<a href="https://elifesciences.org/articles/06063">Hippocampal place cells construct reward related sequences through unexplored space</a><br />
<a href="http://www.nature.com/neuro/journal/v20/n1/full/nn.4444.html">A Probabilistic Approach to Demixing Odors</a><br />
<a href="https://arxiv.org/pdf/1512.08457v1.pdf">Approximate Hubel-Wiesel Modules and the Data Structures of Neural Computation</a><br />
<a href="http://static1.1.sqspcdn.com/static/f/1096238/22043246/1361990370157/FutureMemory--Neuron12.pdf?token=b5gB3ycz3e%2BmKnQQCW3%2FvwZyHwE%3D">The Future of Memory: Remembering, Imagining, and the Brain</a><br />
<a href="http://www.gatsby.ucl.ac.uk/~demis/TuringSpecialIssue(Nature2012).pdf">Is the Brain a Good Model for Machine Intelligence?</a><br />
<a href="http://www.pnas.org/content/112/37/11708.full.pdf">Evidence Integration in Model-Based Tree Search</a><br />
<a href="https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/building-machines-that-learn-and-think-for-themselves/E28DBFEC380D4189FB7754B50066A96F">(Commentary on0 Building Machines that Learn and Think for Themselves</a><br />
<a href="https://www.nature.com/articles/s41593-018-0147-8">Prefrontal Cortex as a Meta-Reinforcement Learning System</a></li>
</ol>

<p>Current Frontier:</p>

<ol>
  <li>
    <p>Hierarchical planning</p>
  </li>
  <li>
    <p>Imagination-based planning with generative models</p>
  </li>
  <li>
    <p>Unsupervised Learning</p>
  </li>
  <li>
    <p>Memory and one-shot learning</p>
  </li>
  <li>
    <p>Abstract Concepts</p>
  </li>
  <li>
    <p>Continual and Transfer Learning</p>
  </li>
</ol>

<p>Emphasis on systems neuroscience - using the brain as inspiration for the structure and function of algorithms.</p>

<p><a href="http://sci-hub.cc/10.1016/j.neuron.2017.06.011">Neuroscience Inspired Artificial Intelligence</a></p>

<p>Examples of previous success of neuro-inspiration:</p>

<ul>
  <li>
    <p>Reinforcement Learning</p>
  </li>
  <li>
    <p>Inspired by animal learning</p>
  </li>
  <li>
    <p>TD Learning came out of animal behavior research.</p>
  </li>
  <li>
    <p>Second-order conditioning (Conditional Stimulus) (Sutton and Barto, 1981)</p>
  </li>
  <li>
    <p>Deep Learning.</p>
  </li>
  <li>
    <p>Convolutional Neural Networks. Visual Cortex (V1)</p>
  </li>
  <li>
    <p>Uses hierarchical structure (successive processing layers)</p>
  </li>
  <li>
    <p>Neurons in the early visual systems responds strongly to specific patterns of light (say, precisely oriented bars) but hardly responds to many other patterns.</p>
  </li>
  <li>
    <p>Gabor functions describe the weights in V1 cells.</p>
  </li>
  <li>
    <p>Nonlinear Transduction</p>
  </li>
  <li>
    <p>Divisive Normalization</p>
  </li>
  <li>
    <p>Word / Sentence Vectors - Distributed Embeddings</p>
  </li>
  <li>
    <p>Parallel Distributed Processing in the brain for representation and computation</p>
  </li>
  <li>
    <p>Dropout</p>
  </li>
  <li>
    <p>Stochasticity in neurons that fire with` Poisson-like statistics (Hinton 2012)</p>
  </li>
  <li>
    <p>Attention</p>
  </li>
  <li>
    <p>Applying attention to memory</p>
  </li>
  <li>
    <p>Thought - it doesn’t make much sense to train an attention model over a static image, rather than over a time series. With a time series, bringing attention to changing aspects of the input makes sense.</p>
  </li>
  <li>
    <p>Multiple Memory Systems</p>
  </li>
  <li>
    <p>Episodic Memory</p>
  </li>
  <li>
    <p>Experience Replay</p>
  </li>
  <li>
    <p>Especially for one shot experiences</p>
  </li>
  <li>
    <p>Working Memory</p>
  </li>
  <li>
    <p>LSTM - gating allows for conditioning on current state</p>
  </li>
  <li>
    <p>Long-term Memory</p>
  </li>
  <li>
    <p>External Memory</p>
  </li>
  <li>
    <p>Gating in LSTM</p>
  </li>
  <li>
    <p>Continual Learning</p>
  </li>
  <li>
    <p>Elastic weight consolidation for slowing down learning on weights that are important for previous tasks.</p>
  </li>
</ul>

<p>Examples of future success:</p>

<ul>
  <li>
    <p>Intuitive Understanding of Physics</p>
  </li>
  <li>
    <p>Need to understand space, number, objectness</p>
  </li>
  <li>
    <p>Need to disentangle representations for transfer. (Dude, I feel so stolen from)</p>
  </li>
  <li>
    <p>Efficient Learning (Learning from few examples)</p>
  </li>
  <li>
    <p>Transfer Learning</p>
  </li>
  <li>
    <p>Transferring generalized knowledge gained in one context to novel domains</p>
  </li>
  <li>
    <p>Concept representations for transfer</p>
  </li>
  <li>
    <p>No direct evidence of concept representations in brains</p>
  </li>
  <li>
    <p>Imagination and Planning</p>
  </li>
  <li>
    <p>Toward model-based RL</p>
  </li>
  <li>
    <p>Internal model of the environment</p>
  </li>
  <li>
    <p>Model needs to include compositional / disentangled representations for flexibility</p>
  </li>
  <li>
    <p>Implementing a forecasted-based method of action selection</p>
  </li>
  <li>
    <p>Monte-carlo Tree Search as simulation based planning</p>
  </li>
  <li>
    <p>In rat brains, we observe ‘preplay’ where rats imagine the likely future experience - measured by comparing neural activations at preplay to activations during the activity</p>
  </li>
  <li>
    <p>Generalization + Transfer in human planning</p>
  </li>
  <li>
    <p>Hierarchical Planning</p>
  </li>
  <li>
    <p>Virtual Brain Analytics</p>
  </li>
</ul>

